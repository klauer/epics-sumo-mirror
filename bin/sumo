#! /usr/bin/env python
# -*- coding: UTF-8 -*-

# pylint: disable=C0111
#                          Missing docstring
# pylint: disable=C0301
#                          Line too long
# pylint: enable=C0301

# pylint: disable=C0103
#                          Invalid name ... for type module
# pylint: disable=C0322
#                          Operator not preceded by a space

from optparse import OptionParser
import sys
import os.path
import os
import re
import errno
import shutil

import sumolib.system
import sumolib.lock
import sumolib.JSON
import sumolib.utils
import sumolib.Config
import sumolib.ModuleSpec
import sumolib.Databases
import sumolib.repos

# version of the program:
__version__= "2.0" #VERSION#

assert __version__==sumolib.system.__version__
assert __version__==sumolib.lock.__version__
assert __version__==sumolib.JSON.__version__
assert __version__==sumolib.utils.__version__
assert __version__==sumolib.Config.__version__
assert __version__==sumolib.ModuleSpec.__version__
assert __version__==sumolib.Databases.__version__
assert __version__==sumolib.repos.__version__

KNOWN_MAIN_COMMANDS=set(("edit","makeconfig","showconfig","db","build"))

KNOWN_DB_COMMANDS=set(("alias-add", "appconvert", "check", "clonemodule",
                       "cloneversion", "convert", "convert-old",
                       "filter", "find",
                       "list", "merge", "dependency-add",
                       "dependency-delete", "replaceversion", "showall",
                       "shownewest", "weight"))

KNOWN_BUILD_COMMANDS=set(("cleanup", "delete", "find", "list",
                          "new",
                          "show", "state", "try", "use", "useall"))

CONFIG_NAME="sumo.config"
ENV_CONFIG="SUMOCONFIG"

# -----------------------------------------------
# utilities
# -----------------------------------------------

def script_shortname():
    """return the name of this script without a path component."""
    return os.path.basename(sys.argv[0])

# -----------------------------------------------
# directory utilities and filenames
# -----------------------------------------------

def makefilename(build_tag):
    """create a makefile name from a build_tag."""
    return "Makefile-%s" % build_tag

def module_dir_string(buildtag, modulename, versionname):
    """create a module directory string."""
    subdir= "%s+%s" % (versionname, buildtag)
    return os.path.join(modulename, subdir)

def module_basedir_string(modulename):
    """create a module base directory string."""
    return modulename

def ensure_dir(dir_, dry_run):
    """create a dir if it doesn't already exist.
    """
    if not dry_run:
        if not os.path.exists(dir_):
            os.makedirs(dir_)

def rm_empty_dir(dirname, verbose, dry_run):
    """remove a directory.

    If the directory is not empty, return without an error message.
    """
    if verbose:
        print "remove dir %s if it is empty" % dirname
    if dry_run:
        return
    try:
        os.rmdir(dirname)
    except OSError, ex:
        if ex.errno == errno.ENOTEMPTY:
            pass

def _assume_dir(dir_, dry_run):
    """ensure that a directory exists."""
    if not dry_run:
        if not os.path.exists(dir_):
            sys.exit("Error, directory 'configure' not found")


def _config_dir(build_tag, module_name, versionname, dry_run):
    """get the config dir name."""
    dir_= module_dir_string(build_tag, module_name, versionname)
    config_dir= os.path.join(dir_, "configure")
    if not dry_run:
        if not os.path.exists(config_dir):
            errmsg("no configure directory found in %s" % dir_)
            return
    return config_dir

# -----------------------------------------------
# buildtag handling
# -----------------------------------------------

def get_buildtag(options, commands, command_index,
                 optional, check_conflict):
    """get the buildtag from options or commands.

    command_index:
                   Index within commands where we expect
                   the buildtag
    optional:
                   Allow that the buildtag is optional, return None if it
                   is not given
    check_conflict:
                   Abort the program when the buildtag is given with both
                   methods.

    returns a tuple, either
    ("option",TAG) or ("argument",TAG) or ("option",None)
    """
    o_buildtag= None
    c_buildtag= None
    if options.buildtag:
        o_buildtag= options.buildtag
    if len(commands)>=command_index+1:
        c_buildtag= commands[command_index]
    if not o_buildtag and not c_buildtag:
        if optional:
            return ("option",None)
        sys.exit("error: buildtag missing")
    if o_buildtag and c_buildtag and check_conflict:
        sys.exit("error: buildtag given as option AND parameter")
    if o_buildtag:
        return ("option",o_buildtag)
    return ("argument",c_buildtag)


# -----------------------------------------------
# load JSON files
# -----------------------------------------------

def db_from_json_file(filename, keep_locked= False):
    """load a db, exits gracefully in case of an error."""
    try:
        db= sumolib.Databases.Dependencies.from_json_file(filename, keep_locked)
    except ValueError, e:
        sys.exit("Error while loading builddb,\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading builddb,\n%s" % str(e))
    return db

def builddb_from_json_file(filename, keep_locked= False):
    """load a builddb, exits gracefully in case of an error."""
    try:
        builddb= sumolib.Databases.Builddb.from_json_file(filename, keep_locked)
    except ValueError, e:
        sys.exit("Error while loading build database (builddb),\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading build database (builddb),\n%s" % str(e))
    return builddb

def init_buildcache(scandb_name, builddb, db):
    """load a builddb, exits gracefully in case of an error."""
    if not scandb_name:
        buildcache= sumolib.Databases.BuildCache()
    else:
        try:
            buildcache= sumolib.Databases.BuildCache.from_json_file(scandb_name,
                                                                 False)
        except ValueError, e:
            sys.exit("Error while loading build database (buildcache),\n%s" % \
                     str(e))
        except IOError, e:
            sys.exit("Error while loading build database (buildcache),\n%s" % \
                     str(e))
    buildcache.update_from_builddb(builddb, db)
    return buildcache

# -----------------------------------------------
# aliases
# -----------------------------------------------

def scan_aliases(aliases):
    """scan aliases given on the command line."""
    d= {}
    if not aliases:
        return d
    for a in aliases:
        (from_, to)= a.split(":")
        d[from_]= to
    return d

def alias(alias_dict, modulename):
    """return a module alias."""
    n= alias_dict.get(modulename)
    if n is None:
        return modulename
    return n

# -----------------------------------------------
# cleanup file handling
# -----------------------------------------------

def cleanupfilename(build_tag):
    """create the name of the cleanup file."""
    return "cleanup-%s" % build_tag

def rmcleanup(build_tag):
    """remove the cleanup file."""
    fn= cleanupfilename(build_tag)
    if os.path.exists(fn):
        return os.remove(fn)

def loadcleanup(build_tag, must_exist= False):
    """load the cleanup file."""
    fn= cleanupfilename(build_tag)
    if os.path.exists(fn):
        return sumolib.JSON.loadfile(fn)
    if must_exist:
        raise IOError("file '%s' not found" % fn)
    return {"modules": [] }

def savecleanup(build_tag, struc):
    """save the cleanup file."""
    fn= cleanupfilename(build_tag)
    sumolib.JSON.dump_file(fn, struc)

# -----------------------------------------------
# error messages
# -----------------------------------------------

def errmsg(msg):
    """print something on stderr."""
    sys.stderr.write(msg+"\n")

# -----------------------------------------------
# module utilities
# -----------------------------------------------

def dump_modules(modulespecs):
    """dump module specs.
    """
    for modulespec in modulespecs:
        print modulespec.to_string()

# -----------------------------------------------
# dependency handling
# -----------------------------------------------

def gather_dependencies(dist_dict, db, modulename, versionname,
                        gathered_deps):
    """recursively gather all dependencies of a module.

    For dependencies, do only take moduleversions that are in dist_dict.

    Returns a dict mapping modulenames to versionnames

    called by builddb_match, command "new"
    """
    if gathered_deps is None:
        gathered_deps= {}
    for dep_name in db.iter_dependencies(modulename, versionname):
        dep_version= dist_dict[dep_name]
        gathered_deps[dep_name]= dep_version
        gathered_deps= gather_dependencies(dist_dict, db, dep_name,
                                           dep_version, gathered_deps)
    return gathered_deps

def _add_dependencies(module_dict, db, build_module_dict,
                      modulename, versionname):
    """recursively add missing dependencies.

    called by get_dependencies, command "use"
    """
    try:
        db.assert_module(modulename, versionname)
    except KeyError, e:
        sys.exit("%s in db file" % str(e))
    for dep in db.iter_dependencies(modulename, versionname):
        if module_dict.has_key(dep):
            continue
        version_present= build_module_dict[dep]
        module_dict[dep]= version_present
        _add_dependencies(module_dict, db, build_module_dict,
                          dep, version_present)

def get_dependencies(module_dict, db, builddb, buildtag):
    """recursively complete the module_dict for missing dependencies.

    called by apprelease, command "use"
    """
    build_module_dict= builddb.modules(buildtag)
    modules= module_dict.items()
    for modulename, versionname in modules:
        _add_dependencies(module_dict, db,
                          build_module_dict, modulename, versionname)

def builddb_match(dist_dict, db, builddb, modulename, versionname):
    """try to find matching deps in builddb.

    called by add_modules, command "new"
    """
    deps= gather_dependencies(dist_dict, db, modulename, versionname, None)
    # now deps is a dict mapping modulenames to versionnames that contains all
    # direct and indirect dependencies of modulename:versionname that was
    # given to this function.
    for build_tag in builddb.iter_builds():
        # try to find modules that were already built, ignore builds that are
        # not marked "stable" or testing:
        if not builddb.is_testing_or_stable(build_tag):
            continue
        if not builddb.has_module(build_tag, modulename):
            continue
        if builddb.module_link(build_tag, modulename):
            # if this build has only a link of the module, skip it
            continue
        modules= builddb.modules(build_tag)
        if modules[modulename]!=versionname:
            # version doesn't match
            continue

        # from here: check if all dependencies match:
        match= True
        for dep_name, dep_ver in deps.items():
            other= modules.get(dep_name)
            if dep_ver!= other:
                match= False
                break
        if match:
            return build_tag
    return

# -----------------------------------------------
# file generation
# -----------------------------------------------

def gen_RELEASE(db, builddb, buildtag,
                dist_dict,
                modulename, versionname,
                extra_lines,
                verbose, dry_run):
    """generate a RELEASE file.

    This function requires that the current working directory is the support
    directory!

    Note: the SUPPORT path is the directory of the builddb file!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_module, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    config_dir= _config_dir(buildtag, modulename, versionname, dry_run)
    if config_dir is None:
        return
    filename= os.path.join(config_dir, "RELEASE")
    if verbose:
        print "creating %s" % filename
    fh= sumolib.utils.file_w_open(filename, verbose, dry_run)

    supportdir= os.getcwd()
    sumolib.utils.file_write(fh, "# generated by sumo for build %s\n\n" % \
                             buildtag,
            verbose, dry_run)
    sumolib.utils.file_write(fh, "SUPPORT=%s\n" % supportdir, verbose, dry_run)
    deps= []

    for dep_name in db.iter_dependencies(modulename, versionname):
        dep_versionname= dist_dict[dep_name]
        deps.append((dep_name, dep_versionname))

    deps= db.sortby_weight(db.sortby_dependency(sorted(deps), True))
    for (dep_name, dep_versionname) in deps:
        name_here= db.get_alias(modulename, versionname, dep_name)
        buildtag_here= builddb.module_link(buildtag, dep_name)
        if buildtag_here is None:
            buildtag_here= buildtag
        path= os.path.join("$(SUPPORT)",
                           module_dir_string(buildtag_here, dep_name,
                                             dep_versionname)
                          )
        sumolib.utils.file_write(fh, "%s=%s\n" % (name_here,path),
                                 verbose, dry_run)
    for l in extra_lines:
        sumolib.utils.file_write(fh, "%s\n" % l.rstrip(), verbose, dry_run)
    if not dry_run:
        fh.close()

def create_makefile(dist_dict, db, builddb, build_tag, verbose, dry_run):
    """generate a makefile.

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_modules, command "new"
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0913
    #                          Too many arguments
    def has_makefile(path):
        """checks if there is a makefile in path."""
        fn= os.path.join(path,"Makefile")
        if os.path.exists(fn):
            return True
        fn= os.path.join(path,"makefile")
        if os.path.exists(fn):
            return True
        return False
    paths= {}
    for modulename, versionname in builddb.iter_modules(build_tag):
        if not builddb.module_link(build_tag, modulename):
            dir_= module_dir_string(build_tag,
                                    modulename,
                                    versionname)
            if not has_makefile(dir_):
                continue
            paths[(modulename, versionname)]= dir_
    filename= makefilename(build_tag)
    if not dry_run:
        cleanup_struc= loadcleanup(build_tag)
        cleanup_struc["makefile"]= filename
        savecleanup(build_tag, cleanup_struc)
    module_dirs= sorted(paths.values())
    stamps= [os.path.join(p,"stamp") for p in module_dirs]
    fh= sumolib.utils.file_w_open(filename, verbose, dry_run)
    sumolib.utils.file_write(fh, "all: %s\n\n" % (" ".join(stamps)),
                             verbose, dry_run)
    sumolib.utils.file_write(fh, "clean:\n", verbose, dry_run)
    for d in module_dirs:
        sumolib.utils.file_write(fh, "\t-$(MAKE) -C %s clean\n" % d,
                                 verbose, dry_run)
    for f in stamps:
        sumolib.utils.file_write(fh, "\trm -f %s\n" % f, verbose, dry_run)
    sumolib.utils.file_write(fh, "\n", verbose, dry_run)
    for spec, path in paths.items():
        (modulename, versionname)= spec
        own_stamp= os.path.join(path, "stamp")
        dep_stamps= []
        for dep_name in db.iter_dependencies(modulename, versionname):
            if builddb.module_link(build_tag, dep_name):
                continue
            dep_version= dist_dict[dep_name]
            # do no handle dependencies that are not in the paths
            # dictionary:
            if not paths.has_key((dep_name, dep_version)):
                continue
            dep_path= module_dir_string(build_tag,
                                        dep_name, dep_version)
            dep_stamps.append(os.path.join(dep_path,"stamp"))

        dep_stamps.sort()
        if dep_stamps:
            sumolib.utils.file_write(fh,
                             "\n%s: %s\n" % \
                                     (own_stamp, " ".join(dep_stamps)),
                             verbose, dry_run)
    sumolib.utils.file_write(fh, "\n%/stamp:\n", verbose, dry_run)
    sumolib.utils.file_write(fh, "\t$(MAKE) -C $(@D)\n", verbose, dry_run)
    sumolib.utils.file_write(fh, "\ttouch $@\n", verbose, dry_run)
    if not dry_run:
        fh.close()

# -----------------------------------------------
# module creation/deletion
# -----------------------------------------------

def create_source(db, modulename, versionname,
                  destdir, verbose, dry_run):
    """create directory by given source spec.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    (sourcetype, sourcedata)= db.module_source_dict(modulename, versionname)
    sumolib.repos.checkout(sourcetype,
                        sourcedata,
                        destdir,
                        verbose, dry_run)

def delete_module(build_tag, modulename, versionname,
                  must_exist,
                  verbose, dry_run):
    """delete a single module."""
    # pylint: disable=R0913
    #                          Too many arguments
    dirname= module_dir_string(build_tag, modulename, versionname)
    if verbose:
        print "removing %s" % dirname
    if not dry_run:
        if os.path.exists(dirname):
            shutil.rmtree(dirname)
        else:
            if must_exist:
                raise IOError("error: '%s' doesn't exist" % dirname)
        # remove the parent directory if it is empty:
    rm_empty_dir(modulename, verbose, dry_run)

def create_module(db, builddb, build_tag,
                  dist_dict,
                  modulename, versionname,
                  extra_defs,
                  archs,
                  verbose, dry_run):
    """check out a module.

    returns the build_tag that was used. If the module was found in another
    build, return that built-tag.

    This function requires that the current working directory is the
    support directory!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_modules, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    if not db.check_archs(modulename, versionname, archs):
        sys.stderr.write("error: archs %s\nnot supportted by "
                         "module %s:%s\n" % \
                         (repr(archs), modulename, versionname))
    basedir= module_basedir_string(modulename)
    ensure_dir(basedir, dry_run) # creates basedir if it doesn't exist
    dirname= module_dir_string(build_tag, modulename, versionname)
    if os.path.exists(dirname):
        raise ValueError("directory %s already exists" % dirname)

    create_source(db, modulename, versionname, dirname, verbose, dry_run)
    gen_RELEASE(db, builddb, build_tag,
                dist_dict,
                modulename, versionname,
                extra_defs,
                verbose, dry_run)

# -----------------------------------------------
# builddb utilities
# -----------------------------------------------

_builddb= [None]
def mspecs_from_build(builddb_name):
    """generate a function to return module specs from a build."""
    def mspecs(buildtag):
        """return module specs for a buildtag."""
        if _builddb[0] is None:
            if builddb_name is None:
                raise ValueError("--builddb is needed for modulespecs")
            _builddb[0]= builddb_from_json_file(builddb_name, False)
        return _builddb[0].module_specs(buildtag)
    return mspecs

def add_modules(dist_dict, db, builddb, build_tag):
    """add modules to the builddb object.

    This function looks for compatible modules in all already existing builds.
    If possible, modules of existing builds are used.

    All modules specified by dist_dict are added with tag <build_tag> to the
    builddb.

    called by create_modules, command "new"
    """
    for modulename in sorted(dist_dict.keys()):
        versionname= dist_dict[modulename]

        # try to find a build that already has the module and where all it's
        # dependencies are also present with the same version as in dist_dict:
        compatible_build= builddb_match(dist_dict, db, builddb, modulename,
                                        versionname)
        if compatible_build is None:
            # no existing build of the module was found, we have to build the
            # module ourselbves:
            build_tag_used= build_tag
        else:
            # a compatible existing build of the module was found:
            build_tag_used= compatible_build

        builddb.add_module(build_tag, build_tag_used, modulename, versionname)

# -----------------------------------------------
# further db functions
# -----------------------------------------------

def create_app_data(deps, repoinfo, groups):
    """create configuration data for an app."""
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    keys= deps.keys()
    if len(keys)!=1:
        sys.exit("error: \"dependencies\" map must have exactly one key")

    modulespecs= []
    aliases    = []

    app_path= keys[0]
    specs_by_path= {}

    for module_name, groupdata in groups.items():
        keys= groupdata.keys()
        if len(keys)!=1:
            sys.exit("error: groupdata \"%s\" must have exactly one key" % \
                     module_name)
        root_path= keys[0]
        values= groupdata[root_path]
        if len(values)!=1:
            sys.exit("error: groudata \"%s\" must have exactly one "
                     "subdir" % module_name)
        subdir= values[0]
        versionedmodule_path= os.path.join(root_path, subdir)
        try:
            r_dict= repoinfo.get[versionedmodule_path]
        except KeyError, _:
            # shouldn't happen, but we just print a warning in this
            # case:
            errmsg("no source data: %s" % versionedmodule_path)
            continue

        sourcespec_obj= sumolib.repos.SourceSpec(r_dict)
        if sourcespec_obj.sourcetype()=="path":
            versionname= "PATH-%s" % subdir
        else:
            tag= sourcespec_obj.tag()
            if tag is None:
                versionname= "TAGLESS-%s" % subdir
            else:
                versionname= tag
        specs_by_path[versionedmodule_path]= (module_name,versionname)

    for (aliasname, path) in deps[app_path].items():
        (module_name,versionname)= specs_by_path[path]
        modulespecs.append("%s:%s" % (module_name,versionname))
        if aliasname!=module_name:
            aliases.append("%s:%s" % (module_name, aliasname))
    aliases.sort()
    modulespecs.sort()

    return {"alias": aliases, "module": modulespecs}


def create_database(deps, repoinfo, groups, archs, source_patches):
    """join the information of the three sources.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0913
    #                          Too many arguments
    patcher= sumolib.utils.RegexpPatcher()
    if source_patches:
        for p in source_patches:
            # pylint: disable=W0123
            #                          Use of eval
            patcher.add(eval(p))
    _path2namevname= {}
    _namevname2path= {}
    db= sumolib.Databases.Dependencies()
    # we first create the map from modulenames to versiondata. In this loop we
    # populate the versiondata only with the source specification. We also
    # create two maps:
    #    _path2namevname: maps a diretory path to (module_name, versionname)
    #    _namevname2path: maps (module_name,versionname) to a diretory path
    for module_name, groupdata in groups.items():
        # the root directory of all the versions:
        for root_path, subdirs in groupdata.items():
            for subdir in sorted(subdirs):
                # iterate over all versions from <groups>:
                # reconstruct the original directory path:
                versionedmodule_path= os.path.join(root_path, subdir)
                # get the repository data:
                try:
                    r_dict= repoinfo.get(versionedmodule_path)
                except KeyError, _:
                    # shouldn't happen, but we just print a warning in this
                    # case:
                    errmsg("no source data: %s" % versionedmodule_path)
                    continue

                src_sourcespec= sumolib.repos.SourceSpec(r_dict)
                if src_sourcespec.sourcetype()=="path":
                    # the source is a directory path, not a repository. We
                    # generate the unique versionname:
                    if subdir.startswith("PATH-"):
                        # Try to handle a subdir that was created by this set
                        # of tools. Such a subdir may already be named
                        # "PATH-<name>+<treetag>". We want to take <name> as
                        # versionname in this case:
                        versionname= sumolib.utils.split_treetag(subdir)[0]
                    else:
                        versionname= "PATH-%s" % subdir
                    # repodata is just the path in this case:
                    src_sourcespec.path(patcher.apply(src_sourcespec.path()))
                if src_sourcespec.is_repo():
                    tag= src_sourcespec.tag()

                    if tag is None:
                        # the source is a repository but has no tag. We
                        # generate a unique versionname:
                        if subdir.startswith("TAGLESS-"):
                            # Try to handle a subdir that was created by this
                            # set of tools. Such a subdir may already be named
                            # "PATH-<name>+<treetag>". We want to take <name>
                            # as versionname in this case:
                            versionname= sumolib.utils.split_treetag(subdir)[0]
                        else:
                            versionname= "TAGLESS-%s" % subdir
                        # patch URL to <versionedmodule_path>. Since we do not
                        # know in what state the working copy repository is, we
                        # have to take this as a source instead of the central
                        # repository:
                    else:
                        # the source is a darcs repository with a tag. We use
                        # the tag as unique versionname:
                        versionname= tag
                    src_sourcespec.url(patcher.apply(src_sourcespec.url()))

                module_archs= archs.get(versionedmodule_path, [])
                if not module_archs:
                    #  module_archs list is empty:
                    errmsg("no archs for path %s" % \
                           versionedmodule_path)
                db.set_source_arch(module_name, versionname,
                                   module_archs,
                                   src_sourcespec)

                _path2namevname[versionedmodule_path]= \
                        (module_name,versionname)
                # when we assume that a versionedmodule_path may contain a
                # buildtag, there may be several versionedmodule_paths for a
                # pair of (module_name, versionname).
                _paths= _namevname2path.setdefault(
                                    (module_name, versionname),[])
                _paths.append(versionedmodule_path)

    #sumolib.JSON.dump(_path2namevname)
    #sys.exit(0)

    buildcache= sumolib.Databases.BuildCache()

    # here we populate the versiondata with the dependency specifications:
    for modulename in db.iter_modulenames():
        # loop on stable, testing and unstable versions:
        for versionname in db.iter_versions(modulename,
                                            None, False):
            versionedmodule_paths= _namevname2path[(modulename, versionname)]

            for versionedmodule_path in versionedmodule_paths:
                _deps= deps.get(versionedmodule_path)
                if _deps is None:
                    errmsg("no dependency info for path %s" % \
                           versionedmodule_path)
                    continue
                for dep_alias, dep_path in _deps.items():
                    try:
                        (_dep_name, _dep_version)= _path2namevname[dep_path]
                    except KeyError, _:
                        sys.exit(("at module %s version %s "+ \
                                  "path %s: "+ \
                                  "missing data for "+ \
                                  "dependency \"%s\"") % \
                                  (modulename, versionname,
                                   versionedmodule_path,
                                   dep_path))
                    if _dep_name != dep_alias:
                        try:
                            db.add_alias(modulename, versionname,
                                         dep_alias, _dep_name)
                        except ValueError, e:
                            errmsg("alias error in module %s: %s" % \
                                   (modulename, str(e)))
                    db.add_dependency(modulename, versionname,
                                      _dep_name)
                    buildcache.add_dependency(modulename, versionname,
                                              _dep_name, _dep_version,
                                              "scanned")
    return (buildcache,db)

def set_weight(db, weight, modulespecs, trace):
    """set the weight for one or more modules."""
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if trace:
            sys.stderr.write("%s\n" % modulespec.to_string())

        # scan stable, testing and unstable versions:
        for version in db.iter_versions(modulename,
                                        None, must_exist= False):
            if trace:
                sys.stderr.write("test %s:%s\n" % (modulename,version))
            if not modulespec.test(version):
                continue
            if trace:
                sys.stderr.write("set weight %d on %s:%s\n" % \
                                 (weight,modulename,version))
            db.weight(modulename, version, weight)

# -----------------------------------------------
# further builddb functions
# -----------------------------------------------

def delete_modules(builddb, build_tag, verbose, dry_run):
    """delete modules of a build.
    """
    for b in builddb.iter_builds():
        if builddb.is_linked_to(b, build_tag):
            raise ValueError("error: other builds depend on build %s" % \
                              build_tag)
    for modulename, versionname in builddb.iter_modules(build_tag):
        if builddb.module_link(build_tag, modulename):
            continue
        delete_module(build_tag, modulename, versionname, True,
                      verbose, dry_run)

    os.remove(makefilename(build_tag))

    builddb.delete(build_tag)

def cleanup_modules(build_tag, verbose, dry_run):
    """cleanup remains of a failed build.

    This can only happen if a "new" command was aborted due to an exception in
    the script.
    """
    try:
        cleanup_struc= loadcleanup(build_tag, must_exist= True)
    except IOError, e:
        sys.exit(str(e))

    module_list= cleanup_struc["modules"]
    for module_dict in module_list:
        delete_module(build_tag,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      False,
                      verbose, dry_run)
    makefile= cleanup_struc.get("makefile")
    if makefile:
        if os.path.exists(makefile):
            os.remove(makefile)
    if not dry_run:
        rmcleanup(build_tag)

def create_modules(dist_dict, db, builddb, build_tag, extra_lines,
                   archs,
                   no_checkout,
                   verbose, dry_run):
    """create all modules.

    This function requires that the current working directory is the support
    directory!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by process, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # save a list of possibly created directories in a cleanup-structure. In
    # case the script exits with an exception, the created cleanup file can be
    # used to clean up the support directory.
    # Load the cleanup file in case other parts of the script have saved
    # someting there:
    cleanup_struc= loadcleanup(build_tag)
    module_list  = cleanup_struc.setdefault("modules", [])

    # add all modules specified by dist_dict to builddb under tag build_tag:
    add_modules(dist_dict, db, builddb, build_tag)

    if builddb.is_fully_linked(build_tag):
        # the new build would contain only links, this is probably not wanted.
        if sumolib.Databases.Builddb.is_generated_buildtag(build_tag):
            # we never want an autotag build that consists only of links
            sys.exit("error: this build with an auto generated tag "
                     "would consist only of links. You can as well "
                     "use one of the existing builds. Just try "
                     "'sumo build use'.")
        sys.stderr.write("Note: The generated build '%s' consists only of "
                         "links.\n" % build_tag)

    for modulename in sorted(dist_dict.keys()):
        versionname= builddb.module_version(build_tag, modulename)
        # do not re-create modules that are links:
        if builddb.module_link(build_tag, modulename):
            continue
        # module_list contains only the modules that are NOT links:
        module_list.append({"modulename" : modulename,
                            "versionname": versionname})

    if not dry_run and not no_checkout:
        savecleanup(build_tag, cleanup_struc)
    if no_checkout:
        return
    for module_dict in module_list:
        create_module(db, builddb, build_tag,
                      dist_dict,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      extra_lines,
                      archs,
                      verbose, dry_run)

def call_make(builddb_name, buildtag,
              make_options,
              verbose, dry_run):
    """call "make", then mark the build "testing"."""
    # pylint: disable=R0913
    #                          Too many arguments
    #cmd="make -f %s" % makefilename(buildtag)
    if make_options is None:
        make_options=[]
    cmd="make %s -f %s" % (" ".join(make_options),makefilename(buildtag))
    try:
        # sys.stderr.write("CALLING MAKE: %s\n" % cmd)
        sumolib.system.system(cmd, False, False, verbose, dry_run)
    except IOError, e:
        sys.stderr.write("error: make failed, %s" % str(e))
        sys.exit(1)

    builddb= builddb_from_json_file(builddb_name, keep_locked= not dry_run)
    builddb.change_state(buildtag, "testing")
    builddb.json_save(builddb_name, verbose, dry_run)
    # ^^^ does also unlock the file

def fullapprelease(build_path, build_tag, builddb, db, modules,
                   aliases, extra_lines):
    """create entries for an release file.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    lines= ["# generated by sumo using build %s:\n" % build_tag,
            "SUPPORT=%s\n" % os.path.realpath(build_path)]
    if modules is None:
        modules= builddb.modules(build_tag).keys()

    basenames= {}
    mods= []
    for modulename in modules:
        tag= builddb.module_link(build_tag, modulename)
        if tag is None:
            tag= build_tag
        version= builddb.module_version(tag, modulename)
        basenames[(modulename, version)]= \
                   module_dir_string(tag, modulename, version)
        mods.append((modulename, version))

    mods= db.sortby_weight(db.sortby_dependency(sorted(mods), True))
    for (modulename, version) in mods:
        lines.append("%s=%s\n" % \
                (alias(aliases, modulename),
                 os.path.join("$(SUPPORT)", basenames[(modulename, version)])
                ))
    for l in extra_lines:
        lines.append("%s\n" % l)
    return lines

def apprelease(build_path, build_tag, modulespecs, builddb, db,
               aliases, extra_lines):
    """create entries for an release file.

    used in command "use".
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if build_tag is None:
            # unspecifed build_tag, all versions must be *exactly specified*:
            if not modulespec.is_exact_spec():
                sys.exit("modulespec '%s' is not an exactly "
                         "specified version" % modulespec.to_string())

    if build_tag is None:
        # must look for a matching build:
        new_builddb= builddb.filter_by_modulespecs(modulespecs, db)
        if new_builddb.is_empty():
            sys.exit("no build found that matches modulespecs")
        tags= [b for b in new_builddb.iter_builds()]
        build_tag= tags[0]
        sys.stderr.write("using build %s\n" % build_tag)


    build_modules= builddb.modules(build_tag)
    module_dict= {}
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        v= build_modules.get(modulename)
        if v is None:
            sys.exit("error: module %s not found in build %s" % \
                     (modulename, build_tag))
        if not modulespec.test(v):
            sys.exit("error: no module matching %s "
                     "found in build %s" % \
                     (modulespec.to_string(), build_tag))
        module_dict[modulename]= v
    get_dependencies(module_dict, db, builddb, build_tag)
    return fullapprelease(build_path, build_tag, builddb, db,
                          module_dict.keys(), aliases, extra_lines)

# -----------------------------------------------
# command processing
# -----------------------------------------------

def process_db(options, commands):
    """do all the work.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    if options.nolock:
        sumolib.lock.use_lockfile= False
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_DB_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if commands[0]=="convert":
        if not options.db:
            sys.exit("error, --db is mandatory here")
        if not options.scandb:
            sys.exit("error, --scandb is mandatory here")
        if len(commands)!=2:
            sys.exit("a filename must follow \"convert\"")
        if os.path.exists(options.db):
            sys.exit("error, db file '%s' already exists" % options.db)
        if os.path.exists(options.scandb):
            sys.exit("error, scandb file '%s' already exists" % \
                     options.scandb)
        filename= commands[1]
        scandata= sumolib.JSON.loadfile(filename)
        deps= scandata["dependencies"]
        repoinfo= scandata["repos"]
        groups= scandata["groups"]
        archs= scandata["archs"]
        (buildcache, db)= create_database(deps, repoinfo, groups, archs,
                                          options.source_patch)
        db.json_save(options.db, options.verbose, options.dry_run)
        buildcache.json_save(options.scandb,
                             options.verbose, options.dry_run)
        return

    if commands[0]=="convert-old":
        if not options.db:
            sys.exit("error, --db is mandatory here")
        if not options.scandb:
            sys.exit("error, --scandb is mandatory here")
        if len(commands)!=2:
            sys.exit("a filename must follow \"convert-old\"")
        if os.path.exists(options.db):
            sys.exit("error, db file '%s' already exists" % options.db)
        if os.path.exists(options.scandb):
            sys.exit("error, scandb file '%s' already exists" % \
                     options.scandb)
        filename= commands[1]
        old= sumolib.Databases.OldDependencies.from_json_file(filename,
                                                           keep_locked=False)
        (buildcache, db)= old.convert()
        db.json_save(options.db, options.verbose, options.dry_run)
        buildcache.json_save(options.scandb,
                             options.verbose, options.dry_run)
        return

    if commands[0]=="appconvert":
        if len(commands)!=2:
            sys.exit("a filename must follow \"convert\"")
        filename= commands[1]
        scandata= sumolib.JSON.loadfile(filename)
        deps= scandata["dependencies"]
        repoinfo= scandata["repos"]
        groups= scandata["groups"]
        struc= create_app_data(deps, repoinfo, groups)
        sumolib.JSON.dump(struc)
        return

    if commands[0]=="weight":
        if len(commands)<=1:
            sys.exit("error: WEIGHT and module missing")
        if len(commands)<=2:
            sys.exit("error: no modules specified")
        if not options.db:
            sys.exit("error, --db is mandatory here")
        weight= commands[1]
        modulespecs= commands[2:]
        try:
            weight= int(weight)
        except ValueError, _:
            sys.exit("error: weight must be an integer")
        db= db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,
                                                                None)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        set_weight(db, weight, modulespecs_obj, options.trace)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="filter":
        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        if not options.db:
            sys.exit("error, --db is mandatory here")
        db= db_from_json_file(options.db, keep_locked= False)
        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,
                                                            None,
                                                            options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        db= db.partial_copy_by_modulespecs(modulespecs_obj)
        db.json_print()
        return

    if commands[0]=="check":
        if len(commands)>1:
            sys.exit("error: extra arguments following \"check\"")
        if not options.db:
            sys.exit("error, --db is mandatory here")
        db = db_from_json_file(options.db,
                                               keep_locked= False)
        msg= db.check()
        print "\n".join(msg)
        return

    if commands[0]=="merge":
        if len(commands)!=2:
            sys.exit("exactly one filename must follow \"merge\"")
        if not options.db:
            sys.exit("error, --db is mandatory here")
        db = db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        db2= db_from_json_file(commands[1])
        db.merge(db2)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="alias-add":
        if len(commands)<4:
            sys.exit("Three arguments must follow \"%s\"" % \
                     commands[0])
        if not options.db:
            sys.exit("error, --db is mandatory here")
        module_spec= sumolib.ModuleSpec.Spec.from_string(commands[1])
        (depname,dep_alias)= commands[2:4]
        db = db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        db.add_alias(module_spec.modulename,
                     module_spec.versionname,
                     dep_alias, depname)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="dependency-add":
        if len(commands)<3:
            sys.exit("Two arguments must follow \"%s\"" % \
                     commands[0])
        if not options.db:
            sys.exit("error, --db is mandatory here")
        module_spec= sumolib.ModuleSpec.Spec.from_string(commands[1])
        dep        = commands[2]
        db = db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        db.add_dependency(module_spec.modulename,
                          module_spec.versionname,
                          dep)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="dependency-delete":
        if len(commands)<3:
            sys.exit("Two arguments must follow \"%s\"" % \
                     commands[0])
        if not options.db:
            sys.exit("error, --db is mandatory here")
        module_spec= sumolib.ModuleSpec.Spec.from_string(commands[1])
        dep        = commands[2]
        if module_spec.no_version_spec():
            sys.exit("module has no version")

        db = db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        db.del_dependency(module_spec.modulename,
                          module_spec.versionname,
                          dep)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="cloneversion" or commands[0]=="replaceversion":
        do_replace= (commands[0]=="replaceversion")
        if len(commands)<4:
            sys.exit("at least three arguments must follow \"%s\"" % \
                     commands[0])
        (modulename, oldversion, newversion)= commands[1:4]
        if len(commands)<=4:
            sourcespec= None
        else:
            sourcespec= commands[4:]
        if not options.db:
            sys.exit("error, --db is mandatory here")

        db = db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        try:
            db.patch_version(modulename, oldversion, newversion,
                             do_replace)
        except ValueError, e:
            sys.exit(str(e))

        if not sourcespec:
            # guess tag from versionname
            changed= db.set_source_spec_by_tag(modulename, newversion,
                                               newversion)
        else:
            try:
                source_spec_obj= \
                    sumolib.repos.SourceSpec.from_string_sourcespec(sourcespec)
            except ValueError, e:
                sys.exit("Error: "+str(e))
            changed= db.set_source_spec(modulename, newversion,
                                        source_spec_obj)
        print "Added module:"
        report_db= db.partial_copy_by_list([(modulename, newversion)])
        report_db.json_print()
        if not changed:
            print ("\nCAUTION: source specification of this module is "
                   "identical with that of \n"
                   "%s:%s, this is probably not what you want!") % \
                   (modulename, oldversion)
        sumolib.utils.ask_abort("Proceed ? ", options.yes)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="clonemodule":
        if len(commands)<3:
            sys.exit("at least two arguments must follow \"%s\"" % \
                     commands[0])
        (oldmodule, newodule)= commands[1:3]
        versions= commands[3:]
        if not options.db:
            sys.exit("error, --db is mandatory here")
        db = db_from_json_file(options.db,
                keep_locked= not options.dumpdb and (not options.dry_run))
        db.clonemodule(oldmodule, newodule, versions)
        if options.dumpdb:
            db.json_print()
        else:
            db.json_save(options.db, options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="list":
        if len(commands)>1:
            sys.exit("error: extra arguments following \"list\"")
        if not options.db:
            sys.exit("error, --db is mandatory here")
        db= db_from_json_file(options.db)
        result= sorted(db.iter_modulenames())
        sumolib.JSON.dump(result)
        return

    if commands[0]=="shownewest" or commands[0]=="showall":
        showall= (commands[0]=="showall")
        if not options.db:
            sys.exit("error, --db is mandatory here")
        db= db_from_json_file(options.db)

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])

        if not modulespecs:
            modulespecs= list(db.iter_modulenames())

        result= {}

        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,
                                                            None,
                                                            options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        for modulespec in modulespecs_obj:
            modulename= modulespec.modulename

            versions= db.sorted_moduleversions(modulename,
                                               options.arch, False)
            if not versions: # no versions match criteria
                continue
            versions= [v for v in versions \
                       if modulespec.test(v)]

            if not showall:
                result[modulename]= versions[0]
            else:
                result[modulename]= versions
        sumolib.JSON.dump(result)
        return

    if commands[0]=="find":
        if len(commands)<=1:
            sys.exit("error: REGEXP missing")
        if not options.db:
            sys.exit("error, --db is mandatory here")
        db= db_from_json_file(options.db)
        regexp= commands[1]
        if options.noignorecase:
            rx_flags= 0
        else:
            rx_flags= re.IGNORECASE
        rx= re.compile(regexp, rx_flags)
        results= db.search_modules(rx, options.arch)
        if options.brief:
            for (module,version) in results:
                print "%s:%s" % (module,version)
            return
        newdb= db.partial_copy_by_list(results)
        newdb.json_print()
        return

def process_build(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0914
    #                          Too many local variables
    if options.nolock:
        sumolib.lock.use_lockfile= False
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_BUILD_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if not options.extra:
        options.extra= []

    if commands[0]=="list":
        if len(commands)>1:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        builddb= builddb_from_json_file(options.builddb)
        for buildtag in builddb.iter_builds():
            print buildtag
        return

    if commands[0]=="show":
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)

        if not options.builddb:
            sys.exit("--builddb is mandatory")
        builddb= builddb_from_json_file(options.builddb)
        if not builddb.has_build_tag(buildtag):
            sys.exit("error: buildtag \"%s\" not found" % buildtag)
        new_builddb= sumolib.Databases.Builddb()
        new_builddb.add_build(builddb, buildtag)
        new_builddb.json_print()
        return

    if commands[0]=="state":
        if options.readonly:
            sys.exit("--readonly forbids changing the state of a build")

        if len(commands)>3:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (buildtag_from,buildtag)= get_buildtag(options, commands,
                                               command_index=1,
                                               optional= False,
                                               check_conflict= False)
        if buildtag_from=="option":
            state_idx= 1
        else:
            state_idx= 2

        if len(commands)<=state_idx:
            new_state= None
        else:
            new_state= commands[state_idx]

        if not options.builddb:
            sys.exit("--builddb is mandatory")
        builddb= builddb_from_json_file(options.builddb,
                keep_locked= not options.dry_run)
        if not builddb.has_build_tag(buildtag):
            # builddb __del__ method should remove lockfiles
            sys.exit("error: buildtag \"%s\" not found" % buildtag)
        if not new_state:
            print "%-20s : %s" % (buildtag, builddb.state(buildtag))
        else:
            try:
                builddb.change_state(buildtag, new_state)
            except ValueError, e:
                # builddb __del__ method should remove lockfiles
                sys.exit(str(e))
            builddb.json_save(options.builddb,
                              options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="delete":
        if options.readonly:
            sys.exit("--readonly forbids deleting a support")
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)

        if options.supportdir:
            os.chdir(options.supportdir)

        builddb= builddb_from_json_file(options.builddb)
        if not builddb.has_build_tag(buildtag):
            sys.exit("error: buildtag \"%s\" not found" % buildtag)
        try:
            delete_modules(builddb, buildtag,
                           options.verbose, options.dry_run)
        except ValueError, e:
            sys.exit(str(e))
        builddb.json_save(options.builddb,
                          options.verbose, options.dry_run)
        return

    if commands[0]=="cleanup":
        if options.readonly:
            sys.exit("--readonly forbids cleaning up")
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)
        if options.supportdir:
            os.chdir(options.supportdir)

        cleanup_modules(buildtag, options.verbose, options.dry_run)
        return

    if commands[0]=="try":

        # this command can no longer work this way,
        # it has to be re-implemented
        buildtag= options.buildtag
        if not options.db:
            sys.exit("--db is mandatory")
        if not options.builddb:
            sys.exit("--builddb is mandatory")

        exclude_matcher= sumolib.utils.RegexpMatcher(options.exclude_states)

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                 modulespecs,
                                 mspecs_from_build(options.builddb),
                                 options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)

        db= db_from_json_file(options.db, keep_locked= False)
        if not os.path.exists(options.builddb):
            builddb= sumolib.Databases.Builddb()
        else:
            builddb= builddb_from_json_file(options.builddb,
                                            keep_locked= False)

        buildcache= init_buildcache(options.scandb,
                                    builddb, db)

        # ensure that each module is only mentioned once in the modulelist:
        try:
            modulespecs_obj.assert_unique()
        except ValueError, e:
            sys.exit(str(e))

        modules_not_exact_spec= []
        for spec in modulespecs_obj:
            if not spec.is_exact_spec():
                modules_not_exact_spec.append(spec.modulename)

        # convert modulespecs to a set dict:
        # { modulename1 : set(version1,version2),
        #   modulename2 : set(version1,version2),
        # }
        try:
            sets_dict= db.sets_dict(modulespecs_obj)
        except ValueError, e:
            sys.exit(str(e))

        # add all missing dependencies:
        added_modules= db.complete_sets_dict(sets_dict)

        was_built= set()
        needed_by_others= {}

        for modulename in sets_dict.keys():
            for versionname in sets_dict[modulename]:
                if buildcache.was_built(modulename,versionname):
                    was_built.add((modulename,versionname))
                for depname in db.iter_dependencies(modulename, versionname):
                    for dep_version in sets_dict[depname]:
                        s= needed_by_others.setdefault((depname,dep_version),
                                                       [])
                        s.append((modulename,versionname,
                                 buildcache.relation(modulename,versionname,
                                                     depname, dep_version)))

        # now build the report structure:
        report= {}
        for modulename in sets_dict.keys():
            mdict= report.setdefault(modulename, {})
            no_of_versions= len(sets_dict[modulename])
            for versionname in sets_dict[modulename]:
                d= {}
                mdict[versionname]= d
                d["built"]= (modulename,versionname) in was_built
                l= needed_by_others.get((modulename,versionname))
                if l is not None:
                    dd= d.setdefault("dependents", {})
                    depmods_versioncount= {}
                    for (m,v,state) in l:
                        depmods_versioncount.setdefault(m, 0)
                        if state is None:
                            state= "state: not tested"
                        else:
                            state= "state: %s" % state
                        if no_of_versions>1:
                            # do only apply the exclude_matcher when there is
                            # more than ony possible version of module
                            # 'modulename':
                            if exclude_matcher.search(state):
                                continue
                        depmods_versioncount[m]+= 1
                        dd["%s:%s" % (m,v)]= state
                    if min(depmods_versioncount.values())==0:
                        # all versions of a dependent were removed,
                        # remove modulename:versionname completely:
                        del mdict[versionname]
            if not mdict:
                sys.exit("error: your '--exclude-states' option removes "
                         "*ALL* versions of module '%s'. You may change "
                         "the REGEXP or specify an exact version "
                         "for the module to avoid this error." % \
                         modulename)

        if modules_not_exact_spec:
            print "Not all modules have exactly specified versions.",
            print "These modules need an "
            print "exact version specification:"
            for m in sorted(modules_not_exact_spec):
                versions= report[m].keys()
                if len(versions)>1:
                    print "    %s" % m
                else:
                    print "    %-20s -> suggested version: %s" % \
                          (m,versions[0])
            print

        if added_modules:
            print "Not all dependencies were included in module",
            print "specifications, these modules"
            print "have to be added:\n   ",
            print "\n    ".join(sorted(added_modules))
            print

        if not options.brief:
            if not modules_not_exact_spec and not added_modules:
                # everything complete, show modules that are not needed by
                # other modules:
                needed_modules= set([m for (m,_) in needed_by_others.keys()])
                not_needed_modules= \
                        set(report.keys()).difference(needed_modules)
                print "The following modules are not needed by other modules",
                print "in your module"
                print "specification:\n   ",
                print "\n    ".join(sorted(not_needed_modules))
                print
            print "List of modules that fullfill the given "+\
                  "module specification:"
            sumolib.JSON.dump(report)

        if buildtag is None:
            if not options.buildtag_stem:
                options.buildtag_stem= "AUTO"
            buildtag= builddb.generate_buildtag(options.buildtag_stem)
            print "Command 'new' would create build with tag '%s'\n" % \
                  buildtag

        if not modules_not_exact_spec and not added_modules:
            print "Your module specifications are complete. You can use",
            print "these with command"
            print "'new' to create a new build."
        else:
            print "Your module specifications are still incomplete,",
            print "command 'new' can not"
            print "be used with these."
        return

    if commands[0]=="new":
        if options.readonly:
            sys.exit("--readonly forbids creating a new build")

        buildtag= options.buildtag

        if not options.db:
            sys.exit("--db is mandatory")
        if not options.builddb:
            sys.exit("--builddb is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        db= db_from_json_file(options.db, keep_locked= False)

        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                 modulespecs,
                                 mspecs_from_build(options.builddb),
                                 options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)

        try:
            dist_dict= modulespecs_obj.to_dist_dict()
        except ValueError, e:
            sys.exit(str(e))
        try:
            db.assert_complete_modulelist(dist_dict)
        except ValueError, e:
            sys.exit(str(e))

        if not os.path.exists(options.builddb):
            builddb= sumolib.Databases.Builddb()
        else:
            builddb= builddb_from_json_file(options.builddb,
                        keep_locked= not options.dry_run)
        if buildtag is None:
            if not options.buildtag_stem:
                options.buildtag_stem= "AUTO"
            buildtag= builddb.generate_buildtag(options.buildtag_stem)
            sys.stderr.write("creating build with tag '%s'\n" % buildtag)
        if builddb.has_build_tag(buildtag):
            # builddb __del__ method should remove lockfiles
            sys.exit("error: buildtag \"%s\" already taken" % buildtag)
        # create a new build in builddb, initial state is "unstable":
        builddb.new_build(buildtag, "unstable")
        if options.supportdir:
            os.chdir(options.supportdir)
        # modifies builddb:
        try:
            create_modules(dist_dict, db, builddb, buildtag,
                           options.extra,
                           options.arch,
                           options.no_checkout,
                           options.verbose,
                           options.dry_run)
            if not options.no_checkout:
                create_makefile(dist_dict, db, builddb, buildtag,
                                options.verbose,
                                options.dry_run)
        except IOError, e:
            db.unlock_file()
            builddb.unlock_file()
            raise

        builddb.json_save(options.builddb, options.verbose, options.dry_run)
        # ^^^ does also unlock the file
        rmcleanup(buildtag)
        if not options.no_make and not options.no_checkout:
            call_make(options.builddb, buildtag,
                      options.makeopts,
                      options.verbose, options.dry_run)
        return
    if commands[0]=="find":
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        if not options.db:
            sys.exit("--db is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                 modulespecs,
                                 mspecs_from_build(options.builddb),
                                 options.arch)
        except ValueError, e:
            sys.exit(str(e))

        db= db_from_json_file(options.db)
        builddb= builddb_from_json_file(options.builddb)

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        new_builddb= builddb.filter_by_modulespecs(modulespecs_obj, db)
        if new_builddb.is_empty():
            print "no matching buildtrees found"
        else:
            if options.brief:
                for buildtag in builddb.iter_builds():
                    print buildtag
            else:
                new_builddb.json_print()
        return
    if commands[0]=="useall":
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)

        if not options.db:
            sys.exit("--db is mandatory")
        output= options.output
        if not output:
            _assume_dir("configure", options.dry_run)
            output= os.path.join("configure","RELEASE")

        builddb= builddb_from_json_file(options.builddb)
        db= db_from_json_file(options.db)
        lines= fullapprelease(options.supportdir \
                                 if options.supportdir else ".",
                              buildtag,
                              builddb,
                              db,
                              None,
                              scan_aliases(options.alias),
                              options.extra)
        sumolib.utils.mk_text_file(output, lines,
                                   options.verbose, options.dry_run)
        return

    if commands[0]=="use":
        buildtag= options.buildtag

        if not options.db:
            sys.exit("--db is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)

        if not options.db:
            sys.exit("--db is mandatory")
        output= options.output
        if not output:
            _assume_dir("configure", options.dry_run)
            output= os.path.join("configure","RELEASE")

        db= db_from_json_file(options.db)
        builddb= builddb_from_json_file(options.builddb)

        try:
            modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                 modulespecs,
                                 mspecs_from_build(options.builddb),
                                 options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)

        lines= apprelease(options.supportdir \
                             if options.supportdir else ".",
                          buildtag,
                          modulespecs_obj,
                          builddb,
                          db,
                          scan_aliases(options.alias),
                          options.extra)
        sumolib.utils.mk_text_file(output, lines,
                                   options.verbose, options.dry_run)
        return

def process(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    if not commands:
        print "command missing\n"
        print usage
        return
    if commands[0]=="help":
        print helptext(commands[1:])
        return

    config_name= None
    if not options.no_default_config:
        config_name= CONFIG_NAME
    config= sumolib.Config.ConfigFile.from_optionlist(
                config_name,
                ENV_CONFIG,
                ( "#include", "arch", "alias", "builddb", "buildtag_stem",
                  "db", "extra", "makeopts", "module", "progress",
                  "readonly", "scandb", "source_patch", "supportdir",
                  "verbose"))

    try:
        config.load(options.config)
    except ValueError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    try:
        config.merge_options(options, options.mergeoption)
    except ValueError, e:
        sys.exit(str(e))
    except TypeError, e:
        sys.exit(str(e))
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_MAIN_COMMANDS:
        sys.exit("unknown maincommand '%s', expected 'db' or 'build'.")
    if commands[0]=="showconfig":
        print "These configuration files were loaded:"
        print "\n".join(config.paths())
        return
    if commands[0]=="makeconfig":
        if len(commands)<=1:
            sys.exit("filename for command \"makeconfig\" is missing")
        if options.module:
            try:
                modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                     options.module,
                                     mspecs_from_build(options.builddb),
                                     options.arch)
            except ValueError, e:
                sys.exit(str(e))
            config.set("module", modulespecs_obj.to_stringlist())
        config.save(commands[1], commands[2:])
        return

    elif commands[0]=="edit":
        if options.readonly:
            sys.exit("--readonly forbids editing a database file")
        if len(commands)!=2:
            sys.exit("exactly one filename must follow \"edit\"")
        try:
            sumolib.lock.edit_with_lock(commands[1],
                                        options.verbose, options.dry_run)
        except IOError, e:
            sys.exit(str(e))
        return

    elif commands[0]=="db":
        process_db(options, commands[1:])
    elif commands[0]=="build":
        process_build(options, commands[1:])
    else:
        raise AssertionError("unexpected command: %s" % commands[0])
    return

def print_summary():
    """print a short summary of the scripts function."""
    print "%-20s: a tool for managing support EPICS trees \n" % \
          script_shortname()

def _test():
    """does a self-test of some functions defined here."""
    print "performing self test..."
    import doctest
    doctest.testmod()
    print "done!"

help_maincommands= set(("makeconfig", "edit", "db", "build"))

help_topics= {
        "":"""
No help topic given. Use
  "help <topic>" to get help on a topic.

Possible topics are:

  maincommand                : explain what a maincommand is
  configuration              : how and where configuration data is stored
  <maincommand>              : help for a specific maincommand
  <maincommand> <subcommand> : help for a subcommand of a maincommand
  <subcommand>               : help for a subcommand
""",
        "maincommand":"""
A maincommand provides a grouping for the various commands of sumo.

While some maincommands can be used without a subcommand, others must be
followed by a subcommand. These are the known maincommands:

  makeconfig         - generate a configuration file
  showconfig         - show which configuration files were loaded
  edit               - lock, then edit a file
  db [subcommand]    - operation on the dependency database
  build [subcommand] - manage the build database and builds

Use "help [maincommand] for further details.
""",
        "configuration":"""

Many options that can be given on the command line can be taken from
configuration files. 

File format
-----------
A configuration file is always in JSON  format. Each key is the long name of a
command line option, each value is either a string or a list of strings.

Merging
-------
Sumo can read several configuration files, in this case the data is *merged*.

Merging means that keys are not yet defined are simply added. For keys that
already exist and whose values are strings, the latter one overwrites the first
one.  For keys that already exist and whose values are lists, the lists are
simply concatenated.

Default paths
-------------
Sumo reads and merges configuration files from various places, which one
depends on your environment variable settings and command line options. 

First the program tries to read the file sumo.config from a list of default
paths. The list of default paths can be set by the environment variable
ENV_CONFIG which must be a colon (on Unix systems) or semicolon (on Windows
systems) separated list of paths. 

If ENV_CONFIG is not set, these are the predefined default paths:

- /etc
- [python-libdir]/sumolib
- $HOME
- your current working directory

If you use the "--no-default-config" command line option, the list of default
paths is made empty.

The config option
-----------------

After the configuration files from default paths were read the program reads
the all configuration files specified by the "-c" or "--config" option.

""",
        "makeconfig":"""
makeconfig [FILENAME] {OPTIONNAMES}

Create a new configuration file from the options read from configuration files
and options from the command line. If FILENAME is '-' dump to the console. 
OPTIONNAMES is an optional list of long option names. If OPTIONNAMES are 
specified, only options from this list are saved in the configuration file.
""",
        "showconfig":"""
showconfig {FILENAME}

Show all the configuration files that were loaded.
""",
        "edit": """
edit [FILE]

Start the editor specified by the environment variable "VISUAL" or "EDITOR"
with that file. This command first aquires a file-lock on the file that is only
released when the editor program is terminated.  If you want to edit a DB or
BUILDDB file directly, you should always do it with this with this command. The
file locking prevents other users to use the file at the same time you modify
it.
""",
        "db": """

db [subcommand]

Query or modify the dependency database (DB) file. These are the known
subcommands here:

  convert      - convert a scanfile created by sumo-scan to a DB file
  convert-old  - convert a DB file from old to new format (legacy)
  appconvert   - convert a scanfile to a MODULES file for an application
  weight       - set the weight factor for modules
  list         - list modules
  shownewest   - show newest module versions
  showall      - show all modules
  filter       - show parts of the DB file
  find         - search for modules with a regexp
  check        - consistency check of the DB file
  merge        - merge two DB files
  cloneversion - create a new DB entry by copying an old one
  replaceversion - 
                 replace a DB entry with a new one
  clonemodule  - add a module under a new name in the DB file

Use "help [subcommand] for further details.
""",
        "build": """

build [subcommand]

Manage the build database (BUILDDB) and create or delete builds. These are the
known subcommands:

  try       - check the module specification for completeness and consistency
  new       - create a new build
  find      - look for builds that match a module specification
  useall    - use all modules of a build in your application
  use       . use all modules or your module specification in your application
  list      - list names of all builds
  show      - show details of a build
  state     - show or change the state of a build
  delete    - delete a build
  cleanup   - clean up remains of build whose checkout command failed
""",
        "list":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db list' enter 'help db list'
For help on 'build list' enter 'help build list'
""",
        "find":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db find' enter 'help db find'
For help on 'build find' enter 'help build find'
""",

        "convert":"""
convert [SCANFILE]: 

Convert SCANFILE created by "sumo-scan all" to a new dependency database. If
SCANFILE is a dash "-" the program expects the scanfile on stdin.  Note that
options "--db" and "--scandb" are mandatory here. With "--db" you specify the
name of the new created dependency database file, with "--scandb" you specify
the name of the scan database file.  The scan database file contains
information on what moduleversion can be used with what dependency version.
""",
        "convert-old": """
convert-old [OLD-DEPS-DB]

Convert a dependency database from the old to the new format. Note that options
"--db" and "--scandb" are mandatory here. With "--db" you specify the name of
the new created dependency database file, with "--scandb" you specify the name
of the scan database or SCANDB file. The scan database file contains
information on what version of a module is probably compatible with what
version of a dependency according to the data in the old dependency database.
""",
        "appconvert": """
appconvert [SCANFILE] 

Convert a SCANFILE that was created by applying sumo-scan to an application to
a list of aliases and modulespecs in JSON format. The result is printed to the
console. It can be used with --config to put these in the configuration file of
sumo.
""",
        "weight": """
weight [WEIGHT] [modules]

Set the weight factor for modules. Use modulename:{+-}versionname to select
more versions of a module.  This command *does not* use the --modules option.
Weight must be an integer.
""",
        "db list": """
list

list the names of all modules
""",
        "shownewest": """
shownewest {MODULES}

Show newest version for each module. If {modules} is missing, take all modules
of the database.
""",
        "showall": """
showall {MODULES}

Show all versions for each module. If {modules} is missing, take all modules of
the database.
""",
        "filter": """
filter [MODULES]

Print the database for the given modules. If you want a specific version of a
module use modulename:versioname instead of the modulename alone.
""",
        "db find": """
find [REGEXP]

Show all modules whose names or sources match regexp.
""",
        "check": """
check 

do some consistency checks on the db specifed by --db
""",
        "merge": """
merge [DB]

Merge the given db with the one specified by --db
""",
        "cloneversion": """
cloneversion [MODULE] [OLD-VERSION] [NEW-VERSION] {SOURCESPEC}

Add a new version to the database by copying the old version. The old-version
data is copied for the new version data. If sourcespec is given, the command
changes the source part according to this parameter. A sourcespec has the form
"path PATH", "tar TARFILE", "REPOTYPE URL" or "REPOTYPE URL TAG". REPOTYPE may
be "darcs", "hg" or "git". Both, URL or TAG may be "*", in this case the
original URL or TAG remain unchanged. If sourcespec is not given, the command
adds NEW-VERSION as new tag to the source specification. The command always
asks for a confirmation of the action unless option "-y" is used.
""",
        "replaceversion": """
replaceversion [MODULE] [OLD-VERSION] [NEW-VERSION] {SOURCESPEC}

Replace a version to the database with a new one. The old-version data is
copied for the new version data. If sourcespec is given, the command changes
the source part according to this parameter. A sourcespec has the form "path
PATH", "tar TARFILE", "REPOTYPE URL" or "REPOTYPE URL TAG". REPOTYPE may be
"darcs", "hg" or "git". Both, URL or TAG may be "*", in this case the original
URL or TAG remains unchanged.
""",
        "clonemodule": """
clonemodule [OLD-MODULE] [NEW-MODULE] {VERSIONS}

Copy all versions of the existing old module and add this with the name of thew
new module to the dependency database. If there are no versions specified, the
command copies all existing versions. Note that this DOES NOT add the new
module as dependency to any other modules.
""",
        "try": """
try [MODULES]

This command helps to create module specifications for the "new" command.  You
can specify an incomplete list of modules, modules without versions or with
version ranges.  The program then shows which modules you have to include in
your list since other modules depend on them and shows information on all
versions of all modules that satisfy your module specifications. It also shows
if your module specifications are *complete* and *exact* meaning that all
dependencies are included and all modules are specified with exactly a single
version. Note that you can use option "--scandb" in order to give additional
information which versions of modules are compatible with each other. Options
"--db" and "--builddb" are mandatory for this command.
""",
        "new": """
new [MODULES]

This command creates a new build. If the buildtag is not given as an option,
the program generates a buildtag in the form "AUTO-nnn". Note that options
"--db" and "--builddb" are mandatory for this command. A new build is created
according to the modulespecs. Your modulespecifications must be *complete* and
*exact* meaning that all dependencies are included and all modules are
specified with exactly a single version. Use command "try" in order to create
module specifications that can be used with command "new".  This command calls
"make" and, after successful completion, sets the state of the build to
"testing". If you want to skip this step, use option "--no-make". In order to
provide arbitrary options to make use option "--makeopts".
""",
        "build find": """
find [MODULESPECS]

This command is used to find matching builds for a given list of modulespecs.
It prints a list of buildtags of matching builds on the console.  Note that the
versions in modulespecs may be *unspecified*, *specified exactly* or *specifed
by relation*. If option --brief is given, the program just shows the buildtags.
""",
        "useall": """
useall [BUILDTAG]

This command creates a configure/RELEASE file for an application. The command
must be followed by buildtag. The release file created includes *all* modules
of the build. The buildtag may be given as argument or option. Output to
another file or the console can be specified with option '-o'.
""",
        "use": """
use [MODULES]

This command creates a configure/RELEASE file for an application. The command
must be followed by a list of modulespecs. If option --buildtag is given, it
checks if this is compatible with the given modules. Otherwise it looks for all
builds that have the modules in the required versions. If more than one
matching build found it takes the one with the alphabetically first buildtag.
Note that the modulespecs MUST specify versions exactly. If you have
unspecified versions or versions specified by relation you must use command
"use" instead. The RELEASE created includes only the modules that are
specified. For this command the DB file must be specified with the "--db"
option. Output to another file or the console can be specified with option
'-o'.
""",
        "build list": """
list    

This command lists the names of all builds.
""",
        "show": """
show [BUILDTAG]

This command shows the data of a build. The buildtag may be given as argument
or option.
""",
        "state": """
state {BUILDTAG} {NEW STATE}

This command is used to show or change the state of a build. The buildtag may
be given as argument or option.If there is no new state given, it just shows
the current state of the build. Otherwise the state of the build is changed to
the given value. 
""",
        "delete": """
delete {BUILDTAG}

If no other build depends on the build specified by the buildtag, the
directories of the build are removed and it's entry in the builddb is deleted.
The buildtag may be given as argument or option.
""",
        "cleanup": """
cleanup {BUILDTAG}

This command removes the remains of a failed build. If the command "new" is
interrupted or stopped by an exception in the program, the build may be in an
incomplete state. In this case you can use the "cleanup" command to remove the
directories of the failed build. The buildtag may be given as argument or
option.
"""
}

def helptext(topics):
    """return helptext.
    """
    # pylint: disable=R0911
    #                          Too many return statements
    if not topics:
        return help_topics[""]
    lc_topics= [s.lower().strip() for s in topics]
    if len(lc_topics)>3:
        return "help should be followed by one or two words"
    if len(lc_topics)==1:
        txt= help_topics[lc_topics[0]]
        if txt is not None:
            return txt
        return "help not found for '%s'" % (" ".join(topics))
    # two words given
    if lc_topics[0] not in help_maincommands:
        return "no known maincommand '%s'" % topics[0]
    txt= help_topics.get(" ".join(lc_topics))
    if txt is not None:
        return txt
    txt= help_topics.get(lc_topics[1])
    if txt is not None:
        return txt
    return "no known subcommand '%s'" % topics[1]

me= script_shortname()
usage = """usage: %s maincommand [subcommand] [options]

Enter '%s help' for help on commands,
      '%s -h' for help on options
""" % (me,me,me)

def main():
    """The main function.

    parse the command-line options and perform the command
    """
    # command-line options and command-line help:

    parser = OptionParser(usage=usage,
                          version="%%prog %s" % __version__,
                          description="This program manages EPICS support trees"
                         )

    parser.add_option("--summary",
                      action="store_true",
                      help="Print a summary of the function of the program.",
                      )
    parser.add_option("--test",
                      action="store_true",
                      help="Perform simple self-test.",
                      )
    parser.add_option("-c", "--config",
                      action="append",
                      type="string",
                      help="Load options from the given configuration "
                           "file. You can specify more than one of "
                           "these.  Unless --no-default-config is given, "
                           "the program always loads configuration files "
                           "from several standard directories first "
                           "before it loads your configuration file. The "
                           "contents of all configuration files are "
                           "merged. ",
                      metavar="CONFIGFILE"
                      )
    parser.add_option("--no-default-config",
                      action="store_true",
                      help="If this option is given the program doesn't load "
                           "the default configuration.",
                      )
    parser.add_option("--mergeoption",
                      action="append",
                      type="string",
                      help= "If an option with name OPTIONNAME is given "
                            "here and it is a list option, the lists from "
                            "the config file and the command line are "
                            "merged. The new list is the sum of both lists "
                            "where it is ensured that for all elements the "
                            "string up to the first colon \":\" is unique "
                            "(this is usefule for module specifications "
                            "that have the form \"module:version\").",
                      metavar="OPTIONNAME"
                      )
    parser.add_option("--#include",
                      action="append",
                      type="string",
                      help="Specify a an '#include' directive in the "
                           "configuration file.  This option has only a "
                           "meaning if a configuration file is created with "
                           "the 'makeconfig' command. '#include' means that "
                           "the following file(s) are included before the "
                           "rest of the configuration file. ",
                      metavar="INCLUDEFILES"
                      )
    parser.add_option("--db",
                      action="store",
                      type="string",
                      help= "Define the name of the DB file. This option "
                            "value is stored in the configuration file. ",
                      metavar="DB"
                      )
    parser.add_option("--builddb",
                      action="store",
                      type="string",
                      help= "Specify the BUILDDB file. This option value is "
                            "stored in the configuration file. ",
                      metavar="BUILDDB"
                      )
    parser.add_option("--scandb",
                      action="store",
                      type="string",
                      help= "Specify the (optional) SCANDB file. The scan "
                            "database file contains information on what "
                            "moduleversion can be used with what "
                            "dependency version.",
                      metavar="SCANDB"
                      )
    parser.add_option("--dumpdb",
                      action="store_true",
                      help="Dump the db on the console, currently "
                           "only for these commands : %s." % \
                           (" ".join(("weight","merge",
                                      "clonemodule",
                                      "cloneversion", "replaceversion")))
                      )
    parser.add_option("-t", "--buildtag",
                      action="store",
                      type="string",
                      help= "Specify a buildtag",
                      metavar="BUILDTAG"
                      )
    parser.add_option("--buildtag-stem",
                      action="store",
                      type="string",
                      help= "Specify the stem of a buildtag. This option "
                            "has only an effect on the commands 'new' and "
                            "'try' if a buildtag is not specified. The "
                            "program generates a new tag in the "
                            "form 'stem-nnn' where 'nnn' is the smallest "
                            "possible number that ensures that the buildtag "
                            "is unique.",
                      metavar="STEM"
                      )
    parser.add_option("--supportdir",
                      action="store",
                      type="string",
                      help= "Specify the support directory. If this option "
                            "is not given take the current working directory "
                            "as support directory.  This option value is "
                            "stored in the configuration file. ",
                      metavar="SUPPORTDIR"
                      )
    parser.add_option("-o", "--output",
                      action="store",
                      type="string",
                      help= "Define the output for commands 'useall' and "
                            "'use'. If this option is not given, 'useall' "
                            "and 'use' write to 'configure/RELEASE'. If "
                            "this option is '-', the commands write to "
                            "standard-out",
                      metavar="OUTPUTFILE",
                      )
    parser.add_option("-x", "--extra",
                      action="append",
                      type="string",
                      help= "Specify an extra line that is added to the "
                            "generated RELEASE file. This option value is "
                            "stored in the configuration file. ",
                      metavar="EXTRALINE"
                      )
    parser.add_option("-a", "--alias",
                      action="append",
                      type="string",
                      help= "Define an alias for the commands 'use' and "
                            "'useall'. An alias must have the form FROM:TO. "
                            "The path of module named 'FROM' is put in the "
                            "generated RELEASE file as a variable named "
                            "'TO'. You can specify more than one of these by "
                            "repeating this option or by joining values in a "
                            "single string separated by spaces. This option "
                            "value is stored in the configuration file. ",
                      metavar="ALIAS"
                      )
    parser.add_option("--arch",
                      action="append",
                      help="Define the name of a TARGETARCHITECTURE. You "
                           "can specify more than one target architecture."
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the "
                           "configuration file.",
                      metavar="TARGETARCHITECTURE"
                      )
    parser.add_option("-m", "--module",
                      action="append",
                      help= "Define a modulespec. If you specify modules "
                            "with this option you don't have to put "
                            "modulespecs after some of the commands.  You "
                            "can specify more than one of these by repeating "
                            "this option or by joining values in a single "
                            "string separated by spaces.  This option value "
                            "is stored in the configuration file. ",
                      metavar="MODULESPEC"
                      )
    parser.add_option("-X", "--exclude-states",
                      action="append",
                      type="string",
                      help="For command 'try' exclude all 'dependents' whose "
                           "state does match one of the regular expressions "
                           "(REGEXP).",
                      metavar="REGEXP"
                      )
    parser.add_option("-b", "--brief",
                      action="store_true",
                      help="Create a more brief output for some commands. ",
                      )
    parser.add_option("-P", "--source-patch",
                      action="append",
                      help="Specify a source PATCHEXPRESSION. Such an "
                           "expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "url generated. You can specify more than one "
                           "PATCHEXPRESSION. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="PATCHEXPRESSION"
                      )
    parser.add_option("--noignorecase",
                      action="store_true",
                      help="For command 'find', do NOT ignore case.",
                      )
    parser.add_option("--no-checkout",
                      action="store_true",
                      help="With this option, \"new\" does not check out "
                           "sources of support modules. This option is "
                           "only here for test purposes.",
                      )
    parser.add_option("--no-make",
                      action="store_true",
                      help="With this option, \"new\" does not call "
                           "\"make\".",
                      )
    parser.add_option("--makeopts",
                      action="append",
                      type="string",
                      help="Specify extra option strings for \"make\""
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the "
                           "configuration file.",
                      )
    parser.add_option("--readonly",
                      action="store_true",
                      help="Do not allow modifying the database files or "
                           "the support directory. "
                           "This option value is stored in the "
                           "configuration file.",
                      )
    parser.add_option("--nolock",
                      action="store_true",
                      help="Do not use file locking."
                      )
    parser.add_option("-p", "--progress",
                      action="store_true",
                      help= "Show progress on stderr. This option value is "
                            "stored in the configuration file. "
                      )
    parser.add_option("--trace",
                      action="store_true",
                      help="Switch on some trace messages.",
                      )
    parser.add_option("--tracemore",
                      action="store_true",
                      help="Switch on even more trace messages.",
                      )
    parser.add_option("--dump-modules",
                      action="store_true",
                      help="Dump module specs, then stop the program.",
                      )
    parser.add_option("-y", "--yes",
                      action="store_true",
                      help="All questions the program may ask are treated "
                           "as if the user replied 'yes'.",
                      )
    parser.add_option("-v", "--verbose",
                      action="store_true",
                      help="Show command calls. This option value is stored "
                           "in the configuration file.",
                      )
    parser.add_option("-n", "--dry-run",
                      action="store_true",
                      help="Just show what the program would do.",
                      )

    # x= sys.argv
    (options, args) = parser.parse_args()
    # options: the options-object
    # args: list of left-over args

    # join some of the list options:
    options.arch       = sumolib.utils.opt_join(options.arch, do_sort= True)
    options.alias      = sumolib.utils.opt_join(options.alias, do_sort= True)
    options.module     = sumolib.utils.opt_join(options.module)
    options.makeopts   = sumolib.utils.opt_join(options.makeopts)
    options.mergeoption= sumolib.utils.opt_join(options.mergeoption)

    if options.summary:
        print_summary()
        sys.exit(0)

    if options.test:
        _test()
        sys.exit(0)

    # we could pass "args" as an additional parameter to process here if it
    # would be needed to process remaining command line arguments.
    process(options, args)
    sys.exit(0)

if __name__ == "__main__":
    main()

