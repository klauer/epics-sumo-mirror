#! /usr/bin/env python
# -*- coding: UTF-8 -*-

# pylint: disable=C0111
#                          Missing docstring
# pylint: disable=C0301
#                          Line too long
# pylint: enable=C0301

# pylint: disable=C0103
#                          Invalid name ... for type module
# pylint: disable=C0322
#                          Operator not preceded by a space

from optparse import OptionParser
import sys
import os.path
import os
import re
import errno
import shutil
import glob
import textwrap

import sumolib.system
import sumolib.lock
import sumolib.JSON
import sumolib.utils
import sumolib.Config
import sumolib.ModuleSpec
import sumolib.Dependencies
import sumolib.Builds
import sumolib.repos

# version of the program:
__version__= "2.4.1" #VERSION#

assert __version__==sumolib.system.__version__
assert __version__==sumolib.lock.__version__
assert __version__==sumolib.JSON.__version__
assert __version__==sumolib.utils.__version__
assert __version__==sumolib.Config.__version__
assert __version__==sumolib.ModuleSpec.__version__
assert __version__==sumolib.Dependencies.__version__
assert __version__==sumolib.Builds.__version__
assert __version__==sumolib.repos.__version__

KNOWN_MAIN_COMMANDS=set(("help","lock","unlock","edit","makeconfig",
                         "showconfig", "db","build"))

KNOWN_DB_COMMANDS=set(("alias-add", "appconvert", "check", "clonemodule",
                       "cloneversion", "convert",
                       "filter", "find", "format",
                       "list", "merge", "dependency-add",
                       "dependency-delete", "replaceversion", "show",
                       "weight"))

KNOWN_BUILD_COMMANDS=set(("cleanup", "delete", "find", "list",
                          "new",
                          "show", "state", "try", "use", "useall"))
KNOWN_FILE_COMMANDS=set(("lock", "unlock", "edit"))

CONFIG_NAME="sumo.config"
ENV_CONFIG="SUMOCONFIG"
BUILDDB="BUILDS.DB"

catch_exceptions= True

# -----------------------------------------------
# utilities
# -----------------------------------------------

def script_shortname():
    """return the name of this script without a path component."""
    return os.path.basename(sys.argv[0])

rx_exept= re.compile(r'^(Error|error|Err|err)[:, ] *')

def errtxt(msg, e):
    """Create an error message from an exception."""
    e_txt= rx_exept.sub("", str(e))
    return "%s\n%s" % (msg, e_txt)

# -----------------------------------------------
# directory utilities and filenames
# -----------------------------------------------

def makefilename(builddir, build_tag):
    """create a makefile name from a build_tag."""
    return os.path.join(builddir, "Makefile-%s" % build_tag)

def module_dir(builddir, buildtag, modulename, versionname):
    """return the complete path to the module.

    If buildtag is "" or None, return just the base directory for all versions
    and builds of the module.
    """
    if not buildtag:
        return os.path.join(builddir, modulename)
    else:
        return os.path.join(builddir, modulename,
                            "%s+%s" % (versionname, buildtag))

def get_builddir(path, path_local):
    """return the build directory that is actually used for new builds."""
    if not path_local:
        return path
    return path_local

def builddb_f(path, path_local):
    """return the filename(s) of the builddb file(s).

    path_local, if given, is the name of the local build directory.

    Return:
    (<build db filename>, <overlay build db filename>)
    """
    if not path_local:
        return (os.path.join(path, BUILDDB), None)
    else:
        return (os.path.join(path_local, BUILDDB),
                os.path.join(path, BUILDDB))

def builddb_localtag(tag):
    """return a "local" marked buildtag."""
    return "local-%s" % tag

def builddb_generate_tag(builddb, buildtag_stem, has_localbuilddir):
    """automatically generate a build tag."""
    if not buildtag_stem:
        buildtag_stem= "AUTO"
    if has_localbuilddir:
        buildtag_stem= builddb_localtag(buildtag_stem)
    return builddb.generate_buildtag(buildtag_stem)

def ensure_dir(dir_, dry_run):
    """create a dir if it doesn't already exist.
    """
    if not dry_run:
        if not os.path.exists(dir_):
            os.makedirs(dir_)

def rm_empty_dir(dirname, verbose, dry_run):
    """remove a directory.

    If the directory is not empty, return without an error message.
    """
    if verbose:
        print "remove dir %s if it is empty" % dirname
    if dry_run:
        return
    try:
        os.rmdir(dirname)
    except OSError, ex:
        if ex.errno == errno.ENOTEMPTY:
            pass

def _assume_dir(dir_, dry_run):
    """ensure that a directory exists."""
    if not dry_run:
        if not os.path.exists(dir_):
            sys.exit("Error, directory 'configure' not found")

# -----------------------------------------------
# load JSON files
# -----------------------------------------------

def repo_msg(prefix, args):
    """generate a standard commit message."""
    return "%s %s" % (prefix, " ".join(args))

def repo_manager(filename, sourcespec_string, mode,
                 verbose, dry_run):
    """create a ManagedRepo object.

    sourcespec_string specifies a repo like:
      darcs <darcs-url>
      hg <mercurial-url>
    """
    if not sourcespec_string:
        return sumolib.repos.ManagedRepo(None,None,None,verbose,dry_run)
    if not mode:
        mode= 'get'
    source_spec_obj= \
        sumolib.repos.SourceSpec.from_string_sourcespec(\
                                          sourcespec_string.split())
    (dir_,_)= os.path.split(filename)
    return sumolib.repos.ManagedRepo(source_spec_obj,
                                     mode,
                                     dir_, verbose, dry_run)

def db_from_json_file(filename, keep_locked= False):
    """load a db, exits gracefully in case of an error."""
    try:
        db= sumolib.Dependencies.DB.from_json_file(filename,
                                                   keep_locked)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading dependency database", e))
    except IOError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading dependency database", e))
    return db

def db_from_repo(options, keep_locked= False, changes_check= True):
    """load a db, exits gracefully in case of an error."""
    # pylint: disable=R0913
    #                          Too many arguments
    mngr= repo_manager(options.db, options.dbrepo, options.dbrepomode,
                       options.verbose, options.dry_run)
    if mngr.local_changes():
        if not changes_check:
            print "Uncommitted changes found in dependency database file"
        else:
            if not sumolib.utils.ask_yes_no(
                    "Uncommitted changes found in dependency database file,\n"
                    "answer 'y' to record them or 'n' to abort",
                    options.yes):
                sys.exit(0)
            # an empty logmessage here means that the user is asked for one:
            mngr.commit(options.logmsg)

    try:
        mngr.prepare_read() # executes a "pull" command
    except IOError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading dependency database",e))
    db= db_from_json_file(options.db, keep_locked)
    return (mngr, db)

def db_to_repo(options, mngr, db, command, arguments):
    """save a db and use the repo mngr."""
    # pylint: disable=R0913
    #                          Too many arguments
    try:
        db.json_save(options.db, options.verbose, options.dry_run)
    except IOError, e:
        # IOError may happen when the file cannot be locked
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while saving dependency database",e))
    if mngr:
        if options.logmsg:
            msg= options.logmsg
        else:
            msg= repo_msg(command, arguments)
        mngr.finish_write(msg)

def builddb_from_json_file(path, path_local, keep_locked= False,
                           must_exist= True):
    """load a builddb, exits gracefully in case of an error.

    Note: this function only gets the path(s) where the build db file can be
    found, not the filename itself.

    If local_path is given, a *local* build db is created that is merged with
    the build db from <path>.
    """
    # pylint: disable=R0912
    #                          Too many branches
    (file_, overlay_file)= builddb_f(path, path_local)

    if not os.path.exists(file_):
        if must_exist:
            sys.exit("Error build database '%s' doesn't exist" % \
                     file_)
        # just create an empty object:
        builddb= sumolib.Builds.DB_overlay()
        # set default filename in the object (JSON.Container method):
        builddb.filename(file_)
    else:
        try:
            builddb= sumolib.Builds.DB_overlay.from_json_file(\
                                    file_, keep_locked)
        except ValueError, e:
            if not catch_exceptions:
                raise
            sys.exit(errtxt("Error while loading build database",e))
        except IOError, e:
            if not catch_exceptions:
                raise
            sys.exit(errtxt("Error while loading build database",e))
    if not overlay_file:
        return builddb
    try:
        builddb.overlay(overlay_file)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading overlay build database",e))
    except IOError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading overlay build database",e))
    return builddb

def assert_build_tag(builddb, buildtag):
    """check if the tag exists in builddb.

    does sys.exit on error.
    """
    if not builddb.has_build_tag(buildtag):
        sys.exit("error: buildtag '%s' not found" % buildtag)

def init_buildcache(scandb_name, builddb, db):
    """load a builddb, exits gracefully in case of an error."""
    if not scandb_name:
        buildcache= sumolib.Builds.BuildCache()
    else:
        try:
            buildcache= sumolib.Builds.BuildCache.from_json_file(scandb_name,
                                                                 False)
        except ValueError, e:
            sys.exit(errtxt("Error while loading build database",e))
            if not catch_exceptions:
                raise
        except IOError, e:
            if not catch_exceptions:
                raise
            sys.exit(errtxt("Error while loading build database",e))
    buildcache.update_from_builddb(builddb, db)
    return buildcache

# -----------------------------------------------
# aliases
# -----------------------------------------------

def scan_aliases(aliases):
    """scan aliases given on the command line."""
    d= {}
    if not aliases:
        return d
    for a in aliases:
        (from_, to)= a.split(":")
        d[from_]= to
    return d

def alias(alias_dict, modulename):
    """return a module alias."""
    n= alias_dict.get(modulename)
    if n is None:
        return modulename
    return n

# -----------------------------------------------
# cleanup file handling
# -----------------------------------------------

def cleanupfilename(build_tag, dir_):
    """create the name of the cleanup file."""
    return os.path.join(dir_,"cleanup-%s" % build_tag)

def rmcleanup(build_tag, dir_):
    """remove the cleanup file."""
    fn= cleanupfilename(build_tag, dir_)
    if os.path.exists(fn):
        return os.remove(fn)

def loadcleanup(build_tag, dir_, must_exist= False):
    """load the cleanup file."""
    fn= cleanupfilename(build_tag, dir_)
    if os.path.exists(fn):
        return sumolib.JSON.loadfile(fn)
    if must_exist:
        raise IOError("file '%s' not found" % fn)
    return {"modules": [] }

def savecleanup(build_tag, dir_, struc):
    """save the cleanup file."""
    fn= cleanupfilename(build_tag, dir_)
    sumolib.JSON.dump_file(fn, struc)

def listcleanup(dir_):
    """list cleanup buildtags of existing cleanup files."""
    files= glob.glob(os.path.join(dir_,"cleanup-*"))
    if not files:
        return
    return [os.path.basename(s).replace("cleanup-","") for s in files]

# -----------------------------------------------
# error messages
# -----------------------------------------------

def errmsg(msg):
    """print something on stderr."""
    sys.stderr.write(msg+"\n")

# -----------------------------------------------
# module utilities
# -----------------------------------------------

def dump_modules(modulespecs):
    """dump module specs.
    """
    for modulespec in modulespecs:
        print modulespec.to_string()

# -----------------------------------------------
# dependency handling
# -----------------------------------------------

def gather_dependencies(dist_dict, db, modulename, versionname,
                        gathered_deps):
    """recursively gather all dependencies of a module.

    For dependencies, do only take moduleversions that are in dist_dict.

    Returns a dict mapping modulenames to versionnames

    called by builddb_match, command "new"
    """
    if gathered_deps is None:
        gathered_deps= {}
    for dep_name in db.iter_dependencies(modulename, versionname):
        dep_version= dist_dict[dep_name]
        gathered_deps[dep_name]= dep_version
        gathered_deps= gather_dependencies(dist_dict, db, dep_name,
                                           dep_version, gathered_deps)
    return gathered_deps

def _add_dependencies(module_dict, db, build_module_dict,
                      modulename, versionname):
    """recursively add missing dependencies.

    called by get_dependencies, command "use"
    """
    try:
        db.assert_module(modulename, versionname)
    except KeyError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error in dependency database", e))
    for dep in db.iter_dependencies(modulename, versionname):
        if module_dict.has_key(dep):
            continue
        version_present= build_module_dict[dep]
        module_dict[dep]= version_present
        _add_dependencies(module_dict, db, build_module_dict,
                          dep, version_present)

def get_dependencies(module_dict, db, builddb, buildtag):
    """recursively complete the module_dict for missing dependencies.

    called by apprelease, command "use"
    """
    build_module_dict= builddb.modules(buildtag)
    modules= module_dict.items()
    for modulename, versionname in modules:
        _add_dependencies(module_dict, db,
                          build_module_dict, modulename, versionname)

def builddb_match(dist_dict, db, builddb, modulename, versionname):
    """try to find matching deps in builddb.

    called by add_modules, command "new"
    """
    deps= gather_dependencies(dist_dict, db, modulename, versionname, None)
    # now deps is a dict mapping modulenames to versionnames that contains all
    # direct and indirect dependencies of modulename:versionname that was
    # given to this function.
    for build_tag in builddb.iter_builds():
        # try to find modules that were already built, ignore builds that are
        # not marked "stable" or testing.
        # This also means that builds marked "disabled" are ignored.
        if not builddb.is_testing_or_stable(build_tag):
            continue
        if not builddb.has_module(build_tag, modulename):
            continue
        if builddb.module_link(build_tag, modulename):
            # if this build has only a link of the module, skip it
            continue
        modules= builddb.modules(build_tag)
        if modules[modulename]!=versionname:
            # version doesn't match
            continue

        # from here: check if all dependencies match:
        match= True
        for dep_name, dep_ver in deps.items():
            other= modules.get(dep_name)
            if dep_ver!= other:
                match= False
                break
        if match:
            return build_tag
    return

# -----------------------------------------------
# file generation
# -----------------------------------------------

def gen_RELEASE(db, builddb, buildtag,
                dist_dict,
                modulename, versionname,
                module_directory,
                extra_lines,
                verbose, dry_run):
    """generate a RELEASE file.

    Note: the SUPPORT path is the directory of the builddb file!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_module, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    filename= os.path.join(module_directory, "configure", "RELEASE")
    deps= []

    for dep_name in db.iter_dependencies(modulename, versionname):
        dep_versionname= dist_dict[dep_name]
        deps.append((dep_name, dep_versionname))

    deps= db.sortby_weight(db.sortby_dependency(sorted(deps), True))

    if not deps:
        # if sumo doesn't know of any dependencies, don't touch
        # configure/RELEASE.
        return

    if verbose:
        print "creating %s" % filename
    fh= sumolib.utils.file_w_open(filename, verbose, dry_run)

    sumolib.utils.file_write(fh, "# generated by sumo for build %s\n\n" % \
                             buildtag,
                             verbose, dry_run)

    for (dep_name, dep_versionname) in deps:
        name_here= db.get_alias(modulename, versionname, dep_name)
        buildtag_here= builddb.module_link(buildtag, dep_name)
        if buildtag_here is None:
            buildtag_here= buildtag
        b_dir= builddb.dirname_from_tag(buildtag_here)
        path= module_dir(b_dir, buildtag_here, dep_name, dep_versionname)
        sumolib.utils.file_write(fh, "%s=%s\n" % (name_here,path),
                                 verbose, dry_run)
    for l in extra_lines:
        sumolib.utils.file_write(fh, "%s\n" % l.rstrip(), verbose, dry_run)
    if not dry_run:
        fh.close()

def create_makefile(dist_dict, db, builddb,
                    build_tag,
                    verbose, dry_run):
    """generate a makefile.

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_modules, command "new"
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0913
    #                          Too many arguments
    def has_makefile(path):
        """checks if there is a makefile in path."""
        fn= os.path.join(path,"Makefile")
        if os.path.exists(fn):
            return True
        fn= os.path.join(path,"makefile")
        if os.path.exists(fn):
            return True
        return False
    paths= {}
    builddir= builddb.dirname()
    for modulename, versionname in builddb.iter_modules(build_tag):
        if not builddb.module_link(build_tag, modulename):
            if not has_makefile(module_dir(builddir, build_tag,
                                           modulename, versionname)):
                continue
            # create relative directories in makefiles:
            paths[(modulename, versionname)]= module_dir("", build_tag,
                                                         modulename,
                                                         versionname)
    filename= makefilename(builddir, build_tag)
    if not dry_run:
        cleanup_struc= loadcleanup(build_tag, builddir)
        cleanup_struc["makefile"]= filename
        ensure_dir(builddir, dry_run)
        savecleanup(build_tag, builddir, cleanup_struc)
    module_dirs= sorted(paths.values())
    stamps= [os.path.join(p,"stamp") for p in module_dirs]
    fh= sumolib.utils.file_w_open(filename, verbose, dry_run)
    sumolib.utils.file_write(fh, "all: %s\n\n" % (" ".join(stamps)),
                             verbose, dry_run)
    sumolib.utils.file_write(fh, "clean:\n", verbose, dry_run)
    for d in module_dirs:
        sumolib.utils.file_write(fh, "\t-$(MAKE) -C %s clean\n" % d,
                                 verbose, dry_run)
    for f in stamps:
        sumolib.utils.file_write(fh, "\trm -f %s\n" % f, verbose, dry_run)
    sumolib.utils.file_write(fh, "\n", verbose, dry_run)
    for spec, path in paths.items():
        (modulename, versionname)= spec
        own_stamp= os.path.join(path, "stamp")
        dep_stamps= []
        for dep_name in db.iter_dependencies(modulename, versionname):
            if builddb.module_link(build_tag, dep_name):
                continue
            dep_version= dist_dict[dep_name]
            # do no handle dependencies that are not in the paths
            # dictionary:
            if not paths.has_key((dep_name, dep_version)):
                continue
            # use relative paths for dependencies:
            dep_path= module_dir("", build_tag, dep_name, dep_version)
            dep_stamps.append(os.path.join(dep_path,"stamp"))

        dep_stamps.sort()
        if dep_stamps:
            sumolib.utils.file_write(fh,\
                        "\n%s: %s\n" % (own_stamp, " ".join(dep_stamps)),\
                        verbose, dry_run)
    sumolib.utils.file_write(fh, "\n%/stamp:\n", verbose, dry_run)
    sumolib.utils.file_write(fh, "\t$(MAKE) -C $(@D)\n", verbose, dry_run)
    sumolib.utils.file_write(fh, "\ttouch $@\n", verbose, dry_run)
    if not dry_run:
        fh.close()

# -----------------------------------------------
# module creation/deletion
# -----------------------------------------------

def create_source(db, modulename, versionname,
                  destdir, verbose, dry_run):
    """create directory by given source spec.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    sourcespec= sumolib.repos.SourceSpec(db.module_source_dict(modulename,
                                                               versionname))
    sumolib.repos.checkout(sourcespec,
                           destdir,
                           verbose, dry_run)

def delete_module(builddir, build_tag, modulename, versionname,
                  must_exist,
                  verbose, dry_run):
    """delete a single module."""
    # pylint: disable=R0913
    #                          Too many arguments
    dirname= module_dir(builddir, build_tag, modulename, versionname)
    if verbose:
        print "removing %s" % dirname
    if not dry_run:
        if os.path.exists(dirname):
            shutil.rmtree(dirname)
        else:
            if must_exist:
                raise IOError("error: '%s' doesn't exist" % dirname)
        # remove the parent directory if it is empty:
    rm_empty_dir(modulename, verbose, dry_run)

def create_module(db, builddb, build_tag,
                  dist_dict,
                  modulename, versionname,
                  extra_defs,
                  archs,
                  verbose, dry_run):
    """check out a module.

    returns the build_tag that was used. If the module was found in another
    build, return that built-tag.

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_modules, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    if not db.check_archs(modulename, versionname, archs):
        sys.stderr.write("error: archs %s\nnot supportted by "
                         "module %s:%s\n" % \
                         (repr(archs), modulename, versionname))
    basedir= module_dir(builddb.dirname(), "", modulename, "")
    ensure_dir(basedir, dry_run) # creates basedir if it doesn't exist
    dirname= module_dir(builddb.dirname(), build_tag, modulename, versionname)
    if os.path.exists(dirname):
        raise ValueError("directory %s already exists" % dirname)

    create_source(db, modulename, versionname, dirname, verbose, dry_run)
    gen_RELEASE(db, builddb, build_tag,
                dist_dict,
                modulename, versionname,
                dirname,
                extra_defs,
                verbose, dry_run)

# -----------------------------------------------
# builddb utilities
# -----------------------------------------------

_builddb= [None]
def mspecs_from_build(options):
    """generate a function to return module specs from a build."""
    def mspecs(buildtag):
        """return module specs for a buildtag."""
        if _builddb[0] is None:
            if not options.builddir:
                raise AssertionError("--builddir is needed for modulespecs")
            _builddb[0]= builddb_from_json_file(options.builddir,
                                                options.localbuilddir,
                                                keep_locked= False,
                                                must_exist= False)
        return _builddb[0].module_specs(buildtag)
    return mspecs

def add_modules(dist_dict, db, builddb, build_tag):
    """add modules to the builddb object.

    This function looks for compatible modules in all already existing builds.
    If possible, modules of existing builds are used.

    All modules specified by dist_dict are added with tag <build_tag> to the
    builddb.

    called by create_modules, command "new"
    """
    for modulename in sorted(dist_dict.keys()):
        versionname= dist_dict[modulename]

        # try to find a build that already has the module and where all it's
        # dependencies are also present with the same version as in dist_dict:
        compatible_build= builddb_match(dist_dict, db, builddb, modulename,
                                        versionname)
        if compatible_build is None:
            # no existing build of the module was found, we have to build the
            # module ourselbves:
            build_tag_used= build_tag
        else:
            # a compatible existing build of the module was found:
            build_tag_used= compatible_build

        builddb.add_module(build_tag, build_tag_used, modulename, versionname)

# -----------------------------------------------
# further db functions
# -----------------------------------------------

def create_app_data(deps, repoinfo, groups):
    """create configuration data for an app."""
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    keys= deps.keys()
    if len(keys)!=1:
        sys.exit("error: \"dependencies\" map must have exactly one key")

    modulespecs= []
    aliases    = []

    app_path= keys[0]
    specs_by_path= {}

    for module_name, groupdata in groups.items():
        keys= groupdata.keys()
        if len(keys)!=1:
            sys.exit("error: groupdata \"%s\" must have exactly one key" % \
                     module_name)
        root_path= keys[0]
        values= groupdata[root_path]
        if len(values)!=1:
            sys.exit("error: groudata \"%s\" must have exactly one "
                     "subdir" % module_name)
        subdir= values[0]
        versionedmodule_path= os.path.join(root_path, subdir)
        try:
            r_dict= repoinfo.get(versionedmodule_path)
        except KeyError, _:
            # shouldn't happen, but we just print a warning in this
            # case:
            errmsg("no source data: %s" % versionedmodule_path)
            continue

        sourcespec_obj= sumolib.repos.SourceSpec(r_dict)
        if sourcespec_obj.sourcetype()=="path":
            versionname= "PATH-%s" % subdir
        elif sourcespec_obj.sourcetype()=="tar":
            versionname= "TAR-%s" % subdir
        elif sourcespec_obj.is_repo():
            tag= sourcespec_obj.tag()
            if tag is None:
                versionname= "TAGLESS-%s" % subdir
            else:
                versionname= tag
        else:
            raise AssertionError("unsupported sourcetype: %s" % \
                                 sourcespec_obj.sourcetype())
        specs_by_path[versionedmodule_path]= (module_name,versionname)

    for (aliasname, path) in deps[app_path].items():
        (module_name,versionname)= specs_by_path[path]
        modulespecs.append("%s:%s" % (module_name,versionname))
        if aliasname!=module_name:
            aliases.append("%s:%s" % (module_name, aliasname))
    aliases.sort()
    modulespecs.sort()

    return {"alias": aliases, "module": modulespecs}


def create_database(deps, repoinfo, groups, archs, dir_patches, url_patches):
    """join the information of the three sources.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0913
    #                          Too many arguments
    dir_patcher= sumolib.utils.RegexpPatcher()
    url_patcher= sumolib.utils.RegexpPatcher()
    if url_patches:
        for p in url_patches:
            # pylint: disable=W0123
            #                          Use of eval
            url_patcher.add(eval(p))
    if dir_patches:
        for p in dir_patches:
            # pylint: disable=W0123
            #                          Use of eval
            dir_patcher.add(eval(p))
    _path2namevname= {}
    _namevname2path= {}
    db= sumolib.Dependencies.DB()
    # we first create the map from modulenames to versiondata. In this loop we
    # populate the versiondata only with the source specification. We also
    # create two maps:
    #    _path2namevname: maps a diretory path to (module_name, versionname)
    #    _namevname2path: maps (module_name,versionname) to a diretory path
    for module_name, groupdata in groups.items():
        # the root directory of all the versions:
        for root_path, subdirs in groupdata.items():
            for subdir in sorted(subdirs):
                # iterate over all versions from <groups>:
                # reconstruct the original directory path:
                versionedmodule_path= os.path.join(root_path, subdir)
                # get the repository data:
                try:
                    r_dict= repoinfo.get(versionedmodule_path)
                except KeyError, _:
                    # shouldn't happen, but we just print a warning in this
                    # case:
                    errmsg("no source data: %s" % versionedmodule_path)
                    continue

                src_sourcespec= sumolib.repos.SourceSpec(r_dict)
                if src_sourcespec.sourcetype()=="path":
                    # the source is a directory path, not a repository. We
                    # generate the unique versionname:
                    if subdir.startswith("PATH-"):
                        # Try to handle a subdir that was created by this set
                        # of tools. Such a subdir may already be named
                        # "PATH-<name>+<treetag>". We want to take <name> as
                        # versionname in this case:
                        versionname= sumolib.utils.split_treetag(subdir)[0]
                    else:
                        versionname= "PATH-%s" % subdir
                    # repodata is just the path in this case:
                    src_sourcespec.path(dir_patcher.apply(\
                                            src_sourcespec.path()))
                elif src_sourcespec.sourcetype()=="tar":
                    # the source is a tar file, not a repository. We
                    # generate the unique versionname:
                    if subdir.startswith("TAR-"):
                        # Try to handle a subdir that was created by this set
                        # of tools. Such a subdir may already be named
                        # "TAR-<name>+<treetag>". We want to take <name> as
                        # versionname in this case:
                        versionname= sumolib.utils.split_treetag(subdir)[0]
                    else:
                        versionname= "TAR-%s" % subdir
                    # we apply not the dir_patched to the path of the tar file
                    # here.
                elif src_sourcespec.is_repo():
                    tag= src_sourcespec.tag()

                    if tag is None:
                        # the source is a repository but has no tag. We
                        # generate a unique versionname:
                        if subdir.startswith("TAGLESS-"):
                            # Try to handle a subdir that was created by this
                            # set of tools. Such a subdir may already be named
                            # "PATH-<name>+<treetag>". We want to take <name>
                            # as versionname in this case:
                            versionname= sumolib.utils.split_treetag(subdir)[0]
                        else:
                            versionname= "TAGLESS-%s" % subdir
                        # patch URL to <versionedmodule_path>. Since we do not
                        # know in what state the working copy repository is, we
                        # have to take this as a source instead of the central
                        # repository:
                    else:
                        # the source is a darcs repository with a tag. We use
                        # the tag as unique versionname:
                        versionname= tag
                    src_sourcespec.url(url_patcher.apply(\
                                           src_sourcespec.url()))
                else:
                    raise AssertionError("unsupported sourcetype: %s" % \
                                         src_sourcespec.sourcetype())

                module_archs= archs.get(versionedmodule_path, [])
                if not module_archs:
                    #  module_archs list is empty:
                    errmsg("no archs for path %s" % \
                           versionedmodule_path)
                db.set_source_arch(module_name, versionname,
                                   module_archs,
                                   src_sourcespec)

                _path2namevname[versionedmodule_path]= \
                        (module_name,versionname)
                # when we assume that a versionedmodule_path may contain a
                # buildtag, there may be several versionedmodule_paths for a
                # pair of (module_name, versionname).
                _paths= _namevname2path.setdefault(\
                                    (module_name, versionname),[])
                _paths.append(versionedmodule_path)

    #sumolib.JSON.dump(_path2namevname)
    #sys.exit(0)

    buildcache= sumolib.Builds.BuildCache()

    # here we populate the versiondata with the dependency specifications:
    for modulename in db.iter_modulenames():
        # loop on stable, testing and unstable versions:
        for versionname in db.iter_versions(modulename,
                                            None, False):
            versionedmodule_paths= _namevname2path[(modulename, versionname)]

            for versionedmodule_path in versionedmodule_paths:
                _deps= deps.get(versionedmodule_path)
                if _deps is None:
                    errmsg("no dependency info for path %s" % \
                           versionedmodule_path)
                    continue
                for dep_alias, dep_path in _deps.items():
                    try:
                        (_dep_name, _dep_version)= _path2namevname[dep_path]
                    except KeyError, _:
                        if not catch_exceptions:
                            raise
                        sys.exit(("at module %s version %s "+ \
                                  "path %s: "+ \
                                  "missing data for "+ \
                                  "dependency \"%s\"") % \
                                  (modulename, versionname,
                                   versionedmodule_path,
                                   dep_path))
                    if _dep_name != dep_alias:
                        try:
                            db.add_alias(modulename, versionname,
                                         dep_alias, _dep_name)
                        except ValueError, e:
                            errmsg("alias error in module %s: %s" % \
                                   (modulename, str(e)))
                    db.add_dependency(modulename, versionname,
                                      _dep_name)
                    buildcache.add_dependency(modulename, versionname,
                                              _dep_name, _dep_version,
                                              "scanned")
    return (buildcache,db)

def set_weight(db, weight, modulespecs, trace):
    """set the weight for one or more modules."""
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if trace:
            sys.stderr.write("%s\n" % modulespec.to_string())

        # scan stable, testing and unstable versions:
        for version in db.iter_versions(modulename,
                                        None, must_exist= False):
            if trace:
                sys.stderr.write("test %s:%s\n" % (modulename,version))
            if not modulespec.test(version):
                continue
            if trace:
                sys.stderr.write("set weight %d on %s:%s\n" % \
                                 (weight,modulename,version))
            db.weight(modulename, version, weight)

# -----------------------------------------------
# further builddb functions
# -----------------------------------------------

def delete_modules(builddb, build_tag, verbose, dry_run):
    """delete modules of a build.
    """
    dependends= builddb.linked_builds(build_tag)
    if dependends:
        raise ValueError("Error, the following builds dependend on "
                         "build %s:\n%s" % \
                         (build_tag," ".join(sorted(dependends))))
    for modulename, versionname in builddb.iter_modules(build_tag):
        if builddb.module_link(build_tag, modulename):
            continue
        delete_module(builddb.dirname(), build_tag, modulename, versionname,
                      True, verbose, dry_run)

    os.remove(makefilename(builddb.dirname(), build_tag))

    builddb.delete(build_tag)

def cleanup_modules(builddir, build_tag, verbose, dry_run):
    """cleanup remains of a failed build.

    This can only happen if a "new" command was aborted due to an exception in
    the script.
    """
    try:
        cleanup_struc= loadcleanup(build_tag, builddir, must_exist= True)
    except IOError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    module_list= cleanup_struc["modules"]
    for module_dict in module_list:
        delete_module(builddir,
                      build_tag,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      False,
                      verbose, dry_run)
    makefile= cleanup_struc.get("makefile")
    if makefile:
        if os.path.exists(makefile):
            os.remove(makefile)
    if not dry_run:
        rmcleanup(build_tag, builddir)

def create_modules(dist_dict, db, builddb, builddir, build_tag,
                   extra_lines,
                   archs,
                   no_checkout,
                   verbose, dry_run):
    """create all modules.

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by process, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # save a list of possibly created directories in a cleanup-structure. In
    # case the script exits with an exception, the created cleanup file can be
    # used to clean up the support directory.
    # Load the cleanup file in case other parts of the script have saved
    # someting there:
    cleanup_struc= loadcleanup(build_tag, builddir)
    module_list  = cleanup_struc.setdefault("modules", [])

    # add all modules specified by dist_dict to builddb under tag build_tag:
    add_modules(dist_dict, db, builddb, build_tag)

    if builddb.is_fully_linked(build_tag):
        # the new build would contain only links, this is maybe not wanted.
        sys.stderr.write("Note: The generated build '%s' consists only of "
                         "links.\n" % build_tag)

    for modulename in sorted(dist_dict.keys()):
        versionname= builddb.module_version(build_tag, modulename)
        # do not re-create modules that are links:
        if builddb.module_link(build_tag, modulename):
            continue
        # module_list contains only the modules that are NOT links:
        module_list.append({"modulename" : modulename,
                            "versionname": versionname})

    if not dry_run and not no_checkout:
        ensure_dir(builddir, dry_run)
        savecleanup(build_tag, builddir, cleanup_struc)
    if no_checkout:
        return
    for module_dict in module_list:
        create_module(db, builddb, build_tag,
                      dist_dict,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      extra_lines,
                      archs,
                      verbose, dry_run)

def call_make(buildtag, options):
    """call "make", then mark the build "testing"."""
    # pylint: disable=R0913
    #                          Too many arguments
    if options.makeopts is None:
        options.makeopts=[]
    builddir= get_builddir(options.builddir, options.localbuilddir)
    cmd="make %s -C %s -f %s" % (" ".join(options.makeopts),
                                 builddir,
                                 makefilename(builddir, buildtag))
    try:
        # sys.stderr.write("CALLING MAKE: %s\n" % cmd)
        sumolib.system.system(cmd, False, False,
                              options.verbose, options.dry_run)
    except IOError, e:
        if not catch_exceptions:
            raise
        sys.exit("Error: make failed, %s" % str(e))

    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= not options.dry_run)
    builddb.change_state(buildtag, "testing")
    builddb.json_save(None, options.verbose, options.dry_run)
    # ^^^ does also unlock the file

def fullapprelease(build_tag, builddb, db, modules,
                   aliases, extra_lines):
    """create entries for an release file.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    lines= ["# generated by sumo using build %s:\n" % build_tag]
    if modules is None:
        modules= builddb.modules(build_tag).keys()

    directories= {}
    mods= []
    for modulename in modules:
        tag= builddb.module_link(build_tag, modulename)
        if tag is None:
            tag= build_tag
        version= builddb.module_version(tag, modulename)
        directories[(modulename, version)]= \
                   module_dir(builddb.dirname(), tag, modulename, version)
        mods.append((modulename, version))

    mods= db.sortby_weight(db.sortby_dependency(sorted(mods), True))
    for (modulename, version) in mods:
        lines.append("%s=%s\n" % \
                (alias(aliases, modulename),
                 directories[(modulename, version)]
                ))
    for l in extra_lines:
        lines.append("%s\n" % l)
    return lines

def apprelease(build_tag, modulespecs, builddb, db,
               aliases, extra_lines):
    """create entries for an release file.

    used in command "use".
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if build_tag is None:
            # unspecifed build_tag, all versions must be *exactly specified*:
            if not modulespec.is_exact_spec():
                sys.exit("modulespec '%s' is not an exactly "
                         "specified version" % modulespec.to_string())

    if build_tag is None:
        # must look for a matching build:
        new_builddb= builddb.filter_by_modulespecs(modulespecs, db)
        if new_builddb.is_empty():
            sys.exit("no build found that matches modulespecs")
        # take only builds that are "testing" or "stable":
        tags= [b for b in new_builddb.iter_builds() \
                 if builddb.is_testing_or_stable(b)]
        if not tags:
            sys.exit("no build with state 'stable' or 'testing' found that "
                     "matches modulespecs")
        build_tag= tags[0]
        sys.stderr.write("using build %s\n" % build_tag)


    build_modules= builddb.modules(build_tag)
    module_dict= {}
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        v= build_modules.get(modulename)
        if v is None:
            sys.exit("error: module %s not found in build %s" % \
                     (modulename, build_tag))
        if not modulespec.test(v):
            sys.exit("error: no module matching %s "
                     "found in build %s" % \
                     (modulespec.to_string(), build_tag))
        module_dict[modulename]= v
    get_dependencies(module_dict, db, builddb, build_tag)
    return fullapprelease(build_tag, builddb, db,
                          module_dict.keys(), aliases, extra_lines)

# -----------------------------------------------
# command implementation
# -----------------------------------------------

def db_convert(arguments, options):
    """implement "db convert"."""
    args= get_command_args(arguments, ["SCANFILE"])
    assert_mandatory_options(options, "db", "scandb")
    if os.path.exists(options.db):
        sys.exit("error, db file '%s' already exists" % options.db)
    if os.path.exists(options.scandb):
        sys.exit("error, scandb file '%s' already exists" % \
                 options.scandb)
    scandata= sumolib.JSON.loadfile(args["SCANFILE"])
    deps= scandata["dependencies"]
    repoinfo= scandata["repos"]
    groups= scandata["groups"]
    archs= scandata["archs"]
    (buildcache, db)= create_database(deps, repoinfo, groups, archs,
                                      options.dir_patch,
                                      options.url_patch)
    mngr= repo_manager(options.db, options.dbrepo, options.dbrepomode,
                       options.verbose, options.dry_run)
    mngr.prepare_read() # does a "pull"
    db_to_repo(options, mngr, db, "convert", arguments)
    buildcache.json_save(options.scandb,
                         options.verbose, options.dry_run)

def db_appconvert(arguments):
    """implement "db appconvert"."""
    args= get_command_args(arguments, ["SCANFILE"])
    scandata= sumolib.JSON.loadfile(args["SCANFILE"])
    deps= scandata["dependencies"]
    repoinfo= scandata["repos"]
    groups= scandata["groups"]
    struc= create_app_data(deps, repoinfo, groups)
    sumolib.JSON.dump(struc)

def db_format(arguments, options):
    """implement "db format."""
    assert_mandatory_options(options, "db")
    get_command_args(arguments)
    (mngr, db)= db_from_repo(options, keep_locked= True, changes_check= False)
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "merge", arguments)
        # ^^^ does also unlock the file

def db_weight(arguments, options):
    """implement "db weight"."""
    args= get_command_args(arguments, ["WEIGHT"],
                           extra_mandatory= "MODULES")
    assert_mandatory_options(options, "db")
    try:
        weight= int(args["WEIGHT"])
    except ValueError, _:
        if not catch_exceptions:
            raise
        sys.exit("error: weight must be an integer")
    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(\
                                                        args["MODULES"],
                                                        None)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    set_weight(db, weight, modulespecs_obj, options.trace)
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "weight", arguments)
        # ^^^ does also unlock the file

def db_filter(arguments, options):
    """implement "db filter"."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db")
    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        if "module" in options.append:
            modulespecs.extend(args["MODULES"])
        else:
            modulespecs= args["MODULES"]
    if not modulespecs:
        sys.exit("error: module specs missing")

    (_, db)= db_from_repo(options)
    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,\
                                                        None, options.arch)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    db= db.partial_copy_by_modulespecs(modulespecs_obj)
    db.json_print()

def db_check(arguments, options):
    """implement "db check"."""
    assert_mandatory_options(options, "db")
    get_command_args(arguments)
    (_, db)= db_from_repo(options, keep_locked= False, changes_check= False)
    msg= db.check()
    print "\n".join(msg)

def db_merge(arguments, options):
    """implement "db merge"."""
    args= get_command_args(arguments, ["DB"])
    assert_mandatory_options(options, "db")
    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    db2= db_from_json_file(args["DB"], keep_locked= False)
    db.merge(db2)
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "merge", arguments)
        # ^^^ does also unlock the file

def db_alias_add(arguments, options):
    """implement "db alias_add"."""
    args= get_command_args(arguments,
                           ["MODULE","DEPENDENCY","ALIAS"])
    assert_mandatory_options(options, "db")
    module_spec= sumolib.ModuleSpec.Spec.from_string(args["MODULE"])
    try:
        module_spec.assert_exact()
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    db.add_alias(module_spec.modulename,
                 module_spec.versionname,
                 args["ALIAS"], args["DEPENDENCY"])
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "alias-add", arguments)
        # ^^^ does also unlock the file

def db_dependency_add(arguments, options):
    """implement "db dependency_add"."""
    args= get_command_args(arguments, ["MODULE","DEPENDENCY"])
    assert_mandatory_options(options, "db")
    module_spec= sumolib.ModuleSpec.Spec.from_string(args["MODULE"])
    try:
        module_spec.assert_exact()
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    db.add_dependency(module_spec.modulename,
                      module_spec.versionname,
                      args["DEPENDENCY"])
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "dependency-add", arguments)
        # ^^^ does also unlock the file

def db_dependency_delete(arguments, options):
    """implement "db dependency_delete"."""
    args= get_command_args(arguments, ["MODULE","DEPENDENCY"])
    assert_mandatory_options(options, "db")
    module_spec= sumolib.ModuleSpec.Spec.from_string(args["MODULE"])
    if module_spec.no_version_spec():
        sys.exit("module has no version")
    try:
        module_spec.assert_exact()
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    db.del_dependency(module_spec.modulename,
                      module_spec.versionname,
                      args["DEPENDENCY"])
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "dependency-delete", arguments)
        # ^^^ does also unlock the file

def db_clone_replace_version(command, arguments, options):
    """implement "db cloneversion/replaceversion"."""
    args= get_command_args(arguments,
                           ["MODULE","OLD-VERSION","NEW-VERSION"],
                           extra_optional="SOURCESPEC")
    assert_mandatory_options(options, "db")
    do_replace= (command=="replaceversion")
    modulename= args["MODULE"]
    sourcespec= args.get("SOURCESPEC")

    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    try:
        db.patch_version(modulename,
                         args["OLD-VERSION"], args["NEW-VERSION"],
                         do_replace)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if not sourcespec:
        # guess tag from versionname
        changed= db.set_source_spec_by_tag(modulename, args["NEW-VERSION"],
                                           args["NEW-VERSION"])
    else:
        try:
            source_spec_obj= \
                sumolib.repos.SourceSpec.from_string_sourcespec(sourcespec)
        except ValueError, e:
            if not catch_exceptions:
                raise
            sys.exit(errtxt("Error",e))
        changed= db.set_source_spec(modulename, args["NEW-VERSION"],
                                    source_spec_obj)
    print "Added module:"
    report_db= db.partial_copy_by_list([(modulename, args["NEW-VERSION"])])
    report_db.json_print()
    if not changed:
        print ("\nCAUTION: source specification of this module is "
               "identical with that of \n"
               "%s:%s, this is probably not what you want!") % \
               (modulename, args["OLD-VERSION"])
    sumolib.utils.ask_abort("Proceed ? ", options.yes)
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, command, arguments)
        # ^^^ does also unlock the file

def db_clonemodule(arguments, options):
    """implement "db clonemodule"."""
    args= get_command_args(arguments,
                           ["OLD-MODULE","NEW-MODULE"],
                           extra_optional="VERSIONS")
    assert_mandatory_options(options, "db")
    (mngr, db)= db_from_repo(options,
                             not options.dumpdb and (not options.dry_run))
    db.clonemodule(args["OLD-MODULE"], args["NEW-MODULE"],
                   args.get("VERSIONS"))
    if options.dumpdb:
        db.json_print()
    else:
        db_to_repo(options, mngr, db, "clonemodule", arguments)
        # ^^^ does also unlock the file

def db_list(arguments, options):
    """implement "db list"."""
    get_command_args(arguments)
    assert_mandatory_options(options, "db")
    (_, db)= db_from_repo(options)
    result= sorted(db.iter_modulenames())
    sumolib.JSON.dump(result)

def db_show(arguments, options):
    """implement "db show."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db")
    (_, db)= db_from_repo(options)

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        if "module" in options.append:
            modulespecs.extend(args["MODULES"])
        else:
            modulespecs= args["MODULES"]
    if not modulespecs:
        modulespecs= list(db.iter_modulenames())

    result= {}

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,\
                                                        None, options.arch)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    for modulespec in modulespecs_obj:
        modulename= modulespec.modulename

        versions= db.sorted_moduleversions(modulename,
                                           options.arch, False)
        if not versions: # no versions match criteria
            continue
        versions= [v for v in versions \
                   if modulespec.test(v)]

        result[modulename]= versions
    sumolib.JSON.dump(result)

def db_find(arguments, options):
    """implement "db find"."""
    args= get_command_args(arguments, ["REGEXP"])
    assert_mandatory_options(options, "db")
    (_, db)= db_from_repo(options)
    if options.noignorecase:
        rx_flags= 0
    else:
        rx_flags= re.IGNORECASE
    rx= re.compile(args["REGEXP"], rx_flags)
    results= db.search_modules(rx, options.arch)
    if options.brief:
        for (module,version) in results:
            print "%s:%s" % (module,version)
        return
    newdb= db.partial_copy_by_list(results)
    newdb.json_print()

def build_list(arguments, options):
    """implement "build_list"."""
    get_command_args(arguments)
    assert_mandatory_options(options, "builddir")
    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= False)
    for buildtag in builddb.iter_builds():
        print buildtag

def build_show(arguments, options):
    """implement "build_show"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    assert_mandatory_options(options, "builddir")
    if options.buildtag:
        sys.exit("error: you cannot use --buildtag here")

    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= False)
    assert_build_tag(builddb, args["BUILDTAG"])
    new_builddb= sumolib.Builds.DB()
    new_builddb.add_build(builddb, args["BUILDTAG"])
    new_builddb.json_print()

def build_state(arguments, options):
    """implement "build_state"."""
    args= get_command_args(arguments, ["BUILDTAG"],
                           optional_args=["NEW-STATE"])
    if options.buildtag:
        sys.exit("error: you cannot use --buildtag here")

    buildtag = args["BUILDTAG"]
    new_state= args.get("NEW-STATE")

    assert_mandatory_options(options, "builddir")
    if options.readonly:
        sys.exit("--readonly forbids changing the state of a build")

    if not new_state:
        builddb= builddb_from_json_file(options.builddir,
                                        options.localbuilddir,
                                        keep_locked= False)
        assert_build_tag(builddb, buildtag)
        print "%-20s : %s" % (buildtag,
                              builddb.state(buildtag))
    else:
        builddb= builddb_from_json_file(options.builddir,
                                        options.localbuilddir,
                                        keep_locked= False)
        assert_build_tag(builddb, buildtag)
        # if assert_build_tag does sys.exit,
        # builddb __del__ method should remove lockfiles
        if new_state!="disabled":
            builds=set((buildtag,))
        else:
            builds=set([b for b in builddb.rec_linked_builds(buildtag)\
                          if not builddb.tag_is_overlayed(b)])
            if builds:
                print "The following builds depend on build %s:" % buildtag
                print " ".join(sorted(builds))
                sumolib.utils.ask_abort("Disabling %s would also disable "
                                        "these.\nProceed ? " % buildtag,
                                        options.yes)
            builds.add(buildtag)

        try:
            for b in builds:
                builddb.change_state(b, new_state)
        except ValueError, e:
            # builddb __del__ method should remove lockfiles
            if not catch_exceptions:
                raise
            sys.exit(str(e))
        builddb.json_save(None, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def build_delete(arguments, options):
    """implement "build_delete"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    assert_mandatory_options(options, "builddir")
    if options.readonly:
        sys.exit("--readonly forbids deleting a support")

    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= not options.dry_run)
    assert_build_tag(builddb, args["BUILDTAG"])
    try:
        delete_modules(builddb, args["BUILDTAG"],
                       options.verbose, options.dry_run)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    builddb.json_save(None, options.verbose, options.dry_run)

def build_cleanup(arguments, options):
    """implement "build_cleanup"."""
    args= get_command_args(arguments, optional_args=["BUILDTAG"])
    assert_mandatory_options(options, "builddir")
    if options.readonly:
        sys.exit("--readonly forbids cleaning up")

    if args.has_key("BUILDTAG"):
        cleanup_modules(get_builddir(options.builddir, options.localbuilddir),
                        args["BUILDTAG"],
                        options.verbose, options.dry_run)
    else:
        l= listcleanup(get_builddir(options.builddir, options.localbuilddir))
        if not l:
            sys.exit("There are no unfinished builds with a cleanup file")
        print "Please provide the buildtag of the unfinished build,",
        print "these are possible candidates:"
        print " ".join(l)

def build_try(arguments, options):
    """implement "build_try"."""
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddir")

    buildtag= options.buildtag

    exclude_matcher= sumolib.utils.RegexpMatcher(options.exclude_states)

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        if "module" in options.append:
            modulespecs.extend(args["MODULES"])
        else:
            modulespecs= args["MODULES"]
    if not modulespecs:
        sys.exit("error: module specs missing")

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(\
                             modulespecs,
                             mspecs_from_build(options),
                             options.arch)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    (_, db)= db_from_repo(options)
    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= False,
                                    must_exist= False)

    buildcache= init_buildcache(options.scandb,
                                builddb, db)

    # ensure that each module is only mentioned once in the modulelist:
    try:
        modulespecs_obj.assert_unique()
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    # gather a list of all modules that don't have an exact specification:
    modules_not_exact_spec= \
        [spec.modulename for spec in modulespecs_obj \
                         if not spec.is_exact_spec()]

    # convert modulespecs to a set dict:
    # { modulename1 : set(version1,version2),
    #   modulename2 : set(version1,version2),
    # }
    try:
        sets_dict= db.sets_dict(modulespecs_obj)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    except KeyError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    # add all missing dependencies and complete the sets_dict:
    added_modules= db.complete_sets_dict(sets_dict)

    was_built= set()
    needed_by_others= {}

    # examine the builds:
    # was_built is a set of (modulename,versionname) or modules
    #           that were built
    # needed_by_others is a dict mapping
    #           (depname,dep_version)->[(modulename,versionname,state)...]
    #           where state is the build state of the build the modules
    #           share

    for modulename in sets_dict.keys():
        for versionname in sets_dict[modulename]:
            if buildcache.was_built(modulename,versionname):
                was_built.add((modulename,versionname))
            for depname in db.iter_dependencies(modulename, versionname):
                for dep_version in sets_dict[depname]:
                    s= needed_by_others.setdefault((depname,dep_version),
                                                   [])
                    s.append((modulename,versionname,
                              buildcache.relation(modulename,versionname,
                                                  depname, dep_version)))

    # now build the report structure:
    report= {}
    for modulename in sets_dict.keys():
        mdict= report.setdefault(modulename, {})
        no_of_versions= len(sets_dict[modulename])
        for versionname in sets_dict[modulename]:
            d= {}
            mdict[versionname]= d
            d["built"]= (modulename,versionname) in was_built
            l= needed_by_others.get((modulename,versionname))
            if l is not None:
                dd= d.setdefault("dependents", {})
                depmods_versioncount= {}
                for (m,v,state) in l:
                    depmods_versioncount.setdefault(m, 0)
                    if state is None:
                        state= "state: not tested"
                    else:
                        state= "state: %s" % state
                    if no_of_versions>1:
                        # do only apply the exclude_matcher when there is
                        # more than one possible version of module
                        # 'modulename':
                        if exclude_matcher.search(state):
                            continue
                    depmods_versioncount[m]+= 1
                    dd["%s:%s" % (m,v)]= state
                if min(depmods_versioncount.values())==0:
                    # all versions of a dependent were removed,
                    # remove modulename:versionname completely:
                    del mdict[versionname]
        if not mdict:
            sys.exit("error: your '--exclude-states' option removes "
                     "*ALL* versions of module '%s'. You may change "
                     "the REGEXP or specify an exact version "
                     "for the module to avoid this error." % \
                     modulename)

    if options.detail>0:
        wanted= set(modules_not_exact_spec)
        wanted.update(added_modules)
        if (options.detail==1) and wanted:
            print "Possible versions for unspecified/missing modules:\n"
            for m in sorted(wanted):
                l= ["%-19s" % m]
                l.extend(sorted(report[m].keys()))
                st= " ".join(l)
                print "\n".join(textwrap.wrap(st, width=70,
                                              subsequent_indent=" "*20))
            print
        elif (options.detail==2) and wanted:
            short_report= {}
            for (k,v) in report.items():
                if k in wanted:
                    short_report[k]= v
            report= short_report
            print "Details on unspecified/missing modules:\n"
            sumolib.JSON.dump(short_report)
        elif options.detail>=3:
            print "Details on all modules:\n"
            sumolib.JSON.dump(report)

    if modules_not_exact_spec:
        print "Not all modules have exactly specified versions.",
        print "These modules need an "
        print "exact version specification:"
        for m in sorted(modules_not_exact_spec):
            versions= report[m].keys()
            if len(versions)>1:
                print "    %s" % m
            else:
                print "    %-20s -> suggested version: %s" % \
                      (m,versions[0])
        print

    if added_modules:
        print "Not all dependencies were included in module",
        print "specifications, these modules"
        print "have to be added:\n   ",
        print "\n    ".join(sorted(added_modules))
        print

    if buildtag is None:
        buildtag= builddb_generate_tag(builddb, options.buildtag_stem,
                                       bool(options.localbuilddir))
        print "Command 'new' would create build with tag '%s'\n" % \
              buildtag

    if not modules_not_exact_spec and not added_modules:
        print "Your module specifications are complete. You can use",
        print "these with command"
        print "'new' to create a new build."
    else:
        print "Your module specifications are still incomplete,",
        print "command 'new' can not"
        print "be used with these."

def build_new(arguments, options):
    """implement "build_new"."""
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddir")
    if options.readonly:
        sys.exit("--readonly forbids creating a new build")

    buildtag= options.buildtag

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        if "module" in options.append:
            modulespecs.extend(args["MODULES"])
        else:
            modulespecs= args["MODULES"]
    if not modulespecs:
        sys.exit("error: module specs missing")

    (_, db)= db_from_repo(options)

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(\
                             modulespecs,
                             mspecs_from_build(options),
                             options.arch)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    try:
        dist_dict= modulespecs_obj.to_dist_dict()
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    try:
        db.assert_complete_modulelist(dist_dict)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= not options.dry_run,
                                    must_exist= False)

    if buildtag is None:
        buildtag= builddb_generate_tag(builddb, options.buildtag_stem,
                                       bool(options.localbuilddir))
        sys.stderr.write("creating build with tag '%s'\n" % buildtag)

    if builddb.has_build_tag(buildtag):
        # builddb __del__ method should remove lockfiles
        sys.exit("error: buildtag \"%s\" already taken" % buildtag)
    # create a new build in builddb, initial state is "unstable":
    builddb.new_build(buildtag, "unstable")
    # modifies builddb:
    try:
        create_modules(dist_dict, db, builddb,
                       get_builddir(options.builddir, options.localbuilddir),
                       buildtag,
                       options.extra, options.arch,
                       options.no_checkout,
                       options.verbose, options.dry_run)
        if not options.no_checkout:
            create_makefile(dist_dict, db,
                            builddb,
                            buildtag,
                            options.verbose,
                            options.dry_run)
    except IOError, e:
        db.unlock_file()
        builddb.unlock_file()
        raise

    builddb.json_save(None, options.verbose, options.dry_run)
    # ^^^ does also unlock the file
    rmcleanup(buildtag, get_builddir(options.builddir, options.localbuilddir))
    if not options.no_make and not options.no_checkout:
        # call_make will set the build state to "testing" if it succeeds:
        call_make(buildtag, options)

def build_find(arguments, options):
    """implement "build_find"."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddir")

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        if "module" in options.append:
            modulespecs.extend(args["MODULES"])
        else:
            modulespecs= args["MODULES"]
    if not modulespecs:
        sys.exit("error: module specs missing")

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(\
                             modulespecs,
                             mspecs_from_build(options),
                             options.arch)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    (_, db)= db_from_repo(options)
    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= False)

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    new_builddb= builddb.filter_by_modulespecs(modulespecs_obj, db)
    if new_builddb.is_empty():
        print "no matching buildtrees found"
    else:
        if options.brief:
            for buildtag in builddb.iter_builds():
                print buildtag
        else:
            new_builddb.json_print()

def build_useall(arguments, options):
    """implement "build_useall"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    assert_mandatory_options(options, "db", "builddir")
    output= options.output
    if not output:
        _assume_dir("configure", options.dry_run)
        output= os.path.join("configure","RELEASE")

    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= False)
    (_, db)= db_from_repo(options)
    lines= fullapprelease(args["BUILDTAG"],
                          builddb,
                          db,
                          None,
                          scan_aliases(options.alias),
                          options.extra)
    sumolib.utils.mk_text_file(output, lines,
                               options.verbose, options.dry_run)

def build_use(arguments, options):
    """implement "build_use"."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddir")

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        if "module" in options.append:
            modulespecs.extend(args["MODULES"])
        else:
            modulespecs= args["MODULES"]
    if not modulespecs:
        sys.exit("error: module specs missing")

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(\
                             modulespecs,
                             mspecs_from_build(options),
                             options.arch)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    output= options.output
    if not output:
        _assume_dir("configure", options.dry_run)
        output= os.path.join("configure","RELEASE")

    (_, db)= db_from_repo(options)
    builddb= builddb_from_json_file(options.builddir,
                                    options.localbuilddir,
                                    keep_locked= False)

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    lines= apprelease(options.buildtag,
                      modulespecs_obj,
                      builddb,
                      db,
                      scan_aliases(options.alias),
                      options.extra)
    sumolib.utils.mk_text_file(output, lines,
                               options.verbose, options.dry_run)

# -----------------------------------------------
# command processing
# -----------------------------------------------

def pr_list(iterable):
    """print for --list option."""
    l= [k for k in iterable if k] # remove empty strings
    print "\n".join(sorted(l))

def complete_command(commandlist):
    """try to return a completion for a commandlist."""
    # pylint: disable=R0911
    #                          Too many return statements
    if len(commandlist)==0:
        return list(KNOWN_MAIN_COMMANDS)
    if commandlist[0] in KNOWN_FILE_COMMANDS:
        if len(commandlist)>1:
            return glob.glob(commandlist[1]+"*")
        return glob.glob("*")
    if commandlist[0]=="db":
        if len(commandlist)==1:
            return list(KNOWN_DB_COMMANDS)
        return []
    if commandlist[0]=="build":
        if len(commandlist)==1:
            return list(KNOWN_BUILD_COMMANDS)
        return []
    return []

def assert_mandatory_options(options, *opt_list):
    """check for the presence of options."""
    for opt in opt_list:
        if not getattr(options, opt):
            sys.exit("--%s is mandatory here" % opt)

def get_command_args(lst, mandatory_args=None,
                     optional_args=None,
                     extra_mandatory= None,
                     extra_optional= None,
                     debug=False):
    """get a command.

    mandatory_args:
        A list of strings, each is a name of a mandatory argument. These
        arguments are stored under their given name in the result dictionary.
    optional_args:
        A list of strings, each is a name of an optional argument. These
        arguments are stored under their given name in the result dictionary.
    extra_mandatory:
        If given, extra arguments are required and all are stored under the
        given name as a single list.
    extra_optional:
        If given, extra arguments are allowed but not required and stored under
        the given name as a single list.

    Here are some examples:

    >>> import pprint
    >>>
    >>> p=pprint.pprint
    >>>
    >>> def test(*args, **kwargs):
          kwargs["debug"]= True
    ...   pprint.pprint(get_command_args(*args, **kwargs))
    ...
    >>> test(["read","t.txt","verbose"],["cmd","file"],["mode"])
    {'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read","t.txt"],["cmd","file"],["mode"])
    {'cmd': 'read', 'file': 't.txt'}
    >>> test(["read","t.txt","verbose","a1","a2"],["cmd","file"],["mode"])
    error, extra arguments follow: a1 a2
    None
    >>> test(["read","t.txt","verbose","a1","a2"],["cmd","file"],["mode"],
    ...      extra_mandatory="args")
    {'args': ['a1', 'a2'], 'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read","t.txt","verbose","a1","a2"],["cmd","file"],["mode"],
    ...      extra_optional="args")
    {'args': ['a1', 'a2'], 'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read","t.txt","verbose"],["cmd","file"],["mode"],
    ...      extra_mandatory="args")
    error, mandatory argument args missing
    None
    >>> test(["read","t.txt","verbose"],["cmd","file"],["mode"],
    ...      extra_optional="args")
    {'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read"],["cmd","file"],["mode"])
    error, mandatory argument missing: file
    None
    >>> test([],["cmd","file"],["mode"])
    error, mandatory arguments missing: cmd file
    None
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0912
    #                          Too many branches
    def ERR(msg):
        if debug:
            print msg
            return
        sys.exit(msg)
    result= {}
    if not mandatory_args:
        mandatory_args= []
    for i in xrange(len(mandatory_args)):
        try:
            result[mandatory_args[i]]= lst[i]
        except IndexError, _:
            missing= mandatory_args[i:]
            ch= "s" if len(missing)>1 else ""
            ERR("error, mandatory argument%s missing: %s" % \
                (ch, " ".join(missing)))
            return
    start= len(mandatory_args)
    if not optional_args:
        optional_args= []
    for i in xrange(len(optional_args)):
        try:
            result[optional_args[i]]= lst[i+start]
        except IndexError, _:
            break
    rest= lst[len(mandatory_args)+len(optional_args):]
    if not rest:
        if extra_mandatory:
            ERR("error, mandatory argument %s missing" % extra_mandatory)
            return
    else:
        if extra_mandatory:
            result[extra_mandatory]= rest
        elif extra_optional:
            result[extra_optional]= rest
        else:
            ch= "s" if len(rest)>1 else ""
            ERR("error, extra argument%s follow: %s" % \
                (ch, " ".join(rest)))
            return
    return result

def process_db(options, commands):
    """do all the work.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    if options.nolock:
        sumolib.lock.use_lockfile= False
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_DB_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if commands[0]=="convert":
        db_convert(commands[1:], options)
        return

    if commands[0]=="appconvert":
        db_appconvert(commands[1:])
        return

    if commands[0]=="format":
        db_format(commands[1:], options)
        return

    if commands[0]=="weight":
        db_weight(commands[1:], options)
        return

    if commands[0]=="filter":
        db_filter(commands[1:], options)
        return

    if commands[0]=="check":
        db_check(commands[1:], options)
        return

    if commands[0]=="merge":
        db_merge(commands[1:], options)
        return

    if commands[0]=="alias-add":
        db_alias_add(commands[1:], options)
        return

    if commands[0]=="dependency-add":
        db_dependency_add(commands[1:], options)
        return

    if commands[0]=="dependency-delete":
        db_dependency_delete(commands[1:], options)
        return

    if commands[0]=="cloneversion" or commands[0]=="replaceversion":
        db_clone_replace_version(commands[0], commands[1:], options)
        return

    if commands[0]=="clonemodule":
        db_clonemodule(commands[1:], options)
        return

    if commands[0]=="list":
        db_list(commands[1:], options)
        return

    if commands[0]=="show":
        db_show(commands[1:], options)
        return

    if commands[0]=="find":
        db_find(commands[1:], options)
        return

def process_build(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0914
    #                          Too many local variables
    if options.nolock:
        sumolib.lock.use_lockfile= False

    # make the build directories absolute:
    if options.builddir:
        options.builddir= os.path.abspath(options.builddir)
    if options.localbuilddir:
        options.localbuilddir= os.path.abspath(options.localbuilddir)

    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_BUILD_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if not options.extra:
        options.extra= []

    if commands[0]=="list":
        build_list(commands[1:], options)
        return

    if commands[0]=="show":
        build_show(commands[1:], options)
        return

    if commands[0]=="state":
        build_state(commands[1:], options)
        return

    if commands[0]=="delete":
        build_delete(commands[1:], options)
        return

    if commands[0]=="cleanup":
        build_cleanup(commands[1:], options)
        return

    if commands[0]=="try":
        build_try(commands[1:], options)
        return

    if commands[0]=="new":
        build_new(commands[1:], options)
        return

    if commands[0]=="find":
        build_find(commands[1:], options)
        return

    if commands[0]=="useall":
        build_useall(commands[1:], options)
        return

    if commands[0]=="use":
        build_use(commands[1:], options)
        return

def process(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0911
    #                          Too many return statements
    global catch_exceptions
    if options.exceptions:
        catch_exceptions= False
    if not commands:
        if options.list:
            pr_list(KNOWN_MAIN_COMMANDS)
        else:
            print "command missing\n"
            print usage
        return
    if commands[0]=="help":
        helptext(commands[1:], options.list)
        return

    if options.list:
        pr_list(complete_command(commands))
        return

    config_name= None
    if not options.no_default_config:
        config_name= CONFIG_NAME
    config= sumolib.Config.ConfigFile.from_optionlist(\
                config_name,
                ENV_CONFIG,
                ( "#preload","#opt-preload","#postload","#opt-postload",
                  "arch", "alias", "buildtag-stem",
                  "db", "dbrepo", "dbrepomode", "extra", "makeopts", "module",
                  "progress", "readonly", "scandb", "dir-patch", "url-patch",
                  "builddir", "localbuilddir", "verbose"))

    try:
        config.load(options.config)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading config file",e))
    except IOError, e:
        if not catch_exceptions:
            raise
        sys.exit(errtxt("Error while loading config file",e))
    try:
        config.merge_options(options, options.append)
    except ValueError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    except TypeError, e:
        if not catch_exceptions:
            raise
        sys.exit(str(e))
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_MAIN_COMMANDS:
        sys.exit("unknown maincommand '%s'" % commands[0])
    if commands[0]=="showconfig":
        print "These configuration files were loaded:"
        print "\n".join(config.real_paths())
        return
    if commands[0]=="makeconfig":
        if len(commands)<=1:
            sys.exit("filename for command \"makeconfig\" is missing")
        if options.module:
            try:
                modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(\
                                     options.module,
                                     mspecs_from_build(options),
                                     options.arch)
            except ValueError, e:
                if not catch_exceptions:
                    raise
                sys.exit(str(e))
            config.set("module", modulespecs_obj.to_stringlist())
        config.save(commands[1], commands[2:])
        return

    elif commands[0]=="lock":
        if options.readonly:
            sys.exit("--readonly forbids editing a database file")
        args= get_command_args(commands[1:], ["FILE"])
        l= sumolib.lock.MyLock(args["FILE"])
        try:
            l.lock()
        except IOError, e:
            if not catch_exceptions:
                raise
            if not l.was_locked:
                raise
            else:
                sys.exit(str(e))
        return
    elif commands[0]=="unlock":
        if options.readonly:
            sys.exit("--readonly forbids editing a database file")
        args= get_command_args(commands[1:], ["FILE"])
        l= sumolib.lock.MyLock(args["FILE"])
        try:
            l.lock()
        except IOError, e:
            if not l.was_locked:
                raise
        if not l.was_locked:
            l.unlock()
            sys.exit("error, cannot unlock '%s' since file wasn't locked" % \
                     args["FILE"])
        l.unlock(force= True)
        return
    elif commands[0]=="edit":
        if options.readonly:
            sys.exit("--readonly forbids editing a database file")
        args= get_command_args(commands[1:], ["FILE"])
        mngr= None
        if args["FILE"]==options.db:
            mngr= repo_manager(options.db, options.dbrepo, options.dbrepomode,
                               options.verbose, options.dry_run)
        try:
            sumolib.lock.edit_with_lock(args["FILE"],
                                        options.verbose, options.dry_run)
        except IOError, e:
            if not catch_exceptions:
                raise
            sys.exit(str(e))
        if mngr:
            mngr.finish_write("edit")
        return

    elif commands[0]=="db":
        process_db(options, commands[1:])
    elif commands[0]=="build":
        process_build(options, commands[1:])
    else:
        raise AssertionError("unexpected command: %s" % commands[0])
    return

def print_summary():
    """print a short summary of the scripts function."""
    print "%-20s: a tool for managing support EPICS trees \n" % \
          script_shortname()

def _test():
    """does a self-test of some functions defined here."""
    print "performing self test..."
    import doctest
    doctest.testmod()
    print "done!"

help_maincommands= set(("makeconfig", "edit", "db", "build"))

# pylint: disable=C0330
#                          Wrong indentation

help_topics= {
        "":"""
No help topic given. Use
  "help <topic>" to get help on a topic.

Possible topics are:

  maincommand                : explain what a maincommand is
  configuration              : how and where configuration data is stored
  <maincommand>              : help for a specific maincommand
  <maincommand> <subcommand> : help for a subcommand of a maincommand
  <subcommand>               : help for a subcommand
""",
        "maincommand":"""
A maincommand provides a grouping for the various commands of sumo.

While some maincommands can be used without a subcommand, others must be
followed by a subcommand. These are the known maincommands:

  makeconfig         - generate a configuration file
  showconfig         - show which configuration files were loaded
  edit               - lock, then edit a file
  lock               - just lock a file
  unlock             - unlock a file
  db [subcommand]    - operation on the dependency database
  build [subcommand] - manage the build database and builds

For all of the db subcommands you have to specify the dependency database with
option --db or a configuration file.

For all of the build subcommands you have to specify the dependency database
and the build database with --db and --builddb or a configuration file.

Use "help [maincommand] for further details.
""",
        "configuration":"""

The philosphy
-------------

In sumo you can always specify all parameters for a command with command line
options and arguments. Configuration files are files that have defaults for
command line options. 

All command line options start with a dash "-". Short command line options have
the form "-<char>", long command line options have the form "--<string>".

All command line options have a long form, some also have a short form.

Some command line options take no argument, some options require an argument.
Some command line options may be given more than once with an argument, they
are used to define lists of values.

The configuration file defines a map that maps keys to values, where keys are
the names of long command line options and values are booleans, strings or
lists or strings. Not all command line options can be set in a configuration
file, "sumo -h" shows you which can.

File format
-----------

A configuration file is always in JSON format. Each key is the long name of a
command line option, each value is a boolean, a string or a list of strings.

Here is an example of such a file:

  {
      "db": "/opt/Epics/sumo/database/DEPS.DB",
      "makeopts": [
          "-s"
      ],
      "builddir": "/opt/Epics/sumo/build"
  }

Merging
-------

Sumo can read several configuration files, in this case the data is *merged*.

Merging means that keys not yet defined are simply added. For keys that already
exist and whose values are strings, the latter one overwrites the first one.
For keys that already exist and whose values are lists, the lists are simply
concatenated.

Default paths
-------------

Sumo reads and merges configuration files from various places, which one
depends on your environment variable settings and command line options. 

First the program tries to read the file sumo.config from a list of default
paths. The list of default paths can be set by the environment variable
SUMOCONFIG which must be a colon (on Unix systems) or semicolon (on Windows
systems) separated list of paths. 

If SUMOCONFIG is not set, these are the predefined default paths:

- /etc
- [python-libdir]/sumolib
- $HOME
- your current working directory

If you use the "--no-default-config" command line option, the list of default
paths is made empty.

The config option
-----------------

After the configuration files from default paths were read the program reads
the all configuration files specified by the "-c" or "--config" option.

Loading other files
-------------------

In a configuration file you can specify names of other configuration files that
can or must be loaded. These files are merged as described above.

There are 4 special keys in the configuration file that are used to specify
other files:

#preload [file list]
  Load files *before* all other definitions

#opt-preload [file list]
  Load files *before* all other definitions, if they exist. 

#postload [file list]
  Load files *after* all other definitions

#opt-postload [file list]
  Load files *after* all other definitions, if they exist.

Note that the loaded files can also contain one or more these special keys.

The default filename for the sumo configuration file
----------------------------------------------------

The default filename of this file is sumo.config.

Keys in the sumo configuration file
+++++++++++++++++++++++++++++++++++

This is the list of keys that may be used in a configuration file, for the meanings of the keys see the sumo command line option documentation or use "sumo -h".

#preload       [list of strings]
#opt-preload   [list of strings]
#postload      [list of strings]
#opt-postload  [list of strings]
arch           [list of strings]
alias          [list of strings]
buildtag_stem  [string]
db             [string]
dbrepo         [string]
dbrepomode     [string]
extra          [list of strings]
makeopts       [list of strings]
module         [list of strings]
progress       [boolean]
readonly       [boolean]
scandb         [string]
dir_patch      [list of strings]
url_patch      [list of strings]
builddir       [string]
verbose        [boolean]
""",
        "makeconfig":"""
makeconfig FILENAME [OPTIONNAMES]

Create a new configuration file from the options read from configuration files
and options from the command line. If FILENAME is '-' dump to the console. 
OPTIONNAMES is an optional list of long option names. If OPTIONNAMES are 
specified, only options from this list are saved in the configuration file.
""",
        "showconfig":"""
showconfig {FILENAME}

Show all the configuration files that were loaded.
""",
        "lock": """
lock FILE

Lock a FILE, then exit sumo. This is useful if you want to read or write a
database file without sumo interfering. Don't forget to remove the lock later
with the "unlock" command.
""",
        "unlock": """
unlock FILE

Unlock a FILE, then exit sumo. If you locked a database with "lock" before you
should always unlock it later, otherwise sumo can't access the file.
""",
        "edit": """
edit FILE

Start the editor specified by the environment variable "VISUAL" or "EDITOR"
with that file. This command first aquires a file-lock on the file that is only
released when the editor program is terminated.  If you want to edit a DB or
BUILDDB file directly, you should always do it with this with this command. The
file locking prevents other users to use the file at the same time you modify
it.
""",
        "db": """

db [subcommand]

Query or modify the dependency database (DB) file. These are the known
subcommands here:

  convert      - convert a scanfile created by sumo-scan to a DB file
  appconvert   - convert a scanfile to a MODULES file for an application
  format       - reformat the dependency file
  weight       - set the weight factor for modules
  alias-add    - add an alias for a dependency in a module
  dependency-add - 
                 add a dependency to a module
  dependency-delete - 
                 delete a dependency of a module
  list         - list modules
  show         - show all modules
  filter       - show parts of the DB file
  find         - search for modules with a regexp
  check        - consistency check of the DB file
  merge        - merge two DB files
  cloneversion - create a new DB entry by copying an old one
  replaceversion - 
                 replace a DB entry with a new one
  clonemodule  - add a module under a new name in the DB file

Use "help [subcommand] for further details.
""",
        "build": """

build [subcommand]

Manage the build database (BUILDDB) and create or delete builds. These are the
known subcommands:

  try       - check the module specification for completeness and consistency
  new       - create a new build
  find      - look for builds that match a module specification
  useall    - use all modules of a build in your application
  use       - use all modules or your module specification in your application
  list      - list names of all builds
  show      - show details of a build
  state     - show or change the state of a build
  delete    - delete a build
  cleanup   - clean up remains of build whose checkout command failed
""",
        "list":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db list' enter 'help db list'
For help on 'build list' enter 'help build list'
""",
        "show":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db show' enter 'help db show'
For help on 'build show' enter 'help build show'
""",
        "find":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db find' enter 'help db find'
For help on 'build find' enter 'help build find'
""",

        "convert":"""
convert SCANFILE

Convert SCANFILE created by "sumo-scan all" to a new dependency database. If
SCANFILE is a dash "-" the program expects the scanfile on stdin.  Note that
options "--db" and "--scandb" are mandatory here. With "--db" you specify the
name of the new created dependency database file, with "--scandb" you specify
the name of the scan database file.  The scan database file contains
information on what moduleversion can be used with what dependency version.
""",
        "appconvert": """
appconvert SCANFILE 

Convert a SCANFILE that was created by applying sumo-scan to an application to
a list of aliases and modulespecs in JSON format. The result is printed to the
console. It can be used with --config to put these in the configuration file of
sumo.
""",
        "format": """
format

Just load and save the dependency database. This ensures that the file is
formatted in the standard sumo format. This is useful when the file was edited
and you want to ensure that key sort order and indentation are restored. If you
specified a repository with --dbrepo, the command will commit the changes. If
you want a log message different from "db format" use option --logmsg. 
""",
        "weight": """
weight WEIGHT MODULES

Set the weight factor for module. A weight determines where a module is placed
in the generated RELEASE file. Modules there are sorted first by weight, then
by dependency. Parameter MODULES is a list of modulespecs. Use
modulename:{+-}versionname to select more versions of a module.

Note that this command *does not* use the "--modules" option.

Parameter WEIGHT must be an integer.
""",
        "alias-add": """
alias-add MODULE DEPENDENCY ALIAS

Define a new alias for a dependency of a module. MODULE here is a modulespec of
the form MODULE:VERSION that specifies a single version of a module.
""",
        "dependency-delete": """
dependency-delete MODULE DEPENDENCY

Delete a dependency of a module. MODULE here is a modulespec of the form
MODULE:VERSION that specifies a single version of a module.
""",
        "dependency-add": """
dependency-add MODULE DEPENDENCY

Add a dependency to a module. MODULE here is a modulespec of the form
MODULE:VERSION that specifies a single version of a module.
""",
        "db list": """
list

list the names of all modules
""",
        "db show": """
show [MODULES]

This command shows all versions of the given modules. 

Optional parameter MODULES specifies the names of modules shown. If no modules
are given the command shows all versions of all modules.
""",
        "filter": """
filter MODULES...

This command prints only the parts of the dependency database that contain the
given modules. 

Parameter MODULES is a list of modulespecs MODULE:{+-}VERSION that specifies
the modules and versions to operate on. 
""",
        "db find": """
find REGEXP

Show all modules whose names or sources match regexp.
""",
        "check": """
check 

do some consistency checks on the db specifed by --db
""",
        "merge": """
merge DB

Merge the given db with the one specified by --db
""",
        "cloneversion": """
cloneversion MODULE OLD-VERSION NEW-VERSION [SOURCESPEC]

This command adds a new version of a module to the dependency database by
copying the old version. MODULE here is just the name of the module since the
version follows as a separate argument.  If sourcespec is given, the command
changes the source part according to this parameter. A sourcespec has the form
"path PATH", "tar TARFILE [PATCHES]", "REPOTYPE URL" or "REPOTYPE URL TAG
[PATCHES]". REPOTYPE may be "darcs", "hg" or "git". Both, URL or TAG may be
"*", in this case the original URL or TAG remain unchanged. PATCHES is a list
of patchfiles or URLs of patchfiles. If sourcespec is not given, the command
adds NEW-VERSION as new tag to the source specification. The command always
asks for a confirmation of the action unless option "-y" is used.

""",
        "replaceversion": """
replaceversion MODULE OLD-VERSION NEW-VERSION

This command replaces a version of a module with a new
version. MODULE here is just the name of the module since the version
follows as a separate argument. All the data of the module is copied.
If sourcespec is given, the command changes the source part according to this
parameter. A sourcespec has the form "path PATH", "tar TARFILE", "REPOTYPE URL"
or "REPOTYPE URL TAG".  REPOTYPE may be "darcs", "hg" or "git". Both, URL or
TAG may be "*", in this case the original URL or TAG remains unchanged.
""",
        "clonemodule": """
clonemodule OLD-MODULE NEW-MODULE [VERSIONS]

Copy all versions of the existing old module and add this with the name of thew
new module to the dependency database.  OLD-MODULE and NEW-MODULE here are just
the module names since the versions may follow as a separate argument. If there
are no versions specified, the command copies all existing versions. Note that
this DOES NOT add the new module as dependency to any other modules.
""",
        "try": """
try MODULES

This command is intended to help you create module specifications for the "new"
command. 

Each MODULE here is a modulespec of the form MODULE or MODULE:{+-}VERSION that
specifies just a module name, a module and some versions or a single version.
You can specify an incomplete list of modules.

The detail of the output is determined by option "--detail" which is an integer
between 0 and 3. 0, the default, gives the shortest, 3 gives the longest
report. The program then shows which modules you have to

In any case the command shows which modules are missing since they depend on
other modules of your specification and which ones are missing an exact
version.

If you converted an existing support directory to sumo you have a scan database
file which you can specify with option "--scandb" to this command.

For a detailed example see the try example in the HTML documentation.
""",
        "new": """
new MODULES

This command creates a new build. Each module given in MODULES here is
a modulespec of the form MODULE:VERSION that specifies a single version
of a module. If the buildtag is not given as an option, the program
generates a buildtag in the form "AUTO-nnn". A new build is
created according to the modulespecs. Your modulespecifications must be
*complete* and *exact* meaning that all dependencies are included and
all modules are specified with exactly a single version. Use
command "try" in order to create module specifications that can be used
with command "new".  This command calls "make" and, after successful
completion, sets the state of the build to "testing". If you want to
skip this step, use option "--no-make". In order to provide arbitrary options
to make use option "--makeopts". 
""",
        "build find": """
find MODULESPECS

This command is used to find matching builds for a given list of modulespecs.
Each module in MODULES here is a modulespec of the form MODULE or
MODULE:{+-}VERSION that specifies just a module name, a module and some
versions or a single version. The command prints a list of buildtags of
matching builds on the console. If option --brief is given, the program just
shows the buildtags. 

""",
        "useall": """
useall BUILDTAG

This command creates a configure/RELEASE file for an application. The command
must be followed by buildtag. The release file created includes *all* modules
of the build. The buildtag may be given as argument or option. Output to
another file or the console can be specified with option '-o'. 

""",
        "use": """
use MODULES

This command creates a configure/RELEASE file for an application. Each module
given in MODULES here is a modulespec of the form MODULE:VERSION that specifies
a single version of a module. If option --buildtag is given, it checks if this
is compatible with the given modules.  Otherwise it looks for all builds that
have the modules in the required versions. If more than one matching build
found it takes the one with the alphabetically first buildtag. The RELEASE file
created includes only the modules that are specified. Output to another file or
the console can be specified with option '-o'.
""",
        "build list": """
list    

This command lists the names of all builds.
""",
        "build show": """
show BUILDTAG

This command shows the data of a build. The buildtag must be given as an 
argument.
""",
        "state": """
state BUILDTAG [NEW-STATE]

This command is used to show or change the state of a build. The buildtag
must be given as an argument. If there is no new state given, it just shows
the current state of the build. Otherwise the state of the build is changed
to the given value. 
""",
        "delete": """
delete BUILDTAG

If no other build depends on the build specified by the buildtag, the
directories of the build are removed and it's entry in the builddb is
deleted. The buildtag must be given as an argument.
""",
        "cleanup": """
cleanup BUILDTAG

This command removes the remains of a failed build. If the command "new" is
interrupted or stopped by an exception in the program, the build may be in an
incomplete state. In this case you can use the "cleanup" command to remove the
directories of the failed build. If BUILDTAG is not given, the program lists
all failed builds that require a cleanup.

"""
}

# pylint: enable=C0330
#                          Wrong indentation

def helptext(topics, listmode):
    """return helptext.
    """
    # pylint: disable=R0911
    #                          Too many return statements
    if not topics:
        if listmode:
            pr_list(help_topics.keys())
        else:
            print help_topics[""]
        return
    lc_topics= [s.lower().strip() for s in topics]
    if len(lc_topics)>3:
        if not listmode:
            print "help should be followed by one or two words"
        return
    if len(lc_topics)==1:
        if listmode:
            pr_list(help_topics.keys())
            return
        txt= help_topics[lc_topics[0]]
        if txt is not None:
            print txt
            return
        print "help not found for '%s'" % (" ".join(topics))
        return
    if listmode:
        return
    # two words given
    if lc_topics[0] not in help_maincommands:
        print "no known maincommand '%s'" % topics[0]
        return
    txt= help_topics.get(" ".join(lc_topics))
    if txt is not None:
        print txt
        return
    txt= help_topics.get(lc_topics[1])
    if txt is not None:
        print txt
        return
    print "no known subcommand '%s'" % topics[1]
    return

me= script_shortname()
usage = """usage: %s maincommand [subcommand] [options]

Enter '%s help' for help on commands,
      '%s -h' for help on options
""" % (me,me,me)

def main():
    """The main function.

    parse the command-line options and perform the command
    """
    # command-line options and command-line help:
    # pylint: disable=R0915
    #                          Too many statements

    parser = OptionParser(usage=usage,
                          version="%%prog %s" % __version__,
                          description="This program manages EPICS support trees"
                         )

    parser.add_option("--summary",
                      action="store_true",
                      help="Print a summary of the function of the program.",
                     )
    parser.add_option("--test",
                      action="store_true",
                      help="Perform simple self-test.",
                     )
    parser.add_option("-c", "--config",
                      action="append",
                      type="string",
                      help="Load options from the given configuration "
                           "file. You can specify more than one of "
                           "these.  Unless --no-default-config is given, "
                           "the program always loads configuration files "
                           "from several standard directories first "
                           "before it loads your configuration file. The "
                           "contents of all configuration files are "
                           "merged. ",
                      metavar="CONFIGFILE"
                     )
    parser.add_option("-C", "--no-default-config",
                      action="store_true",
                      help="If this option is given the program doesn't load "
                           "the default configuration.",
                     )
    parser.add_option("-A", "--append",
                      action="append",
                      type="string",
                      help="If an option with name OPTIONNAME is given "
                           "here and it is a list option, the list from "
                           "the command line is *appended* to the list "
                           "from the configuration file. The default is "
                           "that options from the command line *override* "
                           "option values from the configuration file.",
                      metavar="OPTIONNAME"
                     )
    parser.add_option("--#preload",
                      action="append",
                      type="string",
                      help="Specify a an '#preload' directive in the "
                           "configuration file. This option has only a "
                           "meaning if a configuration file is created with "
                           "the 'makeconfig' command. '#preload' means that "
                           "the following file(s) are loaded before the "
                           "rest of the configuration file. ",
                      metavar="FILES"
                     )
    parser.add_option("--#opt-preload",
                      action="append",
                      type="string",
                      help="This option does the same as --#preload but "
                           "the file loading is optional. If they do not "
                           "exist the program continues without an error. ",
                      metavar="FILES"
                     )
    parser.add_option("--#postload",
                      action="append",
                      type="string",
                      help="Specify a an '#postload' directive in the "
                           "configuration file. This option has only a "
                           "meaning if a configuration file is created with "
                           "the 'makeconfig' command. '#postload' means that "
                           "the following file(s) are loaded after the "
                           "rest of the configuration file. ",
                      metavar="FILES"
                     )
    parser.add_option("--#opt-postload",
                      action="append",
                      type="string",
                      help="This option does the same as --#postload but "
                           "the file loading is optional. If they do not "
                           "exist the program continues without an error. ",
                      metavar="FILES"
                     )
    parser.add_option("--db",
                      action="store",
                      type="string",
                      help="Define the name of the DB file. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="DB"
                     )
    parser.add_option("--dbrepomode",
                      action="store",
                      type="string",
                      help="Specify how sumo should use the dependency "
                           "database repository. There are three possible "
                           "values: 'get', 'pull' and 'push'. With 'get' "
                           "the foreign repository is cloned if the local "
                           "repository does not yet exist. With 'pull' "
                           "sumo does a pull and merge before each read "
                           "operation on the database. With 'push' it "
                           "additionally does a push after each "
                           "modification of the database. The default is "
                           "'get'. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="MODE"
                     )
    parser.add_option("--dbrepo",
                      action="store",
                      type="string",
                      help="Define a REPOSITORY for the DB file. "
                           "REPOSITORY must consist of 'REPOTYPE URL', "
                           "REPOTYPE may be 'darcs', 'hg' or 'git'. Option "
                           "--db must specify a file path whose directory "
                           "part will contain the repository for the db "
                           "file. Before reading the db file a 'pull' "
                           "command will be executed.  When the file is "
                           "changed, a 'commit' and a 'push' command will "
                           "be executed. If the repository doesn't exist "
                           "the program tries to check out a working copy "
                           "from the given URL. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="REPOSITORY"
                     )
    parser.add_option("--scandb",
                      action="store",
                      type="string",
                      help= "Specify the (optional) SCANDB file. The scan "
                            "database file contains information on what "
                            "moduleversion can be used with what "
                            "dependency version.",
                      metavar="SCANDB"
                     )
    parser.add_option("--dumpdb",
                      action="store_true",
                      help="Dump the db on the console, currently "
                           "only for these commands : %s." % \
                           (" ".join(("format","weight","merge",
                                      "clonemodule",
                                      "cloneversion", "replaceversion")))
                     )
    parser.add_option("--logmsg",
                      action="store",
                      type="string",
                      help= "Specify a logmessage for automatic commits",
                      metavar="BUILDTAG"
                     )
    parser.add_option("-t", "--buildtag",
                      action="store",
                      type="string",
                      help= "Specify a buildtag",
                      metavar="BUILDTAG"
                     )
    parser.add_option("--buildtag-stem",
                      action="store",
                      type="string",
                      help= "Specify the stem of a buildtag. This option "
                            "has only an effect on the commands 'new' and "
                            "'try' if a buildtag is not specified. The "
                            "program generates a new tag in the "
                            "form 'stem-nnn' where 'nnn' is the smallest "
                            "possible number that ensures that the buildtag "
                            "is unique.",
                      metavar="STEM"
                     )
    parser.add_option("--builddir",
                      action="store",
                      type="string",
                      help="Specify the support directory. If this option "
                           "is not given take the current working directory "
                           "as support directory. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="BUILDDIR"
                     )
    parser.add_option("--localbuilddir",
                      action="store",
                      type="string",
                      help="Specify a local support directory. Modules "
                           "from the directory specifed by --builddir are "
                           "used but this directory is not modfied. All "
                           "new builds are created in the local build "
                           "directory and only the build database file "
                           "there is modified.",
                      metavar="BUILDDIR"
                     )
    parser.add_option("-o", "--output",
                      action="store",
                      type="string",
                      help= "Define the output for commands 'useall' and "
                            "'use'. If this option is not given, 'useall' "
                            "and 'use' write to 'configure/RELEASE'. If "
                            "this option is '-', the commands write to "
                            "standard-out",
                      metavar="OUTPUTFILE",
                     )
    parser.add_option("-x", "--extra",
                      action="append",
                      type="string",
                      help="Specify an extra line that is added to the "
                           "generated RELEASE file. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="EXTRALINE"
                     )
    parser.add_option("-a", "--alias",
                      action="append",
                      type="string",
                      help="Define an alias for the commands 'use' and "
                           "'useall'. An alias must have the form FROM:TO. "
                           "The path of module named 'FROM' is put in the "
                           "generated RELEASE file as a variable named "
                           "'TO'. You can specify more than one of these by "
                           "repeating this option or by joining values in a "
                           "single string separated by spaces. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="ALIAS"
                     )
    parser.add_option("--arch",
                      action="append",
                      help="Define the name of a TARGETARCHITECTURE. You "
                           "can specify more than one target architecture."
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="TARGETARCHITECTURE"
                     )
    parser.add_option("-m", "--module",
                      action="append",
                      help="Define a modulespec. If you specify modules "
                           "with this option you don't have to put "
                           "modulespecs after some of the commands.  You "
                           "can specify more than one of these by repeating "
                           "this option or by joining values in a single "
                           "string separated by spaces. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="MODULESPEC"
                     )
    parser.add_option("-X", "--exclude-states",
                      action="append",
                      type="string",
                      help="For command 'try' exclude all 'dependents' whose "
                           "state does match one of the regular expressions "
                           "(REGEXP).",
                      metavar="REGEXP"
                     )
    parser.add_option("-b", "--brief",
                      action="store_true",
                      help="Create a more brief output for some commands. ",
                     )
    parser.add_option("--detail",
                      action="store",
                      type="int",
                      help="Control the output of command 'try'. The value "
                           "must be an integer between 0 (very short) and "
                           "3 (very long)."
                     )
    parser.add_option("-D", "--dir-patch",
                      action="append",
                      help="Specify a directory PATCHEXPRESSION. Such an "
                           "expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "path generated. You can specify more than one "
                           "PATCHEXPRESSION. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="PATCHEXPRESSION"
                     )
    parser.add_option("-U", "--url-patch",
                      action="append",
                      help="Specify a repository url PATCHEXPRESSION. Such "
                           "an expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "url generated. You can specify more than one "
                           "PATCHEXPRESSION. "
                           "A default for this option can be put in a "
                           "configuration file.",
                      metavar="PATCHEXPRESSION"
                     )
    parser.add_option("--noignorecase",
                      action="store_true",
                      help="For command 'find', do NOT ignore case.",
                     )
    parser.add_option("--no-checkout",
                      action="store_true",
                      help="With this option, \"new\" does not check out "
                           "sources of support modules. This option is "
                           "only here for test purposes.",
                     )
    parser.add_option("--no-make",
                      action="store_true",
                      help="With this option, \"new\" does not call "
                           "\"make\".",
                     )
    parser.add_option("--makeopts",
                      action="append",
                      type="string",
                      help="Specify extra option strings for \"make\""
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "A default for this option can be put in a "
                           "configuration file.",
                     )
    parser.add_option("--readonly",
                      action="store_true",
                      help="Do not allow modifying the database files or "
                           "the support directory. "
                           "A default for this option can be put in a "
                           "configuration file.",
                     )
    parser.add_option("--nolock",
                      action="store_true",
                      help="Do not use file locking."
                     )
    parser.add_option("-p", "--progress",
                      action="store_true",
                      help="Show progress on stderr. "
                           "A default for this option can be put in a "
                           "configuration file.",
                     )
    parser.add_option("--trace",
                      action="store_true",
                      help="Switch on some trace messages.",
                     )
    parser.add_option("--tracemore",
                      action="store_true",
                      help="Switch on even more trace messages.",
                     )
    parser.add_option("--dump-modules",
                      action="store_true",
                      help="Dump module specs, then stop the program.",
                     )
    parser.add_option("--list",
                      action="store_true",
                      help="Show information for automatic command "
                           "completion."
                     )
    parser.add_option("-y", "--yes",
                      action="store_true",
                      help="All questions the program may ask are treated "
                           "as if the user replied 'yes'.",
                     )
    parser.add_option("--exceptions",
                      action="store_true",
                      help="On fatal errors that raise python "
                           "exceptions, don't catch these. This will "
                           "show a python stacktrace instead of an "
                           "error message and may be useful for "
                           "debugging the program."
                     )
    parser.add_option("-v", "--verbose",
                      action="store_true",
                      help="Show command calls. "
                           "A default for this option can be put in a "
                           "configuration file.",
                     )
    parser.add_option("-n", "--dry-run",
                      action="store_true",
                      help="Just show what the program would do.",
                     )

    # x= sys.argv
    (options, args) = parser.parse_args()
    # options: the options-object
    # args: list of left-over args

    # join some of the list options:
    options.arch       = sumolib.utils.opt_join(options.arch, do_sort= True)
    options.alias      = sumolib.utils.opt_join(options.alias, do_sort= True)
    options.module     = sumolib.utils.opt_join(options.module)
    options.makeopts   = sumolib.utils.opt_join(options.makeopts)

    # ^^^ A set of all options where lists from the command line are *appended*
    # to lists from the config file. The default is that lists from the command
    # line overwrite settings from the config file.
    if not options.append:
        options.append= set()
    else:
        options.append= sumolib.utils.opt_join(options.append)
        options.append= set(options.append)

    if options.summary:
        print_summary()
        sys.exit(0)

    if options.test:
        _test()
        sys.exit(0)

    # we could pass "args" as an additional parameter to process here if it
    # would be needed to process remaining command line arguments.
    process(options, args)
    sys.exit(0)

if __name__ == "__main__":
    main()

