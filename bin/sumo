#! /usr/bin/env python
# -*- coding: UTF-8 -*-

# pylint: disable=C0111
#                          Missing docstring
# pylint: disable=C0301
#                          Line too long
# pylint: enable=C0301

# pylint: disable=C0103
#                          Invalid name ... for type module
# pylint: disable=C0322
#                          Operator not preceded by a space

from optparse import OptionParser
import sys
import os.path
import os
import re
import errno
import shutil

import sumolib.system
import sumolib.lock
import sumolib.JSON
import sumolib.utils
import sumolib.Config
import sumolib.ModuleSpec
import sumolib.Databases
import sumolib.repos

# version of the program:
__version__= "2.1.1" #VERSION#

assert __version__==sumolib.system.__version__
assert __version__==sumolib.lock.__version__
assert __version__==sumolib.JSON.__version__
assert __version__==sumolib.utils.__version__
assert __version__==sumolib.Config.__version__
assert __version__==sumolib.ModuleSpec.__version__
assert __version__==sumolib.Databases.__version__
assert __version__==sumolib.repos.__version__

KNOWN_MAIN_COMMANDS=set(("edit","makeconfig","showconfig","db","build"))

KNOWN_DB_COMMANDS=set(("alias-add", "appconvert", "check", "clonemodule",
                       "cloneversion", "convert", "convert-old",
                       "filter", "find",
                       "list", "merge", "dependency-add",
                       "dependency-delete", "replaceversion", "showall",
                       "shownewest", "weight"))

KNOWN_BUILD_COMMANDS=set(("cleanup", "delete", "find", "list",
                          "new",
                          "show", "state", "try", "use", "useall"))

CONFIG_NAME="sumo.config"
ENV_CONFIG="SUMOCONFIG"

# -----------------------------------------------
# utilities
# -----------------------------------------------

def script_shortname():
    """return the name of this script without a path component."""
    return os.path.basename(sys.argv[0])

# -----------------------------------------------
# directory utilities and filenames
# -----------------------------------------------

def makefilename(build_tag):
    """create a makefile name from a build_tag."""
    return "Makefile-%s" % build_tag

def module_dir_string(buildtag, modulename, versionname):
    """create a module directory string."""
    subdir= "%s+%s" % (versionname, buildtag)
    return os.path.join(modulename, subdir)

def module_basedir_string(modulename):
    """create a module base directory string."""
    return modulename

def ensure_dir(dir_, dry_run):
    """create a dir if it doesn't already exist.
    """
    if not dry_run:
        if not os.path.exists(dir_):
            os.makedirs(dir_)

def rm_empty_dir(dirname, verbose, dry_run):
    """remove a directory.

    If the directory is not empty, return without an error message.
    """
    if verbose:
        print "remove dir %s if it is empty" % dirname
    if dry_run:
        return
    try:
        os.rmdir(dirname)
    except OSError, ex:
        if ex.errno == errno.ENOTEMPTY:
            pass

def _assume_dir(dir_, dry_run):
    """ensure that a directory exists."""
    if not dry_run:
        if not os.path.exists(dir_):
            sys.exit("Error, directory 'configure' not found")


def _config_dir(build_tag, module_name, versionname, dry_run):
    """get the config dir name."""
    dir_= module_dir_string(build_tag, module_name, versionname)
    config_dir= os.path.join(dir_, "configure")
    if not dry_run:
        if not os.path.exists(config_dir):
            errmsg("no configure directory found in %s" % dir_)
            return
    return config_dir

# -----------------------------------------------
# load JSON files
# -----------------------------------------------

def db_from_json_file(filename, keep_locked= False):
    """load a db, exits gracefully in case of an error."""
    try:
        db= sumolib.Databases.Dependencies.from_json_file(filename, keep_locked)
    except ValueError, e:
        sys.exit("Error while loading builddb,\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading builddb,\n%s" % str(e))
    return db

def builddb_from_json_file(filename, keep_locked= False):
    """load a builddb, exits gracefully in case of an error."""
    try:
        builddb= sumolib.Databases.Builddb.from_json_file(filename, keep_locked)
    except ValueError, e:
        sys.exit("Error while loading build database (builddb),\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading build database (builddb),\n%s" % str(e))
    return builddb

def init_buildcache(scandb_name, builddb, db):
    """load a builddb, exits gracefully in case of an error."""
    if not scandb_name:
        buildcache= sumolib.Databases.BuildCache()
    else:
        try:
            buildcache= sumolib.Databases.BuildCache.from_json_file(scandb_name,
                                                                 False)
        except ValueError, e:
            sys.exit("Error while loading build database (buildcache),\n%s" % \
                     str(e))
        except IOError, e:
            sys.exit("Error while loading build database (buildcache),\n%s" % \
                     str(e))
    buildcache.update_from_builddb(builddb, db)
    return buildcache

# -----------------------------------------------
# aliases
# -----------------------------------------------

def scan_aliases(aliases):
    """scan aliases given on the command line."""
    d= {}
    if not aliases:
        return d
    for a in aliases:
        (from_, to)= a.split(":")
        d[from_]= to
    return d

def alias(alias_dict, modulename):
    """return a module alias."""
    n= alias_dict.get(modulename)
    if n is None:
        return modulename
    return n

# -----------------------------------------------
# cleanup file handling
# -----------------------------------------------

def cleanupfilename(build_tag):
    """create the name of the cleanup file."""
    return "cleanup-%s" % build_tag

def rmcleanup(build_tag):
    """remove the cleanup file."""
    fn= cleanupfilename(build_tag)
    if os.path.exists(fn):
        return os.remove(fn)

def loadcleanup(build_tag, must_exist= False):
    """load the cleanup file."""
    fn= cleanupfilename(build_tag)
    if os.path.exists(fn):
        return sumolib.JSON.loadfile(fn)
    if must_exist:
        raise IOError("file '%s' not found" % fn)
    return {"modules": [] }

def savecleanup(build_tag, struc):
    """save the cleanup file."""
    fn= cleanupfilename(build_tag)
    sumolib.JSON.dump_file(fn, struc)

# -----------------------------------------------
# error messages
# -----------------------------------------------

def errmsg(msg):
    """print something on stderr."""
    sys.stderr.write(msg+"\n")

# -----------------------------------------------
# module utilities
# -----------------------------------------------

def dump_modules(modulespecs):
    """dump module specs.
    """
    for modulespec in modulespecs:
        print modulespec.to_string()

# -----------------------------------------------
# dependency handling
# -----------------------------------------------

def gather_dependencies(dist_dict, db, modulename, versionname,
                        gathered_deps):
    """recursively gather all dependencies of a module.

    For dependencies, do only take moduleversions that are in dist_dict.

    Returns a dict mapping modulenames to versionnames

    called by builddb_match, command "new"
    """
    if gathered_deps is None:
        gathered_deps= {}
    for dep_name in db.iter_dependencies(modulename, versionname):
        dep_version= dist_dict[dep_name]
        gathered_deps[dep_name]= dep_version
        gathered_deps= gather_dependencies(dist_dict, db, dep_name,
                                           dep_version, gathered_deps)
    return gathered_deps

def _add_dependencies(module_dict, db, build_module_dict,
                      modulename, versionname):
    """recursively add missing dependencies.

    called by get_dependencies, command "use"
    """
    try:
        db.assert_module(modulename, versionname)
    except KeyError, e:
        sys.exit("%s in db file" % str(e))
    for dep in db.iter_dependencies(modulename, versionname):
        if module_dict.has_key(dep):
            continue
        version_present= build_module_dict[dep]
        module_dict[dep]= version_present
        _add_dependencies(module_dict, db, build_module_dict,
                          dep, version_present)

def get_dependencies(module_dict, db, builddb, buildtag):
    """recursively complete the module_dict for missing dependencies.

    called by apprelease, command "use"
    """
    build_module_dict= builddb.modules(buildtag)
    modules= module_dict.items()
    for modulename, versionname in modules:
        _add_dependencies(module_dict, db,
                          build_module_dict, modulename, versionname)

def builddb_match(dist_dict, db, builddb, modulename, versionname):
    """try to find matching deps in builddb.

    called by add_modules, command "new"
    """
    deps= gather_dependencies(dist_dict, db, modulename, versionname, None)
    # now deps is a dict mapping modulenames to versionnames that contains all
    # direct and indirect dependencies of modulename:versionname that was
    # given to this function.
    for build_tag in builddb.iter_builds():
        # try to find modules that were already built, ignore builds that are
        # not marked "stable" or testing:
        if not builddb.is_testing_or_stable(build_tag):
            continue
        if not builddb.has_module(build_tag, modulename):
            continue
        if builddb.module_link(build_tag, modulename):
            # if this build has only a link of the module, skip it
            continue
        modules= builddb.modules(build_tag)
        if modules[modulename]!=versionname:
            # version doesn't match
            continue

        # from here: check if all dependencies match:
        match= True
        for dep_name, dep_ver in deps.items():
            other= modules.get(dep_name)
            if dep_ver!= other:
                match= False
                break
        if match:
            return build_tag
    return

# -----------------------------------------------
# file generation
# -----------------------------------------------

def gen_RELEASE(db, builddb, buildtag,
                dist_dict,
                modulename, versionname,
                extra_lines,
                verbose, dry_run):
    """generate a RELEASE file.

    This function requires that the current working directory is the support
    directory!

    Note: the SUPPORT path is the directory of the builddb file!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_module, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    config_dir= _config_dir(buildtag, modulename, versionname, dry_run)
    if config_dir is None:
        return
    filename= os.path.join(config_dir, "RELEASE")
    if verbose:
        print "creating %s" % filename
    fh= sumolib.utils.file_w_open(filename, verbose, dry_run)

    supportdir= os.getcwd()
    sumolib.utils.file_write(fh, "# generated by sumo for build %s\n\n" % \
                             buildtag,
            verbose, dry_run)
    deps= []

    for dep_name in db.iter_dependencies(modulename, versionname):
        dep_versionname= dist_dict[dep_name]
        deps.append((dep_name, dep_versionname))

    deps= db.sortby_weight(db.sortby_dependency(sorted(deps), True))
    for (dep_name, dep_versionname) in deps:
        name_here= db.get_alias(modulename, versionname, dep_name)
        buildtag_here= builddb.module_link(buildtag, dep_name)
        if buildtag_here is None:
            buildtag_here= buildtag
        path= os.path.join(supportdir,
                           module_dir_string(buildtag_here, dep_name,
                                             dep_versionname)
                          )
        sumolib.utils.file_write(fh, "%s=%s\n" % (name_here,path),
                                 verbose, dry_run)
    for l in extra_lines:
        sumolib.utils.file_write(fh, "%s\n" % l.rstrip(), verbose, dry_run)
    if not dry_run:
        fh.close()

def create_makefile(dist_dict, db, builddb, build_tag, verbose, dry_run):
    """generate a makefile.

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_modules, command "new"
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0913
    #                          Too many arguments
    def has_makefile(path):
        """checks if there is a makefile in path."""
        fn= os.path.join(path,"Makefile")
        if os.path.exists(fn):
            return True
        fn= os.path.join(path,"makefile")
        if os.path.exists(fn):
            return True
        return False
    paths= {}
    for modulename, versionname in builddb.iter_modules(build_tag):
        if not builddb.module_link(build_tag, modulename):
            dir_= module_dir_string(build_tag,
                                    modulename,
                                    versionname)
            if not has_makefile(dir_):
                continue
            paths[(modulename, versionname)]= dir_
    filename= makefilename(build_tag)
    if not dry_run:
        cleanup_struc= loadcleanup(build_tag)
        cleanup_struc["makefile"]= filename
        savecleanup(build_tag, cleanup_struc)
    module_dirs= sorted(paths.values())
    stamps= [os.path.join(p,"stamp") for p in module_dirs]
    fh= sumolib.utils.file_w_open(filename, verbose, dry_run)
    sumolib.utils.file_write(fh, "all: %s\n\n" % (" ".join(stamps)),
                             verbose, dry_run)
    sumolib.utils.file_write(fh, "clean:\n", verbose, dry_run)
    for d in module_dirs:
        sumolib.utils.file_write(fh, "\t-$(MAKE) -C %s clean\n" % d,
                                 verbose, dry_run)
    for f in stamps:
        sumolib.utils.file_write(fh, "\trm -f %s\n" % f, verbose, dry_run)
    sumolib.utils.file_write(fh, "\n", verbose, dry_run)
    for spec, path in paths.items():
        (modulename, versionname)= spec
        own_stamp= os.path.join(path, "stamp")
        dep_stamps= []
        for dep_name in db.iter_dependencies(modulename, versionname):
            if builddb.module_link(build_tag, dep_name):
                continue
            dep_version= dist_dict[dep_name]
            # do no handle dependencies that are not in the paths
            # dictionary:
            if not paths.has_key((dep_name, dep_version)):
                continue
            dep_path= module_dir_string(build_tag,
                                        dep_name, dep_version)
            dep_stamps.append(os.path.join(dep_path,"stamp"))

        dep_stamps.sort()
        if dep_stamps:
            sumolib.utils.file_write(fh,
                             "\n%s: %s\n" % \
                                     (own_stamp, " ".join(dep_stamps)),
                             verbose, dry_run)
    sumolib.utils.file_write(fh, "\n%/stamp:\n", verbose, dry_run)
    sumolib.utils.file_write(fh, "\t$(MAKE) -C $(@D)\n", verbose, dry_run)
    sumolib.utils.file_write(fh, "\ttouch $@\n", verbose, dry_run)
    if not dry_run:
        fh.close()

# -----------------------------------------------
# module creation/deletion
# -----------------------------------------------

def create_source(db, modulename, versionname,
                  destdir, verbose, dry_run):
    """create directory by given source spec.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    (sourcetype, sourcedata)= db.module_source_dict(modulename, versionname)
    sumolib.repos.checkout(sourcetype,
                        sourcedata,
                        destdir,
                        verbose, dry_run)

def delete_module(build_tag, modulename, versionname,
                  must_exist,
                  verbose, dry_run):
    """delete a single module."""
    # pylint: disable=R0913
    #                          Too many arguments
    dirname= module_dir_string(build_tag, modulename, versionname)
    if verbose:
        print "removing %s" % dirname
    if not dry_run:
        if os.path.exists(dirname):
            shutil.rmtree(dirname)
        else:
            if must_exist:
                raise IOError("error: '%s' doesn't exist" % dirname)
        # remove the parent directory if it is empty:
    rm_empty_dir(modulename, verbose, dry_run)

def create_module(db, builddb, build_tag,
                  dist_dict,
                  modulename, versionname,
                  extra_defs,
                  archs,
                  verbose, dry_run):
    """check out a module.

    returns the build_tag that was used. If the module was found in another
    build, return that built-tag.

    This function requires that the current working directory is the
    support directory!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by create_modules, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    if not db.check_archs(modulename, versionname, archs):
        sys.stderr.write("error: archs %s\nnot supportted by "
                         "module %s:%s\n" % \
                         (repr(archs), modulename, versionname))
    basedir= module_basedir_string(modulename)
    ensure_dir(basedir, dry_run) # creates basedir if it doesn't exist
    dirname= module_dir_string(build_tag, modulename, versionname)
    if os.path.exists(dirname):
        raise ValueError("directory %s already exists" % dirname)

    create_source(db, modulename, versionname, dirname, verbose, dry_run)
    gen_RELEASE(db, builddb, build_tag,
                dist_dict,
                modulename, versionname,
                extra_defs,
                verbose, dry_run)

# -----------------------------------------------
# builddb utilities
# -----------------------------------------------

_builddb= [None]
def mspecs_from_build(builddb_name):
    """generate a function to return module specs from a build."""
    def mspecs(buildtag):
        """return module specs for a buildtag."""
        if _builddb[0] is None:
            if builddb_name is None:
                raise ValueError("--builddb is needed for modulespecs")
            _builddb[0]= builddb_from_json_file(builddb_name, False)
        return _builddb[0].module_specs(buildtag)
    return mspecs

def add_modules(dist_dict, db, builddb, build_tag):
    """add modules to the builddb object.

    This function looks for compatible modules in all already existing builds.
    If possible, modules of existing builds are used.

    All modules specified by dist_dict are added with tag <build_tag> to the
    builddb.

    called by create_modules, command "new"
    """
    for modulename in sorted(dist_dict.keys()):
        versionname= dist_dict[modulename]

        # try to find a build that already has the module and where all it's
        # dependencies are also present with the same version as in dist_dict:
        compatible_build= builddb_match(dist_dict, db, builddb, modulename,
                                        versionname)
        if compatible_build is None:
            # no existing build of the module was found, we have to build the
            # module ourselbves:
            build_tag_used= build_tag
        else:
            # a compatible existing build of the module was found:
            build_tag_used= compatible_build

        builddb.add_module(build_tag, build_tag_used, modulename, versionname)

# -----------------------------------------------
# further db functions
# -----------------------------------------------

def create_app_data(deps, repoinfo, groups):
    """create configuration data for an app."""
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    keys= deps.keys()
    if len(keys)!=1:
        sys.exit("error: \"dependencies\" map must have exactly one key")

    modulespecs= []
    aliases    = []

    app_path= keys[0]
    specs_by_path= {}

    for module_name, groupdata in groups.items():
        keys= groupdata.keys()
        if len(keys)!=1:
            sys.exit("error: groupdata \"%s\" must have exactly one key" % \
                     module_name)
        root_path= keys[0]
        values= groupdata[root_path]
        if len(values)!=1:
            sys.exit("error: groudata \"%s\" must have exactly one "
                     "subdir" % module_name)
        subdir= values[0]
        versionedmodule_path= os.path.join(root_path, subdir)
        try:
            r_dict= repoinfo.get(versionedmodule_path)
        except KeyError, _:
            # shouldn't happen, but we just print a warning in this
            # case:
            errmsg("no source data: %s" % versionedmodule_path)
            continue

        sourcespec_obj= sumolib.repos.SourceSpec(r_dict)
        if sourcespec_obj.sourcetype()=="path":
            versionname= "PATH-%s" % subdir
        else:
            tag= sourcespec_obj.tag()
            if tag is None:
                versionname= "TAGLESS-%s" % subdir
            else:
                versionname= tag
        specs_by_path[versionedmodule_path]= (module_name,versionname)

    for (aliasname, path) in deps[app_path].items():
        (module_name,versionname)= specs_by_path[path]
        modulespecs.append("%s:%s" % (module_name,versionname))
        if aliasname!=module_name:
            aliases.append("%s:%s" % (module_name, aliasname))
    aliases.sort()
    modulespecs.sort()

    return {"alias": aliases, "module": modulespecs}


def create_database(deps, repoinfo, groups, archs, dir_patches, url_patches):
    """join the information of the three sources.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0913
    #                          Too many arguments
    dir_patcher= sumolib.utils.RegexpPatcher()
    url_patcher= sumolib.utils.RegexpPatcher()
    if url_patches:
        for p in url_patches:
            # pylint: disable=W0123
            #                          Use of eval
            url_patcher.add(eval(p))
    if dir_patches:
        for p in dir_patches:
            # pylint: disable=W0123
            #                          Use of eval
            dir_patcher.add(eval(p))
    _path2namevname= {}
    _namevname2path= {}
    db= sumolib.Databases.Dependencies()
    # we first create the map from modulenames to versiondata. In this loop we
    # populate the versiondata only with the source specification. We also
    # create two maps:
    #    _path2namevname: maps a diretory path to (module_name, versionname)
    #    _namevname2path: maps (module_name,versionname) to a diretory path
    for module_name, groupdata in groups.items():
        # the root directory of all the versions:
        for root_path, subdirs in groupdata.items():
            for subdir in sorted(subdirs):
                # iterate over all versions from <groups>:
                # reconstruct the original directory path:
                versionedmodule_path= os.path.join(root_path, subdir)
                # get the repository data:
                try:
                    r_dict= repoinfo.get(versionedmodule_path)
                except KeyError, _:
                    # shouldn't happen, but we just print a warning in this
                    # case:
                    errmsg("no source data: %s" % versionedmodule_path)
                    continue

                src_sourcespec= sumolib.repos.SourceSpec(r_dict)
                if src_sourcespec.sourcetype()=="path":
                    # the source is a directory path, not a repository. We
                    # generate the unique versionname:
                    if subdir.startswith("PATH-"):
                        # Try to handle a subdir that was created by this set
                        # of tools. Such a subdir may already be named
                        # "PATH-<name>+<treetag>". We want to take <name> as
                        # versionname in this case:
                        versionname= sumolib.utils.split_treetag(subdir)[0]
                    else:
                        versionname= "PATH-%s" % subdir
                    # repodata is just the path in this case:
                    src_sourcespec.path(dir_patcher.apply(
                                            src_sourcespec.path()))
                if src_sourcespec.is_repo():
                    tag= src_sourcespec.tag()

                    if tag is None:
                        # the source is a repository but has no tag. We
                        # generate a unique versionname:
                        if subdir.startswith("TAGLESS-"):
                            # Try to handle a subdir that was created by this
                            # set of tools. Such a subdir may already be named
                            # "PATH-<name>+<treetag>". We want to take <name>
                            # as versionname in this case:
                            versionname= sumolib.utils.split_treetag(subdir)[0]
                        else:
                            versionname= "TAGLESS-%s" % subdir
                        # patch URL to <versionedmodule_path>. Since we do not
                        # know in what state the working copy repository is, we
                        # have to take this as a source instead of the central
                        # repository:
                    else:
                        # the source is a darcs repository with a tag. We use
                        # the tag as unique versionname:
                        versionname= tag
                    src_sourcespec.url(url_patcher.apply(
                                           src_sourcespec.url()))

                module_archs= archs.get(versionedmodule_path, [])
                if not module_archs:
                    #  module_archs list is empty:
                    errmsg("no archs for path %s" % \
                           versionedmodule_path)
                db.set_source_arch(module_name, versionname,
                                   module_archs,
                                   src_sourcespec)

                _path2namevname[versionedmodule_path]= \
                        (module_name,versionname)
                # when we assume that a versionedmodule_path may contain a
                # buildtag, there may be several versionedmodule_paths for a
                # pair of (module_name, versionname).
                _paths= _namevname2path.setdefault(
                                    (module_name, versionname),[])
                _paths.append(versionedmodule_path)

    #sumolib.JSON.dump(_path2namevname)
    #sys.exit(0)

    buildcache= sumolib.Databases.BuildCache()

    # here we populate the versiondata with the dependency specifications:
    for modulename in db.iter_modulenames():
        # loop on stable, testing and unstable versions:
        for versionname in db.iter_versions(modulename,
                                            None, False):
            versionedmodule_paths= _namevname2path[(modulename, versionname)]

            for versionedmodule_path in versionedmodule_paths:
                _deps= deps.get(versionedmodule_path)
                if _deps is None:
                    errmsg("no dependency info for path %s" % \
                           versionedmodule_path)
                    continue
                for dep_alias, dep_path in _deps.items():
                    try:
                        (_dep_name, _dep_version)= _path2namevname[dep_path]
                    except KeyError, _:
                        sys.exit(("at module %s version %s "+ \
                                  "path %s: "+ \
                                  "missing data for "+ \
                                  "dependency \"%s\"") % \
                                  (modulename, versionname,
                                   versionedmodule_path,
                                   dep_path))
                    if _dep_name != dep_alias:
                        try:
                            db.add_alias(modulename, versionname,
                                         dep_alias, _dep_name)
                        except ValueError, e:
                            errmsg("alias error in module %s: %s" % \
                                   (modulename, str(e)))
                    db.add_dependency(modulename, versionname,
                                      _dep_name)
                    buildcache.add_dependency(modulename, versionname,
                                              _dep_name, _dep_version,
                                              "scanned")
    return (buildcache,db)

def set_weight(db, weight, modulespecs, trace):
    """set the weight for one or more modules."""
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if trace:
            sys.stderr.write("%s\n" % modulespec.to_string())

        # scan stable, testing and unstable versions:
        for version in db.iter_versions(modulename,
                                        None, must_exist= False):
            if trace:
                sys.stderr.write("test %s:%s\n" % (modulename,version))
            if not modulespec.test(version):
                continue
            if trace:
                sys.stderr.write("set weight %d on %s:%s\n" % \
                                 (weight,modulename,version))
            db.weight(modulename, version, weight)

# -----------------------------------------------
# further builddb functions
# -----------------------------------------------

def delete_modules(builddb, build_tag, verbose, dry_run):
    """delete modules of a build.
    """
    for b in builddb.iter_builds():
        if builddb.is_linked_to(b, build_tag):
            raise ValueError("error: other builds depend on build %s" % \
                              build_tag)
    for modulename, versionname in builddb.iter_modules(build_tag):
        if builddb.module_link(build_tag, modulename):
            continue
        delete_module(build_tag, modulename, versionname, True,
                      verbose, dry_run)

    os.remove(makefilename(build_tag))

    builddb.delete(build_tag)

def cleanup_modules(build_tag, verbose, dry_run):
    """cleanup remains of a failed build.

    This can only happen if a "new" command was aborted due to an exception in
    the script.
    """
    try:
        cleanup_struc= loadcleanup(build_tag, must_exist= True)
    except IOError, e:
        sys.exit(str(e))

    module_list= cleanup_struc["modules"]
    for module_dict in module_list:
        delete_module(build_tag,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      False,
                      verbose, dry_run)
    makefile= cleanup_struc.get("makefile")
    if makefile:
        if os.path.exists(makefile):
            os.remove(makefile)
    if not dry_run:
        rmcleanup(build_tag)

def create_modules(dist_dict, db, builddb, build_tag, extra_lines,
                   archs,
                   no_checkout,
                   verbose, dry_run):
    """create all modules.

    This function requires that the current working directory is the support
    directory!

    dist_dict: a dictionary mapping modulename-->versionname that is
        with respect to dependencies a complete set of modules.

    called by process, command "new"
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # save a list of possibly created directories in a cleanup-structure. In
    # case the script exits with an exception, the created cleanup file can be
    # used to clean up the support directory.
    # Load the cleanup file in case other parts of the script have saved
    # someting there:
    cleanup_struc= loadcleanup(build_tag)
    module_list  = cleanup_struc.setdefault("modules", [])

    # add all modules specified by dist_dict to builddb under tag build_tag:
    add_modules(dist_dict, db, builddb, build_tag)

    if builddb.is_fully_linked(build_tag):
        # the new build would contain only links, this is probably not wanted.
        if sumolib.Databases.Builddb.is_generated_buildtag(build_tag):
            # we never want an autotag build that consists only of links
            sys.exit("error: this build with an auto generated tag "
                     "would consist only of links. You can as well "
                     "use one of the existing builds. Just try "
                     "'sumo build use'.")
        sys.stderr.write("Note: The generated build '%s' consists only of "
                         "links.\n" % build_tag)

    for modulename in sorted(dist_dict.keys()):
        versionname= builddb.module_version(build_tag, modulename)
        # do not re-create modules that are links:
        if builddb.module_link(build_tag, modulename):
            continue
        # module_list contains only the modules that are NOT links:
        module_list.append({"modulename" : modulename,
                            "versionname": versionname})

    if not dry_run and not no_checkout:
        savecleanup(build_tag, cleanup_struc)
    if no_checkout:
        return
    for module_dict in module_list:
        create_module(db, builddb, build_tag,
                      dist_dict,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      extra_lines,
                      archs,
                      verbose, dry_run)

def call_make(builddb_name, buildtag,
              make_options,
              verbose, dry_run):
    """call "make", then mark the build "testing"."""
    # pylint: disable=R0913
    #                          Too many arguments
    #cmd="make -f %s" % makefilename(buildtag)
    if make_options is None:
        make_options=[]
    cmd="make %s -f %s" % (" ".join(make_options),makefilename(buildtag))
    try:
        # sys.stderr.write("CALLING MAKE: %s\n" % cmd)
        sumolib.system.system(cmd, False, False, verbose, dry_run)
    except IOError, e:
        sys.stderr.write("error: make failed, %s" % str(e))
        sys.exit(1)

    builddb= builddb_from_json_file(builddb_name, keep_locked= not dry_run)
    builddb.change_state(buildtag, "testing")
    builddb.json_save(builddb_name, verbose, dry_run)
    # ^^^ does also unlock the file

def fullapprelease(build_path, build_tag, builddb, db, modules,
                   aliases, extra_lines):
    """create entries for an release file.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    supportdir= os.path.realpath(build_path)
    lines= ["# generated by sumo using build %s:\n" % build_tag]
    if modules is None:
        modules= builddb.modules(build_tag).keys()

    basenames= {}
    mods= []
    for modulename in modules:
        tag= builddb.module_link(build_tag, modulename)
        if tag is None:
            tag= build_tag
        version= builddb.module_version(tag, modulename)
        basenames[(modulename, version)]= \
                   module_dir_string(tag, modulename, version)
        mods.append((modulename, version))

    mods= db.sortby_weight(db.sortby_dependency(sorted(mods), True))
    for (modulename, version) in mods:
        lines.append("%s=%s\n" % \
                (alias(aliases, modulename),
                 os.path.join(supportdir, basenames[(modulename, version)])
                ))
    for l in extra_lines:
        lines.append("%s\n" % l)
    return lines

def apprelease(build_path, build_tag, modulespecs, builddb, db,
               aliases, extra_lines):
    """create entries for an release file.

    used in command "use".
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if build_tag is None:
            # unspecifed build_tag, all versions must be *exactly specified*:
            if not modulespec.is_exact_spec():
                sys.exit("modulespec '%s' is not an exactly "
                         "specified version" % modulespec.to_string())

    if build_tag is None:
        # must look for a matching build:
        new_builddb= builddb.filter_by_modulespecs(modulespecs, db)
        if new_builddb.is_empty():
            sys.exit("no build found that matches modulespecs")
        tags= [b for b in new_builddb.iter_builds()]
        build_tag= tags[0]
        sys.stderr.write("using build %s\n" % build_tag)


    build_modules= builddb.modules(build_tag)
    module_dict= {}
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        v= build_modules.get(modulename)
        if v is None:
            sys.exit("error: module %s not found in build %s" % \
                     (modulename, build_tag))
        if not modulespec.test(v):
            sys.exit("error: no module matching %s "
                     "found in build %s" % \
                     (modulespec.to_string(), build_tag))
        module_dict[modulename]= v
    get_dependencies(module_dict, db, builddb, build_tag)
    return fullapprelease(build_path, build_tag, builddb, db,
                          module_dict.keys(), aliases, extra_lines)

# -----------------------------------------------
# command implementation
# -----------------------------------------------

def db_convert(arguments, options):
    """implement "db convert"."""
    args= get_command_args(arguments, ["SCANFILE"])
    assert_mandatory_options(options, "db", "scandb")
    if os.path.exists(options.db):
        sys.exit("error, db file '%s' already exists" % options.db)
    if os.path.exists(options.scandb):
        sys.exit("error, scandb file '%s' already exists" % \
                 options.scandb)
    scandata= sumolib.JSON.loadfile(args["SCANFILE"])
    deps= scandata["dependencies"]
    repoinfo= scandata["repos"]
    groups= scandata["groups"]
    archs= scandata["archs"]
    (buildcache, db)= create_database(deps, repoinfo, groups, archs,
                                      options.dir_patch,
                                      options.url_patch)
    db.json_save(options.db, options.verbose, options.dry_run)
    buildcache.json_save(options.scandb,
                         options.verbose, options.dry_run)

def db_convert_old(arguments, options):
    """implement "db convert-old"."""
    args= get_command_args(arguments, ["OLD-DEPS-DB"])
    assert_mandatory_options(options, "db", "scandb")
    if os.path.exists(options.db):
        sys.exit("error, db file '%s' already exists" % options.db)
    if os.path.exists(options.scandb):
        sys.exit("error, scandb file '%s' already exists" % \
                 options.scandb)
    old= sumolib.Databases.OldDependencies.from_json_file(
                                                    args["OLD-DEPS-DB"],
                                                    keep_locked=False)
    (buildcache, db)= old.convert()
    db.json_save(options.db, options.verbose, options.dry_run)
    buildcache.json_save(options.scandb,
                         options.verbose, options.dry_run)

def db_appconvert(arguments):
    """implement "db appconvert"."""
    args= get_command_args(arguments, ["SCANFILE"])
    scandata= sumolib.JSON.loadfile(args["SCANFILE"])
    deps= scandata["dependencies"]
    repoinfo= scandata["repos"]
    groups= scandata["groups"]
    struc= create_app_data(deps, repoinfo, groups)
    sumolib.JSON.dump(struc)

def db_weight(arguments, options):
    """implement "db weight"."""
    args= get_command_args(arguments, ["WEIGHT"],
                           extra_mandatory= "MODULES")
    assert_mandatory_options(options, "db")
    try:
        weight= int(args["WEIGHT"])
    except ValueError, _:
        sys.exit("error: weight must be an integer")
    db= db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                                        args["MODULES"],
                                                        None)
    except ValueError, e:
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    set_weight(db, weight, modulespecs_obj, options.trace)
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_filter(arguments, options):
    """implement "db filter"."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db")
    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        modulespecs.extend(args["MODULES"])
    if not modulespecs:
        sys.exit("error: module specs missing")

    db= db_from_json_file(options.db, keep_locked= False)
    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,
                                                        None,
                                                        options.arch)
    except ValueError, e:
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    db= db.partial_copy_by_modulespecs(modulespecs_obj)
    db.json_print()

def db_check(arguments, options):
    """implement "db check"."""
    assert_mandatory_options(options, "db")
    get_command_args(arguments)
    db = db_from_json_file(options.db, keep_locked= False)
    msg= db.check()
    print "\n".join(msg)

def db_merge(arguments, options):
    """implement "db merge"."""
    args= get_command_args(arguments, ["DB"])
    assert_mandatory_options(options, "db")
    db = db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    db2= db_from_json_file(args["DB"])
    db.merge(db2)
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_alias_add(arguments, options):
    """implement "db alias_add"."""
    args= get_command_args(arguments,
                           ["MODULE","DEPENDENCY","ALIAS"])
    assert_mandatory_options(options, "db")
    module_spec= sumolib.ModuleSpec.Spec.from_string(args["MODULE"])
    try:
        module_spec.assert_exact()
    except ValueError, e:
        sys.exit(str(e))
    db = db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    db.add_alias(module_spec.modulename,
                 module_spec.versionname,
                 args["ALIAS"], args["DEPENDENCY"])
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_dependency_add(arguments, options):
    """implement "db dependency_add"."""
    args= get_command_args(arguments, ["MODULE","DEPENDENCY"])
    assert_mandatory_options(options, "db")
    module_spec= sumolib.ModuleSpec.Spec.from_string(args["MODULE"])
    try:
        module_spec.assert_exact()
    except ValueError, e:
        sys.exit(str(e))
    db = db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    db.add_dependency(module_spec.modulename,
                      module_spec.versionname,
                      args["DEPENDENCY"])
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_dependency_delete(arguments, options):
    """implement "db dependency_delete"."""
    args= get_command_args(arguments, ["MODULE","DEPENDENCY"])
    assert_mandatory_options(options, "db")
    module_spec= sumolib.ModuleSpec.Spec.from_string(args["MODULE"])
    if module_spec.no_version_spec():
        sys.exit("module has no version")
    try:
        module_spec.assert_exact()
    except ValueError, e:
        sys.exit(str(e))
    db = db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    db.del_dependency(module_spec.modulename,
                      module_spec.versionname,
                      args["DEPENDENCY"])
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_clone_replace_version(command, arguments, options):
    """implement "db cloneversion/replaceversion"."""
    args= get_command_args(arguments,
                           ["MODULE","OLD-VERSION","NEW-VERSION"],
                           extra_optional="SOURCESPEC")
    assert_mandatory_options(options, "db")
    do_replace= (command=="replaceversion")
    modulename= args["MODULE"]
    sourcespec= args.get("SOURCESPEC")

    db = db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    try:
        db.patch_version(modulename,
                         args["OLD-VERSION"], args["NEW-VERSION"],
                         do_replace)
    except ValueError, e:
        sys.exit(str(e))

    if not sourcespec:
        # guess tag from versionname
        changed= db.set_source_spec_by_tag(modulename, args["NEW-VERSION"],
                                           args["NEW-VERSION"])
    else:
        try:
            source_spec_obj= \
                sumolib.repos.SourceSpec.from_string_sourcespec(sourcespec)
        except ValueError, e:
            sys.exit("Error: "+str(e))
        changed= db.set_source_spec(modulename, args["NEW-VERSION"],
                                    source_spec_obj)
    print "Added module:"
    report_db= db.partial_copy_by_list([(modulename, args["NEW-VERSION"])])
    report_db.json_print()
    if not changed:
        print ("\nCAUTION: source specification of this module is "
               "identical with that of \n"
               "%s:%s, this is probably not what you want!") % \
               (modulename, args["OLD-VERSION"])
    sumolib.utils.ask_abort("Proceed ? ", options.yes)
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_clonemodule(arguments, options):
    """implement "db clonemodule"."""
    args= get_command_args(arguments,
                           ["OLD-MODULE","NEW-MODULE"],
                           extra_optional="VERSIONS")
    assert_mandatory_options(options, "db")
    db = db_from_json_file(options.db,
            keep_locked= not options.dumpdb and (not options.dry_run))
    db.clonemodule(args["OLD-MODULE"], args["NEW-MODULE"],
                   args.get("VERSIONS"))
    if options.dumpdb:
        db.json_print()
    else:
        db.json_save(options.db, options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def db_list(arguments, options):
    """implement "db list"."""
    get_command_args(arguments)
    assert_mandatory_options(options, "db")
    db= db_from_json_file(options.db)
    result= sorted(db.iter_modulenames())
    sumolib.JSON.dump(result)

def db_show_newest_all(command, arguments, options):
    """implement "db shownewest/showall"."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db")
    showall= (command=="showall")
    db= db_from_json_file(options.db)

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        modulespecs.extend(args["MODULES"])
    if not modulespecs:
        modulespecs= list(db.iter_modulenames())

    result= {}

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(modulespecs,
                                                        None,
                                                        options.arch)
    except ValueError, e:
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    for modulespec in modulespecs_obj:
        modulename= modulespec.modulename

        versions= db.sorted_moduleversions(modulename,
                                           options.arch, False)
        if not versions: # no versions match criteria
            continue
        versions= [v for v in versions \
                   if modulespec.test(v)]

        if not showall:
            result[modulename]= versions[0]
        else:
            result[modulename]= versions
    sumolib.JSON.dump(result)

def db_find(arguments, options):
    """implement "db find"."""
    args= get_command_args(arguments, ["REGEXP"])
    assert_mandatory_options(options, "db")
    db= db_from_json_file(options.db)
    if options.noignorecase:
        rx_flags= 0
    else:
        rx_flags= re.IGNORECASE
    rx= re.compile(args["REGEXP"], rx_flags)
    results= db.search_modules(rx, options.arch)
    if options.brief:
        for (module,version) in results:
            print "%s:%s" % (module,version)
        return
    newdb= db.partial_copy_by_list(results)
    newdb.json_print()

def build_list(arguments, options):
    """implement "build_list"."""
    get_command_args(arguments)
    assert_mandatory_options(options, "builddb")
    builddb= builddb_from_json_file(options.builddb)
    for buildtag in builddb.iter_builds():
        print buildtag

def build_show(arguments, options):
    """implement "build_show"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    assert_mandatory_options(options, "builddb")
    if options.buildtag:
        sys.exit("error: you cannot use --buildtag here")

    builddb= builddb_from_json_file(options.builddb)
    if not builddb.has_build_tag(args["BUILDTAG"]):
        sys.exit("error: BUILDTAG \"%s\" not found" % \
                 args["BUILDTAG"])
    new_builddb= sumolib.Databases.Builddb()
    new_builddb.add_build(builddb, args["BUILDTAG"])
    new_builddb.json_print()

def build_state(arguments, options):
    """implement "build_state"."""
    args= get_command_args(arguments, ["BUILDTAG"],
                           optional_args=["NEW-STATE"])
    if options.buildtag:
        sys.exit("error: you cannot use --buildtag here")

    assert_mandatory_options(options, "builddb")
    if options.readonly:
        sys.exit("--readonly forbids changing the state of a build")

    builddb= builddb_from_json_file(options.builddb,
            keep_locked= not options.dry_run)
    if not builddb.has_build_tag(args["BUILDTAG"]):
        # builddb __del__ method should remove lockfiles
        sys.exit("error: BUILDTAG \"%s\" not found" % \
                 args["BUILDTAG"])
    if not args.get("NEW-STATE"):
        print "%-20s : %s" % (args["BUILDTAG"],
                              builddb.state(args["BUILDTAG"]))
    else:
        try:
            builddb.change_state(args["BUILDTAG"], args["NEW-STATE"])
        except ValueError, e:
            # builddb __del__ method should remove lockfiles
            sys.exit(str(e))
        builddb.json_save(options.builddb,
                          options.verbose, options.dry_run)
        # ^^^ does also unlock the file

def build_delete(arguments, options):
    """implement "build_delete"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    assert_mandatory_options(options, "builddb")
    if options.readonly:
        sys.exit("--readonly forbids deleting a support")

    if options.supportdir:
        os.chdir(options.supportdir)

    builddb= builddb_from_json_file(options.builddb)
    if not builddb.has_build_tag(args["BUILDTAG"]):
        sys.exit("error: BUILDTAG \"%s\" not found" % \
                 args["BUILDTAG"])
    try:
        delete_modules(builddb, args["BUILDTAG"],
                       options.verbose, options.dry_run)
    except ValueError, e:
        sys.exit(str(e))
    builddb.json_save(options.builddb,
                      options.verbose, options.dry_run)

def build_cleanup(arguments, options):
    """implement "build_cleanup"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    if options.readonly:
        sys.exit("--readonly forbids cleaning up")

    if options.supportdir:
        os.chdir(options.supportdir)

    cleanup_modules(args["BUILDTAG"], options.verbose, options.dry_run)

def build_try(arguments, options):
    """implement "build_try"."""
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddb")

    buildtag= options.buildtag

    exclude_matcher= sumolib.utils.RegexpMatcher(options.exclude_states)

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        modulespecs.extend(args["MODULES"])
    if not modulespecs:
        sys.exit("error: module specs missing")

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                             modulespecs,
                             mspecs_from_build(options.builddb),
                             options.arch)
    except ValueError, e:
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    db= db_from_json_file(options.db, keep_locked= False)
    if not os.path.exists(options.builddb):
        builddb= sumolib.Databases.Builddb()
    else:
        builddb= builddb_from_json_file(options.builddb,
                                        keep_locked= False)

    buildcache= init_buildcache(options.scandb,
                                builddb, db)

    # ensure that each module is only mentioned once in the modulelist:
    try:
        modulespecs_obj.assert_unique()
    except ValueError, e:
        sys.exit(str(e))

    modules_not_exact_spec= []
    for spec in modulespecs_obj:
        if not spec.is_exact_spec():
            modules_not_exact_spec.append(spec.modulename)

    # convert modulespecs to a set dict:
    # { modulename1 : set(version1,version2),
    #   modulename2 : set(version1,version2),
    # }
    try:
        sets_dict= db.sets_dict(modulespecs_obj)
    except ValueError, e:
        sys.exit(str(e))

    # add all missing dependencies:
    added_modules= db.complete_sets_dict(sets_dict)

    was_built= set()
    needed_by_others= {}

    for modulename in sets_dict.keys():
        for versionname in sets_dict[modulename]:
            if buildcache.was_built(modulename,versionname):
                was_built.add((modulename,versionname))
            for depname in db.iter_dependencies(modulename, versionname):
                for dep_version in sets_dict[depname]:
                    s= needed_by_others.setdefault((depname,dep_version),
                                                   [])
                    s.append((modulename,versionname,
                             buildcache.relation(modulename,versionname,
                                                 depname, dep_version)))

    # now build the report structure:
    report= {}
    for modulename in sets_dict.keys():
        mdict= report.setdefault(modulename, {})
        no_of_versions= len(sets_dict[modulename])
        for versionname in sets_dict[modulename]:
            d= {}
            mdict[versionname]= d
            d["built"]= (modulename,versionname) in was_built
            l= needed_by_others.get((modulename,versionname))
            if l is not None:
                dd= d.setdefault("dependents", {})
                depmods_versioncount= {}
                for (m,v,state) in l:
                    depmods_versioncount.setdefault(m, 0)
                    if state is None:
                        state= "state: not tested"
                    else:
                        state= "state: %s" % state
                    if no_of_versions>1:
                        # do only apply the exclude_matcher when there is
                        # more than ony possible version of module
                        # 'modulename':
                        if exclude_matcher.search(state):
                            continue
                    depmods_versioncount[m]+= 1
                    dd["%s:%s" % (m,v)]= state
                if min(depmods_versioncount.values())==0:
                    # all versions of a dependent were removed,
                    # remove modulename:versionname completely:
                    del mdict[versionname]
        if not mdict:
            sys.exit("error: your '--exclude-states' option removes "
                     "*ALL* versions of module '%s'. You may change "
                     "the REGEXP or specify an exact version "
                     "for the module to avoid this error." % \
                     modulename)

    if modules_not_exact_spec:
        print "Not all modules have exactly specified versions.",
        print "These modules need an "
        print "exact version specification:"
        for m in sorted(modules_not_exact_spec):
            versions= report[m].keys()
            if len(versions)>1:
                print "    %s" % m
            else:
                print "    %-20s -> suggested version: %s" % \
                      (m,versions[0])
        print

    if added_modules:
        print "Not all dependencies were included in module",
        print "specifications, these modules"
        print "have to be added:\n   ",
        print "\n    ".join(sorted(added_modules))
        print

    if not options.brief:
        if not modules_not_exact_spec and not added_modules:
            # everything complete, show modules that are not needed by
            # other modules:
            needed_modules= set([m for (m,_) in needed_by_others.keys()])
            not_needed_modules= \
                    set(report.keys()).difference(needed_modules)
            print "The following modules are not needed by other modules",
            print "in your module"
            print "specification:\n   ",
            print "\n    ".join(sorted(not_needed_modules))
            print
        print "List of modules that fullfill the given "+\
              "module specification:"
        sumolib.JSON.dump(report)

    if buildtag is None:
        if not options.buildtag_stem:
            options.buildtag_stem= "AUTO"
        buildtag= builddb.generate_buildtag(options.buildtag_stem)
        print "Command 'new' would create build with tag '%s'\n" % \
              buildtag

    if not modules_not_exact_spec and not added_modules:
        print "Your module specifications are complete. You can use",
        print "these with command"
        print "'new' to create a new build."
    else:
        print "Your module specifications are still incomplete,",
        print "command 'new' can not"
        print "be used with these."

def build_new(arguments, options):
    """implement "build_new"."""
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddb")
    if options.readonly:
        sys.exit("--readonly forbids creating a new build")

    buildtag= options.buildtag

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        modulespecs.extend(args["MODULES"])
    if not modulespecs:
        sys.exit("error: module specs missing")

    db= db_from_json_file(options.db, keep_locked= False)

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                             modulespecs,
                             mspecs_from_build(options.builddb),
                             options.arch)
    except ValueError, e:
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    try:
        dist_dict= modulespecs_obj.to_dist_dict()
    except ValueError, e:
        sys.exit(str(e))
    try:
        db.assert_complete_modulelist(dist_dict)
    except ValueError, e:
        sys.exit(str(e))

    if not os.path.exists(options.builddb):
        builddb= sumolib.Databases.Builddb()
    else:
        builddb= builddb_from_json_file(options.builddb,
                    keep_locked= not options.dry_run)
    if buildtag is None:
        if not options.buildtag_stem:
            options.buildtag_stem= "AUTO"
        buildtag= builddb.generate_buildtag(options.buildtag_stem)
        sys.stderr.write("creating build with tag '%s'\n" % buildtag)
    if builddb.has_build_tag(buildtag):
        # builddb __del__ method should remove lockfiles
        sys.exit("error: buildtag \"%s\" already taken" % buildtag)
    # create a new build in builddb, initial state is "unstable":
    builddb.new_build(buildtag, "unstable")
    if options.supportdir:
        os.chdir(options.supportdir)
    # modifies builddb:
    try:
        create_modules(dist_dict, db, builddb, buildtag,
                       options.extra,
                       options.arch,
                       options.no_checkout,
                       options.verbose,
                       options.dry_run)
        if not options.no_checkout:
            create_makefile(dist_dict, db, builddb, buildtag,
                            options.verbose,
                            options.dry_run)
    except IOError, e:
        db.unlock_file()
        builddb.unlock_file()
        raise

    builddb.json_save(options.builddb, options.verbose, options.dry_run)
    # ^^^ does also unlock the file
    rmcleanup(buildtag)
    if not options.no_make and not options.no_checkout:
        call_make(options.builddb, buildtag,
                  options.makeopts,
                  options.verbose, options.dry_run)

def build_find(arguments, options):
    """implement "build_find"."""
    args= get_command_args(arguments,
                           extra_optional="MODULESPECS")
    assert_mandatory_options(options, "db", "builddb")

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULESPECS"):
        modulespecs.extend(args["MODULESPECS"])
    if not modulespecs:
        sys.exit("error: module specs missing")

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                             modulespecs,
                             mspecs_from_build(options.builddb),
                             options.arch)
    except ValueError, e:
        sys.exit(str(e))

    db= db_from_json_file(options.db)
    builddb= builddb_from_json_file(options.builddb)

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)
    new_builddb= builddb.filter_by_modulespecs(modulespecs_obj, db)
    if new_builddb.is_empty():
        print "no matching buildtrees found"
    else:
        if options.brief:
            for buildtag in builddb.iter_builds():
                print buildtag
        else:
            new_builddb.json_print()

def build_useall(arguments, options):
    """implement "build_useall"."""
    args= get_command_args(arguments, ["BUILDTAG"])
    assert_mandatory_options(options, "db", "builddb")
    output= options.output
    if not output:
        _assume_dir("configure", options.dry_run)
        output= os.path.join("configure","RELEASE")

    builddb= builddb_from_json_file(options.builddb)
    db= db_from_json_file(options.db)
    lines= fullapprelease(options.supportdir \
                             if options.supportdir else ".",
                          args["BUILDTAG"],
                          builddb,
                          db,
                          None,
                          scan_aliases(options.alias),
                          options.extra)
    sumolib.utils.mk_text_file(output, lines,
                               options.verbose, options.dry_run)

def build_use(arguments, options):
    """implement "build_use"."""
    args= get_command_args(arguments,
                           extra_optional="MODULES")
    assert_mandatory_options(options, "db", "builddb")
    buildtag= options.buildtag

    modulespecs= []
    if options.module:
        modulespecs.extend(options.module)
    if args.has_key("MODULES"):
        modulespecs.extend(args["MODULES"])
    if not modulespecs:
        sys.exit("error: module specs missing")

    try:
        modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                             modulespecs,
                             mspecs_from_build(options.builddb),
                             options.arch)
    except ValueError, e:
        sys.exit(str(e))

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    output= options.output
    if not output:
        _assume_dir("configure", options.dry_run)
        output= os.path.join("configure","RELEASE")

    db= db_from_json_file(options.db)
    builddb= builddb_from_json_file(options.builddb)

    if options.dump_modules:
        dump_modules(modulespecs_obj)
        sys.exit(0)

    lines= apprelease(options.supportdir \
                         if options.supportdir else ".",
                      buildtag,
                      modulespecs_obj,
                      builddb,
                      db,
                      scan_aliases(options.alias),
                      options.extra)
    sumolib.utils.mk_text_file(output, lines,
                               options.verbose, options.dry_run)

# -----------------------------------------------
# command processing
# -----------------------------------------------

def assert_mandatory_options(options, *opt_list):
    """check for the presence of options."""
    for opt in opt_list:
        if not getattr(options, opt):
            sys.exit("--%s is mandatory here" % opt)

def get_command_args(lst, mandatory_args=None,
                     optional_args=None,
                     extra_mandatory= None,
                     extra_optional= None,
                     debug=False):
    """get a command.

    extra_mandatory:
        If given, extra arguments are required and stored under the given name
        as a list.
    extra_optional:
        If given, extra arguments are allowed and stored under the given name
        as a list.

    Here are some examples:

    >>> import pprint
    >>>
    >>> p=pprint.pprint
    >>>
    >>> def test(*args, **kwargs):
          kwargs["debug"]= True
    ...   pprint.pprint(get_command_args(*args, **kwargs))
    ...
    >>> test(["read","t.txt","verbose"],["cmd","file"],["mode"])
    {'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read","t.txt"],["cmd","file"],["mode"])
    {'cmd': 'read', 'file': 't.txt'}
    >>> test(["read","t.txt","verbose","a1","a2"],["cmd","file"],["mode"])
    error, extra arguments follow: a1 a2
    None
    >>> test(["read","t.txt","verbose","a1","a2"],["cmd","file"],["mode"],
    ...      extra_mandatory="args")
    {'args': ['a1', 'a2'], 'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read","t.txt","verbose","a1","a2"],["cmd","file"],["mode"],
    ...      extra_optional="args")
    {'args': ['a1', 'a2'], 'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read","t.txt","verbose"],["cmd","file"],["mode"],
    ...      extra_mandatory="args")
    error, mandatory argument args missing
    None
    >>> test(["read","t.txt","verbose"],["cmd","file"],["mode"],
    ...      extra_optional="args")
    {'cmd': 'read', 'file': 't.txt', 'mode': 'verbose'}
    >>> test(["read"],["cmd","file"],["mode"])
    error, mandatory argument missing: file
    None
    >>> test([],["cmd","file"],["mode"])
    error, mandatory arguments missing: cmd file
    None
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0912
    #                          Too many branches
    def ERR(msg):
        if debug:
            print msg
            return
        sys.exit(msg)
    result= {}
    if not mandatory_args:
        mandatory_args= []
    for i in xrange(len(mandatory_args)):
        try:
            result[mandatory_args[i]]= lst[i]
        except IndexError, _:
            missing= mandatory_args[i:]
            ch= "s" if len(missing)>1 else ""
            ERR("error, mandatory argument%s missing: %s" % \
                (ch, " ".join(missing)))
            return
    start= len(mandatory_args)
    if not optional_args:
        optional_args= []
    for i in xrange(len(optional_args)):
        try:
            result[optional_args[i]]= lst[i+start]
        except IndexError, _:
            break
    rest= lst[len(mandatory_args)+len(optional_args):]
    if not rest:
        if extra_mandatory:
            ERR("error, mandatory argument %s missing" % extra_mandatory)
            return
    else:
        if extra_mandatory:
            result[extra_mandatory]= rest
        elif extra_optional:
            result[extra_optional]= rest
        else:
            ch= "s" if len(rest)>1 else ""
            ERR("error, extra argument%s follow: %s" % \
                (ch, " ".join(rest)))
            return
    return result

def process_db(options, commands):
    """do all the work.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    if options.nolock:
        sumolib.lock.use_lockfile= False
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_DB_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if commands[0]=="convert":
        db_convert(commands[1:], options)
        return

    if commands[0]=="convert-old":
        db_convert_old(commands[1:], options)
        return

    if commands[0]=="appconvert":
        db_appconvert(options)
        return

    if commands[0]=="weight":
        db_weight(commands[1:], options)
        return

    if commands[0]=="filter":
        db_filter(commands[1:], options)
        return

    if commands[0]=="check":
        db_check(commands[1:], options)
        return

    if commands[0]=="merge":
        db_merge(commands[1:], options)
        return

    if commands[0]=="alias-add":
        db_alias_add(commands[1:], options)
        return

    if commands[0]=="dependency-add":
        db_dependency_add(commands[1:], options)
        return

    if commands[0]=="dependency-delete":
        db_dependency_delete(commands[1:], options)
        return

    if commands[0]=="cloneversion" or commands[0]=="replaceversion":
        db_clone_replace_version(commands[0], commands[1:], options)
        return

    if commands[0]=="clonemodule":
        db_clonemodule(commands[1:], options)
        return

    if commands[0]=="list":
        db_list(commands[1:], options)
        return

    if commands[0]=="shownewest" or commands[0]=="showall":
        db_show_newest_all(commands[0], commands[1:], options)
        return

    if commands[0]=="find":
        db_find(commands[1:], options)
        return

def process_build(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0914
    #                          Too many local variables
    if options.nolock:
        sumolib.lock.use_lockfile= False
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_BUILD_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if not options.extra:
        options.extra= []

    if commands[0]=="list":
        build_list(commands[1:], options)
        return

    if commands[0]=="show":
        build_show(commands[1:], options)
        return

    if commands[0]=="state":
        build_state(commands[1:], options)
        return

    if commands[0]=="delete":
        build_delete(commands[1:], options)
        return

    if commands[0]=="cleanup":
        build_cleanup(commands[1:], options)
        return

    if commands[0]=="try":
        build_try(commands[1:], options)
        return

    if commands[0]=="new":
        build_new(commands[1:], options)
        return

    if commands[0]=="find":
        build_find(commands[1:], options)
        return

    if commands[0]=="useall":
        build_useall(commands[1:], options)
        return

    if commands[0]=="use":
        build_use(commands[1:], options)
        return

def process(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    if not commands:
        print "command missing\n"
        print usage
        return
    if commands[0]=="help":
        print helptext(commands[1:])
        return

    config_name= None
    if not options.no_default_config:
        config_name= CONFIG_NAME
    config= sumolib.Config.ConfigFile.from_optionlist(
                config_name,
                ENV_CONFIG,
                ( "#include", "arch", "alias", "builddb", "buildtag_stem",
                  "db", "extra", "makeopts", "module", "progress",
                  "readonly", "scandb", "dir_patch", "url_patch",
                  "supportdir", "verbose"))

    try:
        config.load(options.config)
    except ValueError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    try:
        config.merge_options(options, options.mergeoption)
    except ValueError, e:
        sys.exit(str(e))
    except TypeError, e:
        sys.exit(str(e))
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_MAIN_COMMANDS:
        sys.exit("unknown maincommand '%s', expected 'db' or 'build'.")
    if commands[0]=="showconfig":
        print "These configuration files were loaded:"
        print "\n".join(config.paths())
        return
    if commands[0]=="makeconfig":
        if len(commands)<=1:
            sys.exit("filename for command \"makeconfig\" is missing")
        if options.module:
            try:
                modulespecs_obj= sumolib.ModuleSpec.Specs.from_strings(
                                     options.module,
                                     mspecs_from_build(options.builddb),
                                     options.arch)
            except ValueError, e:
                sys.exit(str(e))
            config.set("module", modulespecs_obj.to_stringlist())
        config.save(commands[1], commands[2:])
        return

    elif commands[0]=="edit":
        if options.readonly:
            sys.exit("--readonly forbids editing a database file")
        if len(commands)!=2:
            sys.exit("exactly one filename must follow \"edit\"")
        try:
            sumolib.lock.edit_with_lock(commands[1],
                                        options.verbose, options.dry_run)
        except IOError, e:
            sys.exit(str(e))
        return

    elif commands[0]=="db":
        process_db(options, commands[1:])
    elif commands[0]=="build":
        process_build(options, commands[1:])
    else:
        raise AssertionError("unexpected command: %s" % commands[0])
    return

def print_summary():
    """print a short summary of the scripts function."""
    print "%-20s: a tool for managing support EPICS trees \n" % \
          script_shortname()

def _test():
    """does a self-test of some functions defined here."""
    print "performing self test..."
    import doctest
    doctest.testmod()
    print "done!"

help_maincommands= set(("makeconfig", "edit", "db", "build"))

help_topics= {
        "":"""
No help topic given. Use
  "help <topic>" to get help on a topic.

Possible topics are:

  maincommand                : explain what a maincommand is
  configuration              : how and where configuration data is stored
  <maincommand>              : help for a specific maincommand
  <maincommand> <subcommand> : help for a subcommand of a maincommand
  <subcommand>               : help for a subcommand
""",
        "maincommand":"""
A maincommand provides a grouping for the various commands of sumo.

While some maincommands can be used without a subcommand, others must be
followed by a subcommand. These are the known maincommands:

  makeconfig         - generate a configuration file
  showconfig         - show which configuration files were loaded
  edit               - lock, then edit a file
  db [subcommand]    - operation on the dependency database
  build [subcommand] - manage the build database and builds

For all of the db subcommands you have to specify the dependency database with
option --db or a configuration file.

For all of the build subcommands you have to specify the dependency database
and the build database with --db and --builddb or a configuration file.

Use "help [maincommand] for further details.
""",
        "configuration":"""

Many options that can be given on the command line can be taken from
configuration files. 

File format
-----------
A configuration file is always in JSON  format. Each key is the long name of a
command line option, each value is either a string or a list of strings.

Merging
-------
Sumo can read several configuration files, in this case the data is *merged*.

Merging means that keys are not yet defined are simply added. For keys that
already exist and whose values are strings, the latter one overwrites the first
one.  For keys that already exist and whose values are lists, the lists are
simply concatenated.

Default paths
-------------
Sumo reads and merges configuration files from various places, which one
depends on your environment variable settings and command line options. 

First the program tries to read the file sumo.config from a list of default
paths. The list of default paths can be set by the environment variable
ENV_CONFIG which must be a colon (on Unix systems) or semicolon (on Windows
systems) separated list of paths. 

If ENV_CONFIG is not set, these are the predefined default paths:

- /etc
- [python-libdir]/sumolib
- $HOME
- your current working directory

If you use the "--no-default-config" command line option, the list of default
paths is made empty.

The config option
-----------------

After the configuration files from default paths were read the program reads
the all configuration files specified by the "-c" or "--config" option.

""",
        "makeconfig":"""
makeconfig FILENAME [OPTIONNAMES]

Create a new configuration file from the options read from configuration files
and options from the command line. If FILENAME is '-' dump to the console. 
OPTIONNAMES is an optional list of long option names. If OPTIONNAMES are 
specified, only options from this list are saved in the configuration file.
""",
        "showconfig":"""
showconfig {FILENAME}

Show all the configuration files that were loaded.
""",
        "edit": """
edit FILE

Start the editor specified by the environment variable "VISUAL" or "EDITOR"
with that file. This command first aquires a file-lock on the file that is only
released when the editor program is terminated.  If you want to edit a DB or
BUILDDB file directly, you should always do it with this with this command. The
file locking prevents other users to use the file at the same time you modify
it.
""",
        "db": """

db [subcommand]

Query or modify the dependency database (DB) file. These are the known
subcommands here:

  convert      - convert a scanfile created by sumo-scan to a DB file
  convert-old  - convert a DB file from old to new format (legacy)
  appconvert   - convert a scanfile to a MODULES file for an application
  weight       - set the weight factor for modules
  alias-add    - add an alias for a dependency in a module
  dependency-add - 
                 add a dependency to a module
  dependency-delete - 
                 delete a dependency of a module
  list         - list modules
  shownewest   - show newest module versions
  showall      - show all modules
  filter       - show parts of the DB file
  find         - search for modules with a regexp
  check        - consistency check of the DB file
  merge        - merge two DB files
  cloneversion - create a new DB entry by copying an old one
  replaceversion - 
                 replace a DB entry with a new one
  clonemodule  - add a module under a new name in the DB file

Use "help [subcommand] for further details.
""",
        "build": """

build [subcommand]

Manage the build database (BUILDDB) and create or delete builds. These are the
known subcommands:

  try       - check the module specification for completeness and consistency
  new       - create a new build
  find      - look for builds that match a module specification
  useall    - use all modules of a build in your application
  use       . use all modules or your module specification in your application
  list      - list names of all builds
  show      - show details of a build
  state     - show or change the state of a build
  delete    - delete a build
  cleanup   - clean up remains of build whose checkout command failed
""",
        "list":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db list' enter 'help db list'
For help on 'build list' enter 'help build list'
""",
        "find":"""
This is a subcommand of command 'db' and command 'build'.

For help on 'db find' enter 'help db find'
For help on 'build find' enter 'help build find'
""",

        "convert":"""
convert SCANFILE

Convert SCANFILE created by "sumo-scan all" to a new dependency database. If
SCANFILE is a dash "-" the program expects the scanfile on stdin.  Note that
options "--db" and "--scandb" are mandatory here. With "--db" you specify the
name of the new created dependency database file, with "--scandb" you specify
the name of the scan database file.  The scan database file contains
information on what moduleversion can be used with what dependency version.
""",
        "convert-old": """
convert-old OLD-DEPS-DB

Convert a dependency database from the old to the new format. Note that options
"--db" and "--scandb" are mandatory here. With "--db" you specify the name of
the new created dependency database file, with "--scandb" you specify the name
of the scan database or SCANDB file. The scan database file contains
information on what version of a module is probably compatible with what
version of a dependency according to the data in the old dependency database.
""",
        "appconvert": """
appconvert SCANFILE 

Convert a SCANFILE that was created by applying sumo-scan to an application to
a list of aliases and modulespecs in JSON format. The result is printed to the
console. It can be used with --config to put these in the configuration file of
sumo.
""",
        "weight": """
weight WEIGHT MODULES

Set the weight factor for module. A weight determines where a module is placed
in the generated RELEASE file. Modules there are sorted first by weight, then
by dependency. Parameter MODULES is a list of modulespecs. Use
modulename:{+-}versionname to select more versions of a module.

Note that this command *does not* use the "--modules" option.

Parameter WEIGHT must be an integer.
""",
        "alias-add": """
alias-add MODULE DEPENDENCY ALIAS

Define a new alias for a dependency of a module. MODULE here is a modulespec of
the form MODULE:VERSION that specifies a single version of a module.
""",
        "dependency-delete": """
dependency-delete MODULE DEPENDENCY

Delete a dependency of a module. MODULE here is a modulespec of the form
MODULE:VERSION that specifies a single version of a module.
""",
        "dependency-add": """
dependency-add MODULE DEPENDENCY

Add a dependency to a module. MODULE here is a modulespec of the form
MODULE:VERSION that specifies a single version of a module.
""",
        "db list": """
list

list the names of all modules
""",
        "shownewest": """
shownewest [MODULES]

This command shows the newest versions of modules by applying some trying to
sort version names intelligently and picking the last in the sort order.

Optional parameter MODULES specifies the names of modules shown. If no modules
are given the command shows the newest versions of all modules.
""",
        "showall": """
showall [MODULES]

This command shows all versions of the given modules. 

Optional parameter MODULES specifies the names of modules shown. If no modules
are given the command shows all versions of all modules.
""",
        "filter": """
filter MODULES...

This command prints only the parts of the dependency database that contain the
given modules. 

Parameter MODULES is a list of modulespecs MODULE:{+-}VERSION that specifies
the modules and versions to operate on. 
""",
        "db find": """
find REGEXP

Show all modules whose names or sources match regexp.
""",
        "check": """
check 

do some consistency checks on the db specifed by --db
""",
        "merge": """
merge DB

Merge the given db with the one specified by --db
""",
        "cloneversion": """
cloneversion MODULE OLD-VERSION NEW-VERSION [SOURCESPEC]

This command adds a new version of a module to the dependency database by
copying the old version. MODULE here is just the name of the module since the
version follows as a separate argument.  If sourcespec is given, the command
changes the source part according to this parameter. A sourcespec has the form
"path PATH", "tar TARFILE", "REPOTYPE URL" or "REPOTYPE URL TAG".  REPOTYPE may
be "darcs", "hg" or "git". Both, URL or TAG may be "*", in this case the
original URL or TAG remain unchanged. If sourcespec is not given, the command
adds NEW-VERSION as new tag to the source specification. The command always
asks for a confirmation of the action unless option "-y" is used.
""",
        "replaceversion": """
replaceversion MODULE OLD-VERSION NEW-VERSION

This command replaces a version of a module with a new
version. MODULE here is just the name of the module since the version
follows as a separate argument. All the data of the module is copied.
If sourcespec is given, the command changes the source part according to this
parameter. A sourcespec has the form "path PATH", "tar TARFILE", "REPOTYPE URL"
or "REPOTYPE URL TAG".  REPOTYPE may be "darcs", "hg" or "git". Both, URL or
TAG may be "*", in this case the original URL or TAG remains unchanged.
""",
        "clonemodule": """
clonemodule OLD-MODULE NEW-MODULE [VERSIONS]

Copy all versions of the existing old module and add this with the name of thew
new module to the dependency database.  OLD-MODULE and NEW-MODULE here are just
the module names since the versions may follow as a separate argument. If there
are no versions specified, the command copies all existing versions. Note that
this DOES NOT add the new module as dependency to any other modules.
""",
        "try": """
try MODULES

This command helps to create module specifications for the "new" command. Each
MODULE here is a modulespec of the form MODULE or MODULE:{+-}VERSION that
specifies just a module name, a module and some versions or a single version.
You can specify an incomplete list of modules.  The program then shows which
modules you have to include in your list since other modules depend on them and
shows information on all versions of all modules that satisfy your module
specifications. It also shows if your module specifications are *complete* and
*exact* meaning that all dependencies are included and all modules are
specified with exactly a single version.  Note that you can use option
"--scandb" in order to give additional information which versions of modules
are compatible with each other. 

With option "--brief" or "-b", the output of the command is a shorter summary
which is in many cases all you want to see.
""",
        "new": """
new MODULES

This command creates a new build. Each module given in MODULES here is
a modulespec of the form MODULE:VERSION that specifies a single version
of a module. If the buildtag is not given as an option, the program
generates a buildtag in the form "AUTO-nnn". A new build is
created according to the modulespecs. Your modulespecifications must be
*complete* and *exact* meaning that all dependencies are included and
all modules are specified with exactly a single version. Use
command "try" in order to create module specifications that can be used
with command "new".  This command calls "make" and, after successful
completion, sets the state of the build to "testing". If you want to
skip this step, use option "--no-make". In order to provide arbitrary options
to make use option "--makeopts". 
""",
        "build find": """
find MODULESPECS

This command is used to find matching builds for a given list of modulespecs.
Each module in MODULES here is a modulespec of the form MODULE or
MODULE:{+-}VERSION that specifies just a module name, a module and some
versions or a single version. The command prints a list of buildtags of
matching builds on the console. If option --brief is given, the program just
shows the buildtags. 

""",
        "useall": """
useall BUILDTAG

This command creates a configure/RELEASE file for an application. The command
must be followed by buildtag. The release file created includes *all* modules
of the build. The buildtag may be given as argument or option. Output to
another file or the console can be specified with option '-o'. 

""",
        "use": """
use MODULES

This command creates a configure/RELEASE file for an application. Each module
given in MODULES here is a modulespec of the form MODULE:VERSION that specifies
a single version of a module. If option --buildtag is given, it checks if this
is compatible with the given modules.  Otherwise it looks for all builds that
have the modules in the required versions. If more than one matching build
found it takes the one with the alphabetically first buildtag. The RELEASE file
created includes only the modules that are specified. Output to another file or
the console can be specified with option '-o'.
""",
        "build list": """
list    

This command lists the names of all builds.
""",
        "show": """
show BUILDTAG

This command shows the data of a build. The buildtag must be given as an 
argument.
""",
        "state": """
state BUILDTAG [NEW-STATE]

This command is used to show or change the state of a build. The buildtag
must be given as an argument. If there is no new state given, it just shows
the current state of the build. Otherwise the state of the build is changed
to the given value. 
""",
        "delete": """
delete BUILDTAG

If no other build depends on the build specified by the buildtag, the
directories of the build are removed and it's entry in the builddb is
deleted. The buildtag must be given as an argument.
""",
        "cleanup": """
cleanup BUILDTAG

This command removes the remains of a failed build. If the command "new" is
interrupted or stopped by an exception in the program, the build may be in an
incomplete state. In this case you can use the "cleanup" command to remove the
directories of the failed build. The buildtag must be given as an argument.

"""
}

def helptext(topics):
    """return helptext.
    """
    # pylint: disable=R0911
    #                          Too many return statements
    if not topics:
        return help_topics[""]
    lc_topics= [s.lower().strip() for s in topics]
    if len(lc_topics)>3:
        return "help should be followed by one or two words"
    if len(lc_topics)==1:
        txt= help_topics[lc_topics[0]]
        if txt is not None:
            return txt
        return "help not found for '%s'" % (" ".join(topics))
    # two words given
    if lc_topics[0] not in help_maincommands:
        return "no known maincommand '%s'" % topics[0]
    txt= help_topics.get(" ".join(lc_topics))
    if txt is not None:
        return txt
    txt= help_topics.get(lc_topics[1])
    if txt is not None:
        return txt
    return "no known subcommand '%s'" % topics[1]

me= script_shortname()
usage = """usage: %s maincommand [subcommand] [options]

Enter '%s help' for help on commands,
      '%s -h' for help on options
""" % (me,me,me)

def main():
    """The main function.

    parse the command-line options and perform the command
    """
    # command-line options and command-line help:
    # pylint: disable=R0915
    #                          Too many statements

    parser = OptionParser(usage=usage,
                          version="%%prog %s" % __version__,
                          description="This program manages EPICS support trees"
                         )

    parser.add_option("--summary",
                      action="store_true",
                      help="Print a summary of the function of the program.",
                      )
    parser.add_option("--test",
                      action="store_true",
                      help="Perform simple self-test.",
                      )
    parser.add_option("-c", "--config",
                      action="append",
                      type="string",
                      help="Load options from the given configuration "
                           "file. You can specify more than one of "
                           "these.  Unless --no-default-config is given, "
                           "the program always loads configuration files "
                           "from several standard directories first "
                           "before it loads your configuration file. The "
                           "contents of all configuration files are "
                           "merged. ",
                      metavar="CONFIGFILE"
                      )
    parser.add_option("--no-default-config",
                      action="store_true",
                      help="If this option is given the program doesn't load "
                           "the default configuration.",
                      )
    parser.add_option("--mergeoption",
                      action="append",
                      type="string",
                      help= "If an option with name OPTIONNAME is given "
                            "here and it is a list option, the lists from "
                            "the config file and the command line are "
                            "merged. The new list is the sum of both lists "
                            "where it is ensured that for all elements the "
                            "string up to the first colon \":\" is unique "
                            "(this is usefule for module specifications "
                            "that have the form \"module:version\").",
                      metavar="OPTIONNAME"
                      )
    parser.add_option("--#include",
                      action="append",
                      type="string",
                      help="Specify a an '#include' directive in the "
                           "configuration file.  This option has only a "
                           "meaning if a configuration file is created with "
                           "the 'makeconfig' command. '#include' means that "
                           "the following file(s) are included before the "
                           "rest of the configuration file. ",
                      metavar="INCLUDEFILES"
                      )
    parser.add_option("--db",
                      action="store",
                      type="string",
                      help= "Define the name of the DB file. This option "
                            "value is stored in the configuration file. ",
                      metavar="DB"
                      )
    parser.add_option("--builddb",
                      action="store",
                      type="string",
                      help= "Specify the BUILDDB file. This option value is "
                            "stored in the configuration file. ",
                      metavar="BUILDDB"
                      )
    parser.add_option("--scandb",
                      action="store",
                      type="string",
                      help= "Specify the (optional) SCANDB file. The scan "
                            "database file contains information on what "
                            "moduleversion can be used with what "
                            "dependency version.",
                      metavar="SCANDB"
                      )
    parser.add_option("--dumpdb",
                      action="store_true",
                      help="Dump the db on the console, currently "
                           "only for these commands : %s." % \
                           (" ".join(("weight","merge",
                                      "clonemodule",
                                      "cloneversion", "replaceversion")))
                      )
    parser.add_option("-t", "--buildtag",
                      action="store",
                      type="string",
                      help= "Specify a buildtag",
                      metavar="BUILDTAG"
                      )
    parser.add_option("--buildtag-stem",
                      action="store",
                      type="string",
                      help= "Specify the stem of a buildtag. This option "
                            "has only an effect on the commands 'new' and "
                            "'try' if a buildtag is not specified. The "
                            "program generates a new tag in the "
                            "form 'stem-nnn' where 'nnn' is the smallest "
                            "possible number that ensures that the buildtag "
                            "is unique.",
                      metavar="STEM"
                      )
    parser.add_option("--supportdir",
                      action="store",
                      type="string",
                      help= "Specify the support directory. If this option "
                            "is not given take the current working directory "
                            "as support directory.  This option value is "
                            "stored in the configuration file. ",
                      metavar="SUPPORTDIR"
                      )
    parser.add_option("-o", "--output",
                      action="store",
                      type="string",
                      help= "Define the output for commands 'useall' and "
                            "'use'. If this option is not given, 'useall' "
                            "and 'use' write to 'configure/RELEASE'. If "
                            "this option is '-', the commands write to "
                            "standard-out",
                      metavar="OUTPUTFILE",
                      )
    parser.add_option("-x", "--extra",
                      action="append",
                      type="string",
                      help= "Specify an extra line that is added to the "
                            "generated RELEASE file. This option value is "
                            "stored in the configuration file. ",
                      metavar="EXTRALINE"
                      )
    parser.add_option("-a", "--alias",
                      action="append",
                      type="string",
                      help= "Define an alias for the commands 'use' and "
                            "'useall'. An alias must have the form FROM:TO. "
                            "The path of module named 'FROM' is put in the "
                            "generated RELEASE file as a variable named "
                            "'TO'. You can specify more than one of these by "
                            "repeating this option or by joining values in a "
                            "single string separated by spaces. This option "
                            "value is stored in the configuration file. ",
                      metavar="ALIAS"
                      )
    parser.add_option("--arch",
                      action="append",
                      help="Define the name of a TARGETARCHITECTURE. You "
                           "can specify more than one target architecture."
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the "
                           "configuration file.",
                      metavar="TARGETARCHITECTURE"
                      )
    parser.add_option("-m", "--module",
                      action="append",
                      help= "Define a modulespec. If you specify modules "
                            "with this option you don't have to put "
                            "modulespecs after some of the commands.  You "
                            "can specify more than one of these by repeating "
                            "this option or by joining values in a single "
                            "string separated by spaces.  This option value "
                            "is stored in the configuration file. ",
                      metavar="MODULESPEC"
                      )
    parser.add_option("-X", "--exclude-states",
                      action="append",
                      type="string",
                      help="For command 'try' exclude all 'dependents' whose "
                           "state does match one of the regular expressions "
                           "(REGEXP).",
                      metavar="REGEXP"
                      )
    parser.add_option("-b", "--brief",
                      action="store_true",
                      help="Create a more brief output for some commands. ",
                      )
    parser.add_option("-D", "--dir-patch",
                      action="append",
                      help="Specify a directory PATCHEXPRESSION. Such an "
                           "expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "path generated. You can specify more than one "
                           "PATCHEXPRESSION. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="PATCHEXPRESSION"
                      )
    parser.add_option("-U", "--url-patch",
                      action="append",
                      help="Specify a repository url PATCHEXPRESSION. Such "
                           "an expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "url generated. You can specify more than one "
                           "PATCHEXPRESSION. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="PATCHEXPRESSION"
                      )
    parser.add_option("--noignorecase",
                      action="store_true",
                      help="For command 'find', do NOT ignore case.",
                      )
    parser.add_option("--no-checkout",
                      action="store_true",
                      help="With this option, \"new\" does not check out "
                           "sources of support modules. This option is "
                           "only here for test purposes.",
                      )
    parser.add_option("--no-make",
                      action="store_true",
                      help="With this option, \"new\" does not call "
                           "\"make\".",
                      )
    parser.add_option("--makeopts",
                      action="append",
                      type="string",
                      help="Specify extra option strings for \"make\""
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the "
                           "configuration file.",
                      )
    parser.add_option("--readonly",
                      action="store_true",
                      help="Do not allow modifying the database files or "
                           "the support directory. "
                           "This option value is stored in the "
                           "configuration file.",
                      )
    parser.add_option("--nolock",
                      action="store_true",
                      help="Do not use file locking."
                      )
    parser.add_option("-p", "--progress",
                      action="store_true",
                      help= "Show progress on stderr. This option value is "
                            "stored in the configuration file. "
                      )
    parser.add_option("--trace",
                      action="store_true",
                      help="Switch on some trace messages.",
                      )
    parser.add_option("--tracemore",
                      action="store_true",
                      help="Switch on even more trace messages.",
                      )
    parser.add_option("--dump-modules",
                      action="store_true",
                      help="Dump module specs, then stop the program.",
                      )
    parser.add_option("-y", "--yes",
                      action="store_true",
                      help="All questions the program may ask are treated "
                           "as if the user replied 'yes'.",
                      )
    parser.add_option("-v", "--verbose",
                      action="store_true",
                      help="Show command calls. This option value is stored "
                           "in the configuration file.",
                      )
    parser.add_option("-n", "--dry-run",
                      action="store_true",
                      help="Just show what the program would do.",
                      )

    # x= sys.argv
    (options, args) = parser.parse_args()
    # options: the options-object
    # args: list of left-over args

    # join some of the list options:
    options.arch       = sumolib.utils.opt_join(options.arch, do_sort= True)
    options.alias      = sumolib.utils.opt_join(options.alias, do_sort= True)
    options.module     = sumolib.utils.opt_join(options.module)
    options.makeopts   = sumolib.utils.opt_join(options.makeopts)
    options.mergeoption= sumolib.utils.opt_join(options.mergeoption)

    if options.summary:
        print_summary()
        sys.exit(0)

    if options.test:
        _test()
        sys.exit(0)

    # we could pass "args" as an additional parameter to process here if it
    # would be needed to process remaining command line arguments.
    process(options, args)
    sys.exit(0)

if __name__ == "__main__":
    main()

