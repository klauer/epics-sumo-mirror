#! /usr/bin/env python
# -*- coding: UTF-8 -*-

# pylint: disable=C0322
#                          Operator not preceded by a space

"""
============
sumo-scan.py
============

Introduction
------------

This programs scans an EPICS support directory tree as it is used at BESSY and
returns the found dependencies in JSON format.

How the program operates
------------------------

The program calls the "make" program in order to evaluate each "RELEASE" file
found in the "configure" directories of the support directories. In these files
there is a definition of a make macro for each dependency like shown here::

  SUPPORT=/opt/Epics/R3.14.8/support
  MISC=$(SUPPORT)/misc/2-4
  ALARM=$(SUPPORT)/alarm/3-1
  SOFT=$(SUPPORT)/soft/2-2

"make" resolves all macros, so "$(SUPPORT)" is replaced by the value of macro
SUPPORT. It returns adds all macros to the set of pre-defined environment
variables and returns the complete set of variables.

This script has a list of all variables that are defined in make if it is
called without any given file. This set is subtracted from the returned set
leaving all macros that were defined in the RELEASE file. The script returns a
list of macros as a map for each support path that was found.

Example output
--------------

For the example shown above, which was taken from the file
"/opt/Epics/R3.14.8/support/mcan/2-3/configure/RELEASE" the script would return
this::

  {
      "/opt/Epics/R3.14.8/support/mcan/2-3": {
          "ALARM": "/opt/Epics/R3.14.8/support/alarm/3-1",
          "MISC": "/opt/Epics/R3.14.8/support/misc/2-4",
          "SOFT": "/opt/Epics/R3.14.8/support/soft/2-2"
      },
  }
"""

# pylint: disable=C0322,C0103

from optparse import OptionParser
import sys
import os.path
import os
import re

import sumo.utils as utils

# version of the program:
my_version= "1.0"

KNOWN_COMMANDS=set(("deps", "name2paths", "path2names",
                    "groups", "repos", "all"))

IGNORE_NAMES= set(["TOP", "EPICS_SUPPORT",
                   "SUPPORT", "TEMPLATE_TOP"]) #, "EPICS_BASE"])

CONFIG_NAME="sumo-scan.config"

import sumo.makefile_scan

makefile_scan_pre= {}

# -----------------------------------------------
# RELEASE file scanning
# -----------------------------------------------

def scan_config_file(filename, external_definitions= None,
                      verbose= False, dry_run= False):
    """scan CONFIG file.

    return CROSS_COMPILER_TARGET_ARCHS.
    """
    wanted= { 'CROSS_COMPILER_TARGET_ARCHS': None
            }
    data= sumo.makefile_scan.scan(filename,
                             external_definitions,
                             makefile_scan_pre,
                             False,
                             verbose, dry_run)
    for k in wanted.keys():
        wanted[k]= data[k]
    return wanted

def scan_support_arch(support_path,
                      verbose= False, dry_run= False):
    """scan the CONFIG file of a support.
    """
    external_definitions= { "TOP": support_path }
    dict_= None
    for n in ("Makefile", "CONFIG"):
        fn= os.path.join(support_path, n)
        if not os.path.exists(fn):
            continue
        dict_= scan_config_file(fn,
                                external_definitions,
                                verbose= verbose, dry_run= dry_run)
        break
    if dict_ is None:
        sys.stderr.write("\nwarning: %s: CROSS_COMPILER_TARGET_ARCHS "
                         "not found\n" % support_path)
        return []
    arch_str= dict_["CROSS_COMPILER_TARGET_ARCHS"]
    return sorted(arch_str.strip().split())


def scan_release_file(filename, external_definitions= None,
                      verbose= False, dry_run= False):
    """scan a release file.
    """
    data= sumo.makefile_scan.scan(filename,
                             external_definitions,
                             makefile_scan_pre,
                             True, # warnings
                             verbose, dry_run)
    dependencies= {}
    for (k,v) in data.items():
        if not os.path.exists(v):
            continue
        #if not "support" in v:
        #    continue
        #if v.endswith("support"):
        #    continue
        if k in IGNORE_NAMES: # names to ignore
            continue
        v= os.path.realpath(v)
        #v= v.replace("//","/") # replace double-slashes
        dependencies[k]= v
    return dependencies

def scan_support_deps(support_path,
                         verbose= False, dry_run= False):
    """scan the RELEASE file of a support.
    """
    external_definitions= { "TOP": support_path }
    return scan_release_file(os.path.join(support_path,"configure","RELEASE"),
                             external_definitions,
                             verbose= verbose, dry_run= dry_run)


def support_configure_data(support_trees,
                    buildtag,
                    rx_exclude_path,
                    progress= False,
                    verbose= False, dry_run= False):
    """scan EPICS configuration files a whole file-tree of EPICS supports.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0913
    #                          Too many arguments
    def slicer(l, val):
        """changes a list to a single element list.

        This function *directly* modifies the list instead of creating a new
        one. This is needed for the os.walk function.
        """
        try:
            i= l.index(val)
        except ValueError, _:
            return
        l[i+1:]= []
        l[0:i]= []
    def purge(l):
        """empties a list by *directly* changing it."""
        l[:]= []
    def slice_buildtag(l, buildtag):
        """narrow the search to a given buildtag."""
        index=0
        i= None
        for e in l:
            if utils.split_treetag(e)[1]==buildtag:
                i= index
                break
            index+=1
        if i is None:
            return
        l[i+1:]= []
        l[0:i]= []
    def exclude(path):
        """test if the exclude expression matches"""
        if rx_exclude_path is None:
            return False
        return bool(rx_exclude_path.search(path))

    release_dict= {}
    arch_dict= {}
    cnt_max= 50
    cnt= 0
    if progress:
        utils.show_progress(cnt, cnt_max, "directories searched for RELEASE")
    # not possible on python 2.5:
    #for (dirpath, dirnames, filenames) in os.walk(support_tree,
    #                                              topdown= True):
    for support_tree in support_trees:
        for (dirpath, dirnames, filenames) in utils.dirwalk(support_tree):
            if progress:
                cnt= utils.show_progress(cnt, cnt_max)
            if exclude(dirpath):
                purge(dirnames)
            slicer(dirnames, "configure")
            if buildtag is not None:
                slice_buildtag(dirnames, buildtag)
            if os.path.basename(dirpath)=="configure":
                # get the path of the versioned support:
                versioned_path= os.path.realpath(os.path.dirname(dirpath))
                if "RELEASE" in filenames:
                    data= scan_support_deps(versioned_path,
                                            verbose= verbose,
                                            dry_run= dry_run)
                    release_dict[versioned_path]= data
                if "CONFIG" in filenames:
                    archs= scan_support_arch(versioned_path,
                                             verbose= verbose,
                                             dry_run= dry_run)
                    arch_dict[versioned_path]= archs
    if progress:
        sys.stderr.write("\n")
    return (release_dict, arch_dict)

def name2path_from_deps(deps):
    """calculate name2path dict from dependency dict.
    """
    name2path= {}
    for dependends in deps.values():
        for name, dep_path in dependends.items():
            utils.dict_of_sets_add(name2path, name, dep_path)
    return utils.dict_sets_to_lists(name2path)

def path2name_from_deps(deps):
    """calculate path2name dict from dependency dict.
    """
    path2name= {}
    for dependends in deps.values():
        for name, dep_path in dependends.items():
            utils.dict_of_sets_add(path2name, dep_path, name)
    return utils.dict_sets_to_lists(path2name)

def groups_from_deps(deps, basedirs):
    """try to group directories.
    """
    def _add(dict_, p):
        """add a path."""
        (head,tail)= os.path.split(p)
        dict_.setdefault(head, set()).add(tail)
    def gen_name(name, basedirs):
        """generate a module name."""
        # print "genname(%s,%s)" % (repr(name),repr(basedirs))
        for basedir in basedirs:
            if name.startswith(basedir):
                if name!=basedir:
                    name= name.replace(basedir,"")
        if name[0]=="/":
            name= name[1:]
        name= name.replace("/","_")
        # print "return: %s" % repr(name.upper())
        return name.upper()
    # print "groups_from_deps STARTED"
    groups= {}
    for path, dependencies in deps.items():
        _add(groups, path)
        for deppath in dependencies.values():
            _add(groups, deppath)
    new= {}
    basedirs= [os.path.realpath(d) for d in basedirs]
    #sys.exit(repr(basedirs))
    for k, v in groups.items():
        groupname= gen_name(k,basedirs)
        groupdict= new.setdefault(groupname, {})
        pathlist = groupdict.setdefault(k, [])
        pathlist.extend(v)
        pathlist.sort()
    # print "ABORTED"
    # sys.exit("exit-ABORTED")
    return new


def filter_exclude_paths(deps, regexp):
    """remove all paths that match regexp.
    """
    rx= re.compile(regexp)
    new= {}
    for path, dependency_dict in deps.items():
        if rx.search(path):
            continue
        new[path]= dependency_dict
    return new

def filter_exclude_deps(deps, regexp):
    """remove all paths whose dependencies match regexp.
    """
    rx= re.compile(regexp)
    new= {}
    for path, dependency_dict in deps.items():
        matched= False
        for _, dep in dependency_dict.items():
            if rx.search(dep):
                matched= True
                break
        if not matched:
            new[path]= dependency_dict
    return new

# -----------------------------------------------
# repository scanning
# -----------------------------------------------

rx_darcs_ssh_url= re.compile(r'^([\w_\.]+)@([\w_\.]+):(.*)$')

def darcs_dir_test(darcs_url, verbose, dry_run):
    """try to list a remote path."""
    m= rx_darcs_ssh_url.match(darcs_url)
    if not m:
        # a pure path
        return os.path.exists(os.path.join(darcs_url, "_darcs"))
    cmd= "ssh %s@%s 'ls %s'" % (m.group(1), m.group(2),
                                os.path.join(m.group(3), "_darcs"))
    try:
        utils.system(cmd,
                     True, verbose, dry_run)
    except IOError, _:
        # probably no darcs repo found
        return False
    return True

def all_paths_from_deps(deps):
    """get a collection of all paths from the dependency dict.
    """
    all_paths= set()
    for path, dependends in deps.items():
        all_paths.add(path)
        for dep_path in dependends.values():
            all_paths.add(dep_path)
    return all_paths

rx_darcs_repo= re.compile(r'^\s*Default Remote:\s*(.*)')

def darcs_source_repo(directory, use_dir_test, verbose, dry_run):
    """get the darcs source repository.

    This function calls "darcs show repo". If there is a "Default
    repository" it is returned.
    """
    if not os.path.exists(os.path.join(directory,"_darcs")):
        return
    try:
        reply= utils.system("cd %s && darcs show repo" % directory,
                             True, verbose, dry_run)
    except IOError, _:
        # probably no darcs repo found
        return
    for line in reply.splitlines():
        m= rx_darcs_repo.match(line)
        if m:
            url= m.group(1).strip()
            if use_dir_test:
                if not darcs_dir_test(url, verbose, dry_run):
                    continue
            return url
    return directory

def darcs_last_tag(directory, verbose, dry_run):
    """Returns the topmost darcs tag.
    """
    try:
        reply= utils.system("cd %s && darcs show tags" % directory, True,
                             verbose, dry_run)
    except IOError, _:
        # probably no darcs repo found
        return
    if not reply:
        # no tags found
        return
    return reply.splitlines()[0].strip()

def repo_info(deps, progress, use_dir_test,
              source_patches,
              verbose, dry_run):
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    """return a PathSource object with repository informations.
    """
    patcher= utils.RegexpPatcher()
    if source_patches:
        for p in source_patches:
            patcher.add(eval(p))
    #sys.exit("ABORT")
    path_set= all_paths_from_deps(deps)
    new= utils.PathSource()
    cnt_max= 50
    cnt= 0
    if progress:
        utils.show_progress(cnt, cnt_max, "paths searched for darcs")
    for path in path_set:
        if progress:
            cnt= utils.show_progress(cnt, cnt_max)
        if not os.path.exists(os.path.join(path,"_darcs")):
            new.add_path(path, patcher.apply(path))
            continue
        # try to find source repository:
        src= darcs_source_repo(path, use_dir_test, verbose, dry_run)
        if not src:
            new.add_path(path, patcher.apply(path))
            continue
        src_patched= patcher.apply(src)
        tag= darcs_last_tag(path, verbose, dry_run)
        if not tag:
            new.add_darcs(path, src_patched)
            continue
        if not utils.is_standardpath(path, tag):
            new.add_darcs(path, src_patched)
            continue
        new.add_darcs(path, src_patched, tag)
    if progress:
        sys.stderr.write("\n")
    return new

# -----------------------------------------------
# main
# -----------------------------------------------

def script_shortname():
    """return the name of this script without a path component."""
    return os.path.basename(sys.argv[0])

def get_configuration(options):
    """get the support configuration data.
    """
    if not options.dir:
        sys.exit("--dir is mandatory")
    for d in options.dir:
        if not os.path.exists(d):
            sys.exit("error, directory \"%s\" doesn't exist" % options.dir)
    rx_exclude= None
    if options.exclude_paths:
        rx_exclude= re.compile(options.exclude_paths)
    (deps, archs)= \
       support_configure_data(options.dir,
                       options.buildtag,
                       rx_exclude,
                       options.progress,
                       options.verbose,
                       options.dry_run
                      )
    return (deps, archs)

# pylint: disable=R0912
#                          Too many branches

def process(options, commands):
    """do all the work.

    """
    if not commands:
        sys.exit("command missing")
    for c in commands:
        if not c in KNOWN_COMMANDS:
            sys.exit("unknown command: %s" % c)

    commands= set(commands)
    if "all" in commands:
        commands.add("deps")
        commands.add("repos")
        commands.add("groups")

    deps= None

    if options.dir:
        (deps, archs)= get_configuration(options)
    elif options.info_file:
        (deps, archs)= utils.json_loadfile(options.info_file)
    else:
        sys.exit("error: -d or -i required for command")

    #if options.exclude_paths:
    #    deps= filter_exclude_paths(deps, options.exclude_paths)
    if options.exclude_deps:
        deps= filter_exclude_deps(deps, options.exclude_deps)

    bag= {}

    if "deps" in commands:
        bag["dependencies"]= deps
        bag["archs"]= archs
    if "name2paths" in commands:
        bag["name2paths"]= name2path_from_deps(deps)
    if "path2names" in commands:
        bag["path2names"]= path2name_from_deps(deps)
    if "groups" in commands:
        bag["groups"]= groups_from_deps(deps, options.group_basedir)
    if "repos" in commands:
        # a utils.PathSource object:
        repo_data= repo_info(deps,
                             options.progress,
                             options.darcs_dirtest,
                             options.source_patch,
                             options.verbose, options.dry_run)
        bag["repos"]= repo_data.to_dict()
        if options.missing_repo:
            bag["missing-repo"]= repo_data.filter_no_repos()
        if options.missing_tag:
            bag["missing-tag"]= repo_data.filter_no_tags()
    utils.json_dump(bag)

# pylint: enable=R0912

def print_doc():
    """print a short summary of the scripts function."""
    print __doc__

def print_summary():
    """print a short summary of the scripts function."""
    print "%-20s: a tool for scanning support EPICS trees \n" % \
          script_shortname()

def _test():
    """does a self-test of some functions defined here."""
    print "performing self test..."
    import doctest
    doctest.testmod()
    print "done!"

usage = """usage: %prog [options] command
where command is:
  deps  : scan RELEASE files
  repos : scan for repositories
  groups: group directories by name
  all   : do commands "deps", "repos" and "groups"
  name2paths: return a map mapping names to paths
  path2names: return a map mapping paths to names
commands can be combined!
"""

def main():
    """The main function.

    parse the command-line options and perform the command
    """
    # command-line options and command-line help:
    parser = OptionParser(usage=usage,
                          version="%%prog %s" % my_version,
                          description="This program scans EPICS support "+\
                              "trees and prints the found dependencies "+\
                              "to the screen",
                         )

    parser.add_option("--summary",
                      action="store_true",
                      help="print a summary of the function of the program",
                      )
    parser.add_option("--doc",
                      action="store_true",
                      help="print a longer description of the program",
                      )
    parser.add_option("--test",
                      action="store_true",
                      help="perform simple self-test",
                      )
    parser.add_option("-c", "--config",
                      action="store",
                      type="string",
                      help="load options from config file FILE, "
                           "default: %s" % CONFIG_NAME,
                      metavar="FILE"
                      )
    parser.add_option("--make-config",
                      action="store",
                      type="string",
                      help="Create a new config file FILE from the given "
                           "options. If the filename is '-' dump "
                           "to the console, if it is an empty string, "
                           "rewrite the config file that was read before.",
                      metavar="FILE"
                      )
    parser.add_option("-d", "--dir",
                      action="append",
                      type="string",
                      help="Parse all RELEASE files in directory DIR, you "
                           "can specify more than one DIR.",
                      metavar="DIR"
                      )
    parser.add_option("-i","--info-file",
                      action="store",
                      type="string",
                      help="read information from INFOFILE. This is a "+ \
                           "file generated by this script in a prevous run.",
                      metavar="INFOFILE"
                      )
    parser.add_option("-g", "--group-basedir",
                      action="append",
                      help="Try to group directories by their name. The "+ \
                           "BASEDIR is taken as directory base to "+ \
                           "calculate group names from directory names." + \
                           "You can specify more than one of these."
                      )
    parser.add_option("--exclude-paths",
                      action="store",
                      type="string",
                      help="exclude all paths that match REGEXP "+ \
                           "from dependencies",
                      metavar="REGEXP"
                      )
    parser.add_option("--exclude-deps",
                      action="store",
                      type="string",
                      help="exclude all paths whose dependencies "+ \
                           "match REGEXP",
                      metavar="REGEXP"
                      )
    parser.add_option("-P", "--source-patch",
                      action="append",
                      help="Specify a source PATCHEXPRESSION. Such an "
                           "expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "url generated. You can specify more than one "
                           "PATCHEXPRESSION.",
                      metavar="PATCHEXPRESSION"
                      )
    parser.add_option("--darcs-dirtest",
                      action="store_true",
                      help="Test if a found remote darcs repository " +\
                           "has a '_darcs' directory in it. This may " +\
                           "help detect invalid default repository " +\
                           "entries.",
                      )
    parser.add_option("--missing-tag",
                      action="store_true",
                      help="show directories where a repository was "+ \
                           "found but no tag",
                      )
    parser.add_option("--missing-repo",
                      action="store_true",
                      help="show directories where no repository was found",
                      )
    parser.add_option("-t", "--buildtag",
                      action="store",
                      type="string",
                      help="scan only directories of the given buildtag",
                      metavar="BUILDTAG"
                      )
    parser.add_option("-p", "--progress",
                      action="store_true",
                      help="show progress on stderr",
                      )
    parser.add_option("-v", "--verbose",
                      action="store_true",
                      help="show command calls ",
                      )
    parser.add_option("-n", "--dry-run",
                      action="store_true",
                      help="just show what the program would do",
                      )

    # x= sys.argv
    (options, args) = parser.parse_args()
    # options: the options-object
    # args: list of left-over args

    config= utils.ConfigFile(("dir", "info_file", "group_basedir",
                              "exclude_paths", "exclude_deps",
                              "source_patch", "darcs_dirtest",
                              "missing_tag", "missing_repo", "buildtag",
                              "progress", "verbose"),
                              CONFIG_NAME)

    if options.summary:
        print_summary()
        sys.exit(0)

    if options.doc:
        print_doc()
        sys.exit(0)

    if options.test:
        _test()
        sys.exit(0)

    config.load_file(options.config)
    # Note: options that are "None" are not changed in the config object:
    config.update_from_options(options)
    config.fill_options(options, overwrite= False)

    if options.make_config is not None:
        config.save_file(options.make_config)
        sys.exit(0)

    # we could pass "args" as an additional parameter to process here if it
    # would be needed to process remaining command line arguments.
    process(options, args)
    sys.exit(0)

if __name__ == "__main__":
    main()

