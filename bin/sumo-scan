#! /usr/bin/env python
# -*- coding: UTF-8 -*-

# pylint: disable=C0322
#                          Operator not preceded by a space

"""
============
sumo-scan.py
============

This script scans an existing EPICS support module directory tree and collects
all information necessary to generate a dependency database or *DB* file.

For details see: `<http://www-csr.bessy.de/control/sumo/>`_

"""

# pylint: disable=C0322,C0103

from optparse import OptionParser
import sys
import os.path
import os
import re
# import pprint

import sumolib.system
import sumolib.Config
import sumolib.utils

import sumolib.makefile_scan
import sumolib.repos

makefile_scan_pre= {}

# version of the program:
__version__= "1.9" #VERSION#

assert __version__==sumolib.system.__version__
assert __version__==sumolib.Config.__version__
assert __version__==sumolib.utils.__version__
assert __version__==sumolib.makefile_scan.__version__
assert __version__==sumolib.repos.__version__

KNOWN_COMMANDS=set(("deps", "name2paths", "path2names",
                    "groups", "repos", "all", "makeconfig"))

IGNORE_NAMES= set(["TOP", "EPICS_SUPPORT",
                   "SUPPORT", "TEMPLATE_TOP"]) #, "EPICS_BASE"])

CONFIG_NAME="sumo-scan.config"

# -----------------------------------------------
# RELEASE file scanning
# -----------------------------------------------

def scan_config_file(filename, external_definitions= None,
                      verbose= False, dry_run= False):
    """scan CONFIG file.

    return CROSS_COMPILER_TARGET_ARCHS.
    """
    wanted= { 'CROSS_COMPILER_TARGET_ARCHS': None
            }
    data= sumolib.makefile_scan.scan(filename,
                             external_definitions,
                             makefile_scan_pre,
                             False,
                             verbose, dry_run)
    for k in wanted.keys():
        wanted[k]= data[k]
    return wanted

def scan_release_file(filename,
                      ignore_names,
                      external_definitions= None,
                      verbose= False, dry_run= False):
    """scan a release file.
    """
    data= sumolib.makefile_scan.scan(filename,
                             external_definitions,
                             makefile_scan_pre,
                             True, # warnings
                             verbose, dry_run)
    dependencies= {}
    for (k,v) in data.items():
        if not os.path.exists(v):
            continue
        #if not "support" in v:
        #    continue
        #if v.endswith("support"):
        #    continue
        if k in ignore_names: # names to ignore
            continue
        v= os.path.realpath(v)
        #v= v.replace("//","/") # replace double-slashes
        dependencies[k]= v
    return dependencies

def scan_support_deps(support_path,
                      ignore_names,
                      verbose= False, dry_run= False):
    """scan the RELEASE file of a support.
    """
    external_definitions= { "TOP": support_path }
    return scan_release_file(os.path.join(support_path,"configure","RELEASE"),
                             ignore_names,
                             external_definitions,
                             verbose= verbose, dry_run= dry_run)


def support_configure_data(support_trees,
                    buildtag,
                    ignore_names,
                    exclude_matcher,
                    trace,
                    progress= False,
                    verbose= False, dry_run= False):
    """scan EPICS configuration files a whole file-tree of EPICS supports.
    """
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0913
    #                          Too many arguments
    def slicer(l, values):
        """changes a list to a list with certain elements.

        This function *directly* modifies the list instead of creating a new
        one. This is needed for the os.walk function.
        """
        new= []
        for v in values:
            if v in l:
                new.append(v)
        l[:]= new
    def purge(l):
        """empties a list by *directly* changing it."""
        l[:]= []
    def slice_buildtag(l, buildtag):
        """narrow the search to a given buildtag."""
        index=0
        i= None
        for e in l:
            if sumolib.utils.split_treetag(e)[1]==buildtag:
                i= index
                break
            index+=1
        if i is None:
            return
        l[i+1:]= []
        l[0:i]= []
    def module_dir_reached(dirnames):
        """return True when we are within a module directory."""
        if "configure" in dirnames:
            return True
        if "db" in dirnames:
            return True
        return False

    release_dict= {}
    arch_dict= {}
    cnt_max= 50
    cnt= 0
    if progress:
        sumolib.utils.show_progress(cnt, cnt_max,
                                    "directories searched for RELEASE")
    # not possible on python 2.5:
    #for (dirpath, dirnames, filenames) in os.walk(support_tree,
    #                                              topdown= True):
    modpath= None
    # progress indicatiors would interfere with trace messages:
    ignore_archs= ["perl","python"]
    if trace:
        progress= False
    for support_tree in support_trees:
        for (dirpath, dirnames, filenames) in \
                                 sumolib.utils.dirwalk(support_tree):
            if trace:
                sys.stderr.write("%s\n" % dirpath)
            if progress:
                cnt= sumolib.utils.show_progress(cnt, cnt_max)
            if exclude_matcher.search(dirpath):
                if trace:
                    sys.stderr.write("\texclude!\n")
                purge(dirnames)
                continue
            if buildtag is not None:
                slice_buildtag(dirnames, buildtag)
            if module_dir_reached(dirnames):
                if trace:
                    sys.stderr.write("\tmodule found\n")
                modpath= dirpath
                # only descend into "configure", "lib" and "bin":
                slicer(dirnames, ["configure","lib","bin"])
                versioned_path= os.path.realpath(dirpath)
                release_dict[versioned_path]= {}
                arch_dict[versioned_path]= set()
                continue
            if modpath is None:
                continue
            if dirpath.startswith(modpath):
                # get the path of the versioned support:
                versioned_path= os.path.realpath(os.path.dirname(dirpath))
                last= os.path.basename(dirpath)
                if last=="configure":
                    if "RELEASE" in filenames:
                        data= scan_support_deps(versioned_path,
                                                ignore_names,
                                                verbose= verbose,
                                                dry_run= dry_run)
                        release_dict[versioned_path]= data
                    purge(dirnames)
                    continue
                elif last=="bin":
                    if "ANY" in arch_dict[versioned_path]:
                        arch_dict[versioned_path].discard("ANY")
                    arch_dict[versioned_path].update(dirnames)
                    purge(dirnames)
                    continue
                elif last=="lib":
                    if "ANY" in arch_dict[versioned_path]:
                        arch_dict[versioned_path].discard("ANY")
                    arch_dict[versioned_path].update(dirnames)
                    purge(dirnames)
                    continue
    if progress:
        sys.stderr.write("\n")
    for (k,v) in arch_dict.items():
        for ign in ignore_archs:
            if ign in v:
                v.discard(ign)
        if not v:
            # set is empty:
            v= set(["ANY"])
        arch_dict[k]= sorted(list(v))
    #if trace:
    #    sys.stderr.write("release_dict:\n")
    #    sys.stderr.write(pprint.pformat(release_dict))
    #    sys.stderr.write("arch_dict:\n")
    #    sys.stderr.write(pprint.pformat(arch_dict))
    return (release_dict, arch_dict)

def name2path_from_deps(deps):
    """calculate name2path dict from dependency dict.
    """
    name2path= {}
    for dependends in deps.values():
        for name, dep_path in dependends.items():
            sumolib.utils.dict_of_sets_add(name2path, name, dep_path)
    return sumolib.utils.dict_sets_to_lists(name2path)

def path2name_from_deps(deps):
    """calculate path2name dict from dependency dict.
    """
    path2name= {}
    for dependends in deps.values():
        for name, dep_path in dependends.items():
            sumolib.utils.dict_of_sets_add(path2name, dep_path, name)
    return sumolib.utils.dict_sets_to_lists(path2name)

def groups_from_deps(deps, basedirs):
    """try to group directories.
    """
    def _add(dict_, p):
        """add a path."""
        (head,tail)= os.path.split(p)
        dict_.setdefault(head, set()).add(tail)
    def gen_name(name, basedirs):
        """generate a module name."""
        # print "genname(%s,%s)" % (repr(name),repr(basedirs))
        for basedir in basedirs:
            if name.startswith(basedir):
                if name!=basedir:
                    name= name.replace(basedir,"")
        if name[0]=="/":
            name= name[1:]
        name= name.replace("/","_")
        # print "return: %s" % repr(name.upper())
        return name.upper()
    # print "groups_from_deps STARTED"
    groups= {}
    for path, dependencies in deps.items():
        _add(groups, path)
        for deppath in dependencies.values():
            _add(groups, deppath)
    new= {}
    basedirs= [os.path.realpath(d) for d in basedirs]
    #sys.exit(repr(basedirs))
    for k, v in groups.items():
        groupname= gen_name(k,basedirs)
        groupdict= new.setdefault(groupname, {})
        pathlist = groupdict.setdefault(k, [])
        pathlist.extend(v)
        pathlist.sort()
    # print "ABORTED"
    # sys.exit("exit-ABORTED")
    return new


def filter_exclude_deps(deps, regexp, trace):
    """remove all paths whose dependencies match regexp.
    """
    rx= re.compile(regexp)
    new= {}
    for path, dependency_dict in deps.items():
        matched= False
        for _, dep in dependency_dict.items():
            if rx.search(dep):
                matched= True
                break
        if not matched:
            new[path]= dependency_dict
        else:
            if trace:
                sys.stderr.write("filter_exclude_deps removes: %s\n" % path)
    return new

# -----------------------------------------------
# repository scanning
# -----------------------------------------------

def all_paths_from_deps(deps):
    """get a collection of all paths from the dependency dict.
    """
    all_paths= set()
    for path, dependends in deps.items():
        all_paths.add(path)
        for dep_path in dependends.values():
            all_paths.add(dep_path)
    return all_paths

def repo_info(deps, progress,
              source_patches,
              ignore_changes_matcher,
              hints,
              verbose, dry_run):
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    """return a dict mapping paths to repository informations.
    """
    repo_hints= {}
    if ignore_changes_matcher:
        repo_hints["ignore changes"]= \
                sumolib.utils.RegexpMatcher(ignore_changes_matcher)
    if source_patches:
        patcher= sumolib.utils.RegexpPatcher()
        for p in source_patches:
            patcher.add(eval(p))
        repo_hints["dir patcher"]= patcher
        repo_hints["url patcher"]= patcher
    repo_hints_path= dict(repo_hints)
    repo_hints_path["force path"]= True
    repo_hints_local= dict(repo_hints)
    repo_hints_local["force local"]= True
    path_set= all_paths_from_deps(deps)
    new= {}
    cnt_max= 50
    cnt= 0
    if progress:
        sumolib.utils.show_progress(cnt, cnt_max,
                                    "paths searched for repositories")
    for path in path_set:
        if progress:
            cnt= sumolib.utils.show_progress(cnt, cnt_max)
        flagdict= hints.flags(path)

        hints_param= repo_hints
        if flagdict.get("path"):
            hints_param= repo_hints_path
        elif flagdict.get("tagless"):
            hints_param= repo_hints_local

        repo_obj= sumolib.repos.repo_from_dir(path, hints_param,
                                           verbose, dry_run)

        new[path]= repo_obj.source_spec()

    if progress:
        sys.stderr.write("\n")
    return new

# -----------------------------------------------
# main
# -----------------------------------------------

def script_shortname():
    """return the name of this script without a path component."""
    return os.path.basename(sys.argv[0])

def get_configuration(options):
    """get the support configuration data.
    """
    if not options.dir:
        sys.exit("--dir is mandatory")
    for d in options.dir:
        if not os.path.exists(d):
            sys.exit("error, directory \"%s\" doesn't exist" % options.dir)
    exclude_matcher= sumolib.utils.RegexpMatcher(options.exclude_path)
    if options.ignore_name:
        ignore_names= set(options.ignore_name)
    else:
        ignore_names= set()
    (deps, archs)= \
       support_configure_data(options.dir,
                       options.buildtag,
                       ignore_names,
                       exclude_matcher,
                       options.trace,
                       options.progress,
                       options.verbose,
                       options.dry_run
                      )
    return (deps, archs)

# pylint: disable=R0912
#                          Too many branches

def process(options, commands):
    """do all the work.

    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    config= sumolib.Config.ConfigFile.from_optionlist(
                CONFIG_NAME,
                ( "#include",
                  "dir", "exclude_deps", "exclude_path", "group_basedir",
                  "hint", "ignore_changes", "ignore_name", "missing_repo",
                  "missing_tag", "progress", "source_patch", "verbose"))
    if (not os.path.exists(CONFIG_NAME)) or options.no_default_config:
        config.disable_default()

    try:
        config.load(options.config)
    except ValueError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    try:
        config.merge_options(options, options.mergeoption)
    except ValueError, e:
        sys.exit(str(e))
    except TypeError, e:
        sys.exit(str(e))

    if not commands:
        sys.exit("command missing")
    for c in commands:
        if not c in KNOWN_COMMANDS:
            sys.exit("unknown command: %s" % c)

    if commands[0]=="makeconfig":
        if len(commands)<=1:
            sys.exit("filename for command \"makeconfig\" is missing")
        config.save(commands[1], commands[2:])
        return

    # evaluate the --hint command line option:
    hints= sumolib.utils.Hints(options.hint)

    commands= set(commands)
    if "all" in commands:
        commands.add("deps")
        commands.add("repos")
        commands.add("groups")

    deps= None

    if "groups" in commands:
        if not options.group_basedir:
            sys.exit("error, option -g is mandatory here")

    options.dir            = sumolib.utils.opt_join(options.dir)
    options.exclude_path   = sumolib.utils.opt_join(options.exclude_path)
    options.group_basedir  = sumolib.utils.opt_join(options.group_basedir)
    options.ignore_changes = sumolib.utils.opt_join(options.ignore_changes)
    options.ignore_name    = sumolib.utils.opt_join(options.ignore_name)
    options.mergeoption    = sumolib.utils.opt_join(options.mergeoption)

    if options.dir:
        (deps, archs)= get_configuration(options)
    elif options.info_file:
        # pylint: disable=W0633
        #                     Attempting to unpack a non-sequence
        (deps, archs)= sumolib.JSON.loadfile(options.info_file)
    else:
        sys.exit("error: -d or -i required for command")

    if options.exclude_deps:
        deps= filter_exclude_deps(deps, options.exclude_deps, options.trace)

    bag= {}

    if "deps" in commands:
        bag["dependencies"]= deps
        bag["archs"]= archs
    if "name2paths" in commands:
        bag["name2paths"]= name2path_from_deps(deps)
    if "path2names" in commands:
        bag["path2names"]= path2name_from_deps(deps)
    if "groups" in commands:
        bag["groups"]= groups_from_deps(deps, options.group_basedir)
    if "repos" in commands:
        repo_data= repo_info(deps,
                             options.progress,
                             options.source_patch,
                             options.ignore_changes,
                             hints,
                             options.verbose, options.dry_run)
        bag["repos"]= repo_data
        if options.missing_repo:
            new= {}
            for (p, s) in repo_data.items():
                sspec= sumolib.repos.SourceSpec(s)
                if sspec.sourcetype=="path":
                    continue
                new[p]= s
            bag["missing-repo"]= new
        if options.missing_tag:
            new= {}
            for (p, s) in repo_data.items():
                sspec= sumolib.repos.SourceSpec(s)
                if sspec.sourcetype=="path":
                    continue
                if sspec.tag is None:
                    new[p]= s
            bag["missing-tag"]= new
    sumolib.JSON.dump(bag)

# pylint: enable=R0912

def print_doc():
    """print a short summary of the scripts function."""
    print __doc__

def print_summary():
    """print a short summary of the scripts function."""
    print "%-20s: a tool for scanning EPICS support trees \n" % \
          script_shortname()

def _test():
    """does a self-test of some functions defined here."""
    print "performing self test..."
    import doctest
    doctest.testmod()
    print "done!"

usage = """usage: %prog [options] command
where command is:
  deps  : scan RELEASE files
  repos : scan for repositories
  groups: group directories by name
  all   : do commands "deps", "repos" and "groups"
  name2paths: return a map mapping names to paths
  path2names: return a map mapping paths to names

The commands above can be combined!

  makeconfig [FILENAME] {OPTIONNAMES}
          Create a new configuration file from the options read from
          configuration files and options from the command line. If FILENAME is
          '-' dump to the console. If FILENAME is "DEFAULT", rewrite the
          configuration file that was read before (see option --config).
          OPTIONNAMES is an optional list of long option names. If OPTIONNAMES
          are specified, only options from this list are saved in the
          configuration file.
"""

def main():
    """The main function.

    parse the command-line options and perform the command
    """
    # command-line options and command-line help:
    parser = OptionParser(usage=usage,
                          version="%%prog %s" % __version__,
                          description="This program scans EPICS support "+\
                              "trees and prints the found dependencies "+\
                              "to the screen",
                         )

    parser.add_option("--summary",
                      action="store_true",
                      help="Print a summary of the function of the program.",
                      )
    parser.add_option("--doc",
                      action="store_true",
                      help="Print a longer description of the program.",
                      )
    parser.add_option("--test",
                      action="store_true",
                      help="Perform simple self-test.",
                      )
    parser.add_option("-c", "--config",
                      action="append",
                      type="string",
                      help="Load options from the given configuration "
                           "file. You can specify more than one of these, "
                           "in this case the files are merged. If this "
                           "option is not given and --no-default-config "
                           "is not given, the program tries to load the "
                           "default configuration file %s." % CONFIG_NAME,
                      metavar="CONFIGFILE"
                      )
    parser.add_option("--no-default-config",
                      action="store_true",
                      help="If this option is given the program doesn't load "
                           "the default configuration.",
                      )
    parser.add_option("--mergeoption",
                      action="append",
                      type="string",
                      help= "If an option with name OPTIONNAME is given "
                            "here and it is a list option, the lists from "
                            "the config file and the command line are "
                            "merged. The new list is the sum of both lists "
                            "where it is ensured that for all elements the "
                            "string up to the first colon \":\" is unique "
                            "(this is usefule for module specifications "
                            "that have the form \"module:version\").",
                      metavar="OPTIONNAME"
                      )
    parser.add_option("--#include",
                      action="append",
                      type="string",
                      help="Specify a an '#include' directive in the "
                           "configuration file.  This option has only a "
                           "meaning if a configuration file is created with "
                           "the 'makeconfig' command. '#include' means that "
                           "the following file(s) are included before the "
                           "rest of the configuration file. ",
                      metavar="INCLUDEFILES"
                      )
    parser.add_option("-d", "--dir",
                      action="append",
                      type="string",
                      help="Parse all RELEASE files in directory DIR."
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="DIR"
                      )
    parser.add_option("-i","--info-file",
                      action="store",
                      type="string",
                      help="Read information from INFOFILE. This is a "
                           "file generated by this script in a prevous run.",
                      metavar="INFOFILE"
                      )
    parser.add_option("-N", "--ignore-name",
                      action="append",
                      help="Define macro names in the RELEASE files that "
                           "should be ignored. You usually want to ignore "
                           "the names 'TOP' or 'SUPPORT' in RELEASE files. "
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="NAME"
                      )
    parser.add_option("-g", "--group-basedir",
                      action="append",
                      help="Option \"-g\" or \"--group-basedir\" must be "
                           "followed by a directory name. It defines the "
                           "part of the directory path that is the same "
                           "for all support modules. This is needed in "
                           "order to generate a module name from the "
                           "module's directory path. "
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "The value of this "
                           "option is stored in the configuration file.",
                      metavar="DIR"
                      )
    parser.add_option("--exclude-path",
                      action="append",
                      type="string",
                      help="Exclude all paths that match REGEXP from "
                           "dependencies. "
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="REGEXP"
                      )
    parser.add_option("--exclude-deps",
                      action="store",
                      type="string",
                      help="Exclude all paths whose dependencies "
                           "match REGEXP. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="REGEXP"
                      )
    parser.add_option("--ignore-changes",
                      action="append",
                      type="string",
                      help="Ignore all uncomitted changes in files that "
                           "match the REGEXP. Usually uncomitted changes "
                           "mean that we cannot use the repository as such "
                           "but must copy the whole directory (source type "
                           "is always 'path'). A common application for "
                           "this option is to ignore changes in "
                           "'configure/RELEASE'. "
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="REGEXP"
                      )
    parser.add_option("-P", "--source-patch",
                      action="append",
                      help="Specify a source PATCHEXPRESSION. Such an "
                           "expression consists of a tuple of 2 python "
                           "strings. The first is the match expression, "
                           "the second one is the replacement string. The "
                           "regular expression is applied to every source "
                           "url generated. You can specify more than one "
                           "PATCHEXPRESSION. "
                           "This option value is stored in the CONFIGFILE.",
                      metavar="PATCHEXPRESSION"
                      )
    parser.add_option( "--hint",
                      action="append",
                      help="Specify a HINT. A HINT has the form "
                      "REGEXP,FLAG{,FLAG}. REGEXP is a regular expression "
                      "that is matched with the module path. FLAG is a "
                      "string that gives hints how to treat that module. "
                      "You can specify more than one hint. "
                      "This option value is stored in the CONFIGFILE.",
                      metavar="HINT"
                      )
    parser.add_option("--missing-tag",
                      action="store_true",
                      help="Show directories where a repository was "
                           "found but no tag. "
                           "This option value is stored in the CONFIGFILE.",
                      )
    parser.add_option("--missing-repo",
                      action="store_true",
                      help="Show directories where no repository was found. "
                           "This option value is stored in the CONFIGFILE.",
                      )
    parser.add_option("-t", "--buildtag",
                      action="store",
                      type="string",
                      help="Scan only directories of the given buildtag.",
                      metavar="BUILDTAG"
                      )
    parser.add_option("-p", "--progress",
                      action="store_true",
                      help= "Show progress on stderr. This option value is "
                            "stored in the configuration file. "
                      )
    parser.add_option("--trace",
                      action="store_true",
                      help="Switch on some trace messages.",
                      )
    parser.add_option("-v", "--verbose",
                      action="store_true",
                      help="Show command calls. This option value is stored "
                           "in the configuration file.",
                      )
    parser.add_option("-n", "--dry-run",
                      action="store_true",
                      help="Just show what the program would do.",
                      )

    # x= sys.argv
    (options, args) = parser.parse_args()
    # options: the options-object
    # args: list of left-over args

    if options.summary:
        print_summary()
        sys.exit(0)

    if options.doc:
        print_doc()
        sys.exit(0)

    if options.test:
        _test()
        sys.exit(0)

    # we could pass "args" as an additional parameter to process here if it
    # would be needed to process remaining command line arguments.
    process(options, args)
    sys.exit(0)

if __name__ == "__main__":
    main()

