#! /usr/bin/env python
# -*- coding: UTF-8 -*-

# pylint: disable=C0111
#                          Missing docstring
# pylint: disable=C0103
#                          Invalid name ... for type module
# pylint: disable=C0322
#                          Operator not preceded by a space

from optparse import OptionParser
import sys
import os.path
import os
import errno
import shutil

import sumo.system
import sumo.JSON
import sumo.lock
import sumo.utils as utils
import sumo.Config
import sumo.ModuleSpec
import sumo.Databases

# version of the program:
my_version= "1.7.3" #VERSION#

sumo.JSON.assert_version(my_version)
sumo.lock.assert_version(my_version)
sumo.system.assert_version(my_version)
utils.assert_version(my_version)

KNOWN_COMMANDS=set(( "cleanup", "delete", "edit", "find", "list",
                     "makeconfig",
                     "new",
                     "show", "state", "try", "use", "useall",
                  ))

CONFIG_NAME="sumo-build.config"

# -----------------------------------------------
# utilities
# -----------------------------------------------

def script_shortname():
    """return the name of this script without a path component."""
    return os.path.basename(sys.argv[0])

# -----------------------------------------------
# directory utilities and filenames
# -----------------------------------------------

def makefilename(build_tag):
    """create a makefile name from a build_tag."""
    return "Makefile-%s" % build_tag

def module_dir_string(buildtag, modulename, versionname):
    """create a module directory string."""
    subdir= "%s+%s" % (versionname, buildtag)
    return os.path.join(modulename, subdir)

def module_basedir_string(modulename):
    """create a module base directory string."""
    return modulename

def ensure_dir(dir_, dry_run):
    """create a dir if it doesn't already exist.
    """
    if not dry_run:
        if not os.path.exists(dir_):
            os.makedirs(dir_)

def rm_empty_dir(dirname, verbose, dry_run):
    """remove a directory.

    If the directory is not empty, return without an error message.
    """
    if verbose:
        print "remove dir %s if it is empty" % dirname
    if dry_run:
        return
    try:
        os.rmdir(dirname)
    except OSError, ex:
        if ex.errno == errno.ENOTEMPTY:
            pass

def _assume_dir(dir_, dry_run):
    """ensure that a directory exists."""
    if not dry_run:
        if not os.path.exists(dir_):
            sys.exit("Error, directory 'configure' not found")


def _config_dir(build_tag, module_name, versionname, dry_run):
    """get the config dir name."""
    dir_= module_dir_string(build_tag, module_name, versionname)
    config_dir= os.path.join(dir_, "configure")
    if not dry_run:
        if not os.path.exists(config_dir):
            errmsg("no configure directory found in %s" % dir_)
            return
    return config_dir

# -----------------------------------------------
# buildtag handling
# -----------------------------------------------

def get_buildtag(options, commands, command_index,
                 optional, check_conflict):
    """get the buildtag from options or commands.

    command_index:
                   Index within commands where we expect
                   the buildtag
    optional:
                   Allow that the buildtag is optional, return None if it
                   is not given
    check_conflict:
                   Abort the program when the buildtag is given with both
                   methods.

    returns a tuple, either
    ("option",TAG) or ("argument",TAG) or ("option",None)
    """
    o_buildtag= None
    c_buildtag= None
    if options.buildtag:
        o_buildtag= options.buildtag
    if len(commands)>=command_index+1:
        c_buildtag= commands[command_index]
    if not o_buildtag and not c_buildtag:
        if optional:
            return ("option",None)
        sys.exit("error: buildtag missing")
    if o_buildtag and c_buildtag and check_conflict:
        sys.exit("error: buildtag given as option AND parameter")
    if o_buildtag:
        return ("option",o_buildtag)
    return ("argument",c_buildtag)

# -----------------------------------------------
# load JSON files
# -----------------------------------------------

def db_from_json_file(filename, keep_locked= False):
    """load a db, exits gracefully in case of an error."""
    try:
        db= sumo.Databases.Dependencies.from_json_file(filename, keep_locked)
    except ValueError, e:
        sys.exit("Error while loading dependency database (db file),\n%s" % \
                 str(e))
    except IOError, e:
        sys.exit("Error while loading dependency database (db file),\n%s" % \
                 str(e))
    return db

def builddb_from_json_file(filename, keep_locked= False):
    """load a builddb, exits gracefully in case of an error."""
    try:
        builddb= sumo.Databases.Builddb.from_json_file(filename, keep_locked)
    except ValueError, e:
        sys.exit("Error while loading build database (builddb),\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading build database (builddb),\n%s" % str(e))
    return builddb

# -----------------------------------------------
# aliases
# -----------------------------------------------

def scan_aliases(aliases):
    """scan aliases given on the command line."""
    d= {}
    if not aliases:
        return d
    for a in aliases:
        (from_, to)= a.split(":")
        d[from_]= to
    return d

def alias(alias_dict, modulename):
    """return a module alias."""
    n= alias_dict.get(modulename)
    if n is None:
        return modulename
    return n

# -----------------------------------------------
# cleanup file handling
# -----------------------------------------------

def cleanupfilename(build_tag):
    """create the name of the cleanup file."""
    return "cleanup-%s" % build_tag

def rmcleanup(build_tag):
    """remove the cleanup file."""
    fn= cleanupfilename(build_tag)
    if os.path.exists(fn):
        return os.remove(fn)

def loadcleanup(build_tag, must_exist= False):
    """load the cleanup file."""
    fn= cleanupfilename(build_tag)
    if os.path.exists(fn):
        return sumo.JSON.loadfile(fn)
    if must_exist:
        raise IOError("file '%s' not found" % fn)
    return {"modules": [] }

def savecleanup(build_tag, struc):
    """save the cleanup file."""
    fn= cleanupfilename(build_tag)
    sumo.JSON.dump_file(fn, struc)

# -----------------------------------------------
# error messages
# -----------------------------------------------

def errmsg(msg):
    """print something on stderr."""
    sys.stderr.write(msg+"\n")

# -----------------------------------------------
# dependency handling
# -----------------------------------------------

def gather_dependencies(dist_dict, db, modulename, versionname,
                        gathered_deps):
    """recursively gather all dependencies of a module.

    For dependencies, do only take moduleversions that are in dist_dict.

    Returns a dict mapping modulenames to versionnames
    """
    if gathered_deps is None:
        gathered_deps= {}
    for dep_name in db.iter_dependencies(modulename, versionname):
        # get all depdendencies, even ones marked "unstable", take
        # archs==None:
        #   ignore architecture
        dep_version= None
        # Note: iter_dependency_versions no longer exists!!
        for v in db.iter_dependency_versions(modulename, versionname,
                                             dep_name, "unstable", None):
            if dist_dict[dep_name]!= v:
                continue
            if dep_version is None:
                dep_version= v
                continue
            else:
                raise AssertionError("module %s dependency %s, two "
                                     "dependency versions found in "
                                     "dist_dict: %s and %s\n" % \
                                     (modulename, dep_name, dep_version, v))
        if dep_version is None:
            raise AssertionError("module %s dependency %s, none of the "
                                 "dependencies of the dependency database is "
                                 "part of dist_dict\n" % \
                                 (modulename, dep_name))
        existing= gathered_deps.get(dep_name)
        if existing is not None:
            if existing!=dep_version:
                raise AssertionError(
                      "version conflict module %s versions %s %s" % \
                      (modulename, existing, dep_version))
            # if this is already in gathered_deps we can skip recursion here
            continue
        gathered_deps[dep_name]= dep_version
        gathered_deps= gather_dependencies(dist_dict, db, dep_name,
                                           dep_version, gathered_deps)
    return gathered_deps

def _add_dependencies(module_dict, db, build_module_dict,
                      modulename, versionname):
    """recursively add missing dependencies.

    called by get_dependencies, command "use"
    """
    try:
        db.assert_module(modulename, versionname)
    except KeyError, e:
        sys.exit("%s in db file" % str(e))
    for dep in db.iter_dependencies(modulename, versionname):
        if module_dict.has_key(dep):
            continue
        version_present= build_module_dict[dep]
        module_dict[dep]= version_present
        _add_dependencies(module_dict, db, build_module_dict,
                          dep, version_present)

def get_dependencies(module_dict, db, builddb, buildtag):
    """recursively complete the module_dict for missing dependencies.

    called by apprelease, command "use"
    """
    build_module_dict= builddb.modules(buildtag)
    modules= module_dict.items()
    for modulename, versionname in modules:
        _add_dependencies(module_dict, db,
                          build_module_dict, modulename, versionname)

def builddb_match(dist_dict, db, builddb, modulename, versionname):
    """try to find matching deps in builddb.
    """
    deps= gather_dependencies(dist_dict, db, modulename, versionname, None)
    # now deps is a dict mapping modulenames to versionnames that contains all
    # direct and indirect dependencies of modulename:versionname that was
    # given to this function.
    for build_tag in builddb.iter_builds():
        # try to find modules that were already built, ignore builds that are
        # not marked "stable" or testing:
        if not builddb.is_testing_or_stable(build_tag):
            continue
        if not builddb.has_module(build_tag, modulename):
            continue
        if builddb.module_link(build_tag, modulename):
            # if this build has only a link of the module, skip it
            continue
        modules= builddb.modules(build_tag)
        if modules[modulename]!=versionname:
            # version doesn't match
            continue

        # from here: check if all dependencies match:
        match= True
        for dep_name, dep_ver in deps.items():
            other= modules.get(dep_name)
            if dep_ver!= other:
                match= False
                break
        if match:
            return build_tag
    return

# -----------------------------------------------
# distribution creation
# -----------------------------------------------

def _distribution_add(db, dist, modulename, versionname,
                      maxstate, archs, required_modules):
    """add a module to the set.

    required_modules: a dict mapping modulename->version that contains modules
    that MUST be used.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0913
    #                          Too many arguments
    #print "_distribution_add(..,..,",modulename,",",versionname,")"
    existing_versionname= dist.get(modulename)
    if existing_versionname is not None:
        if existing_versionname!= versionname:
            raise ValueError("conflict: %s %s %s" % \
                      (modulename, existing_versionname, versionname))
        return dist
    new_dist= dict(dist)
    # ^^^ caution, not a deep copy
    new_dist[modulename]= versionname
    try:
        if not db.dependencies_found(modulename, versionname):
            return new_dist
    except KeyError, e:
        raise ValueError("no information for module %s version %s" % \
                         (modulename, versionname))

    if not db.check_archs(modulename, versionname, archs):
        raise ValueError("no support for archs %s in module %s:%s" % \
                         (repr(archs),modulename,versionname))

    for dep_modulename in db.iter_dependencies(modulename, versionname):
        required_version= required_modules.get(dep_modulename)
        possible_dep_versions= []
        if required_version:
            if not db.depends_on(modulename, versionname,
                                 dep_modulename, required_version):
                raise ValueError("module %s:%s has no dependency of "
                                 "%s:%s according to the dependency "
                                 "database." % \
                                 (modulename, versionname,
                                  dep_modulename, required_version))
            possible_dep_versions= [required_version]
        else:
            possible_dep_versions= db.sorted_dependency_versions(
                modulename, versionname, dep_modulename, maxstate, archs)

        for dep_version in possible_dep_versions:
            errst= None
            try:
                new_dist= _distribution_add(db,
                                            new_dist,
                                            dep_modulename,
                                            dep_version, maxstate, archs,
                                            required_modules)
                errst= None
                break
            except ValueError, e:
                errst= str(e)
        if errst:
            raise ValueError("no module found, last error message: %s" % \
                             errst)
    return new_dist

def distribution(db, modulespecs, maxstate, trace, tracemore):
    """create a distribution.

    modulespecs: a ModuleSpecs object.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0915
    #                          Too many statements
    if not isinstance(modulespecs, sumo.ModuleSpec.Specs):
        raise TypeError("wrong type: '%s'" % modulespecs)
    if trace:
        sys.stderr.write("looking for modules, maxstate: %s\n\n" % \
                         maxstate)

    required_modules= {}
    versioned_modules= []
    versionless_modules= []
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if modulespec.no_version_spec():
            versionless_modules.append((modulename, modulespec.archs))
        elif modulespec.is_exact_spec():
            required_modules[modulename]= modulespec.versionname
            versioned_modules.append((modulename,
                                      modulespec.versionname,
                                      modulespec.archs))
        else:
            raise ValueError("\"-version\" and \"+version\" not "
                             "supported here")
    dist= {}
    m_list= []
    for (modulename, versionname, archs) in versioned_modules:
        if tracemore:
            sys.stderr.write("dist: %s\n" % dist)
            sys.stderr.write("examine %s:%s\n" % (modulename,versionname))
        try:
            dist= _distribution_add(db, dist, modulename, versionname,
                                    maxstate, archs,
                                    required_modules)
        except ValueError, e:
            if trace:
                sys.stderr.write("modules added so far\n%s\n" % \
                                 ("\n".join(m_list)))
                sys.stderr.write("%s:%s\n" % \
                                 (modulename, versionname))
            raise
        if trace:
            m_list.append("\t%s:%s" % (modulename, versionname))

    for (modulename, archs) in versionless_modules:
        if tracemore:
            sys.stderr.write("dist: %s\n" % dist)
            sys.stderr.write("examine %s:*\n" % modulename)
        if trace:
            sys.stderr.write("module %s\n" % modulename)
        try:
            versionlist= db.sorted_moduleversions(modulename, maxstate,
                                                  archs, True)
        except KeyError, e:
            raise ValueError("no data for module %s" % modulename)
        except ValueError, e:
            raise

        found= False
        for versionname in versionlist:
            try:
                dist= _distribution_add(db, dist, modulename, versionname,
                                        maxstate, archs,
                                        required_modules)
                found= True
                break
            except ValueError, e:
                if trace:
                    sys.stderr.write("\t%-15s: %s\n" % \
                                     (versionname, str(e)))
        if not found:
            raise ValueError("no non conflicting versions found for %s" % \
                             modulename)
        else:
            if trace:
                sys.stderr.write("\t%-15s --> found\n" % versionname)

    # dist is now a map, mapping MODULE -> VERSION
    return dist

# -----------------------------------------------
# file generation
# -----------------------------------------------

def gen_RELEASE(db, builddb, buildtag,
                module_set,
                modulename, versionname,
                extra_lines,
                verbose, dry_run):
    """generate a RELEASE file.

    This function requires that the current working directory is the support
    directory!

    Note: the SUPPORT path is the directory of the builddb file!

    module_set:
      a set of (modulename,versionname) pairs that contains all modules of the
      build.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    config_dir= _config_dir(buildtag, modulename, versionname, dry_run)
    if config_dir is None:
        return
    filename= os.path.join(config_dir, "RELEASE")
    if verbose:
        print "creating %s" % filename
    fh= utils.file_w_open(filename, verbose, dry_run)

    supportdir= os.getcwd()
    utils.file_write(fh, "# generated by sumo for build %s\n\n" % buildtag,
            verbose, dry_run)
    utils.file_write(fh, "SUPPORT=%s\n" % supportdir, verbose, dry_run)
    deps= []
    for dep_name in db.iter_dependencies(modulename, versionname):
        # get all depdendencies, even ones marked "unstable":
        # archs==None:
        #   ignore architecture
        # Note: iter_dependency_versions no longer exists!!
        dep_versions= list(db.iter_dependency_versions(modulename,
                                                       versionname,
                                                       dep_name,
                                                       "unstable",
                                                       None))
        my_dep_versions= [v for v in dep_versions \
                          if (dep_name,v) in module_set]
        if len(my_dep_versions)!=1:
            raise AssertionError("unexpected: %s:%s %s %s\n" % \
                    (modulename,versionname,dep_name,
                    repr(my_dep_versions)))

        dep_versionname= my_dep_versions[0]
        deps.append((dep_name, dep_versionname))

    deps= db.sortby_weight(db.sortby_dependency(sorted(deps), True))
    for (dep_name, dep_versionname) in deps:
        name_here= db.get_alias(modulename, versionname, dep_name)
        buildtag_here= builddb.module_link(buildtag, dep_name)
        if buildtag_here is None:
            buildtag_here= buildtag
        path= os.path.join("$(SUPPORT)",
                           module_dir_string(buildtag_here, dep_name,
                                             dep_versionname)
                          )
        utils.file_write(fh, "%s=%s\n" % (name_here,path), verbose, dry_run)
    for l in extra_lines:
        utils.file_write(fh, "%s\n" % l.rstrip(), verbose, dry_run)
    if not dry_run:
        fh.close()

def create_makefile(db, builddb, build_tag, verbose, dry_run):
    """generate a makefile.
    """
    # pylint: disable=R0914
    #                          Too many local variables
    # pylint: disable=R0912
    #                          Too many branches
    def has_makefile(path):
        """checks if there is a makefile in path."""
        fn= os.path.join(path,"Makefile")
        if os.path.exists(fn):
            return True
        fn= os.path.join(path,"makefile")
        if os.path.exists(fn):
            return True
        return False
    paths= {}
    for modulename, versionname in builddb.iter_modules(build_tag):
        if not builddb.module_link(build_tag, modulename):
            dir_= module_dir_string(build_tag,
                                    modulename,
                                    versionname)
            if not has_makefile(dir_):
                continue
            paths[(modulename, versionname)]= dir_
    filename= makefilename(build_tag)
    if not dry_run:
        cleanup_struc= loadcleanup(build_tag)
        cleanup_struc["makefile"]= filename
        savecleanup(build_tag, cleanup_struc)
    module_dirs= sorted(paths.values())
    stamps= [os.path.join(p,"stamp") for p in module_dirs]
    fh= utils.file_w_open(filename, verbose, dry_run)
    utils.file_write(fh, "all: %s\n\n" % (" ".join(stamps)), verbose, dry_run)
    utils.file_write(fh, "clean:\n", verbose, dry_run)
    for d in module_dirs:
        utils.file_write(fh, "\t-$(MAKE) -C %s clean\n" % d, verbose, dry_run)
    for f in stamps:
        utils.file_write(fh, "\trm -f %s\n" % f, verbose, dry_run)
    utils.file_write(fh, "\n", verbose, dry_run)
    for spec, path in paths.items():
        (modulename, versionname)= spec
        own_stamp= os.path.join(path, "stamp")
        dep_stamps= []
        for dep_name in db.iter_dependencies(modulename, versionname):
            if builddb.module_link(build_tag, dep_name):
                continue
            # get all depdendencies, even the ones marked "unstable":
            # archs==None:
            #   ignore architecture
            # Note: iter_dependency_versions no longer exists!!
            dep_versions= list(db.iter_dependency_versions(modulename,
                                                           versionname,
                                                           dep_name,
                                                           "unstable",
                                                           None))
            # keep only (module,version) pairs that are in the path
            # dictionary:
            my_dep_versions= [v for v in dep_versions \
                              if paths.has_key((dep_name,v))]
            if len(my_dep_versions)>1:
                raise AssertionError("unexpected: %s:%s %s %s\n" % \
                        (modulename,versionname,dep_name,
                        repr(my_dep_versions)))
            if not my_dep_versions:
                # do no handle dependencies that are not in the paths
                # dictionary:
                continue
            dep_path= module_dir_string(build_tag,
                                        dep_name, my_dep_versions[0])
            dep_stamps.append(os.path.join(dep_path,"stamp"))

        dep_stamps.sort()
        if dep_stamps:
            utils.file_write(fh,
                             "\n%s: %s\n" % \
                                     (own_stamp, " ".join(dep_stamps)),
                             verbose, dry_run)
    utils.file_write(fh, "\n%/stamp:\n", verbose, dry_run)
    utils.file_write(fh, "\t$(MAKE) -C $(@D)\n", verbose, dry_run)
    utils.file_write(fh, "\ttouch $@\n", verbose, dry_run)
    if not dry_run:
        fh.close()

# -----------------------------------------------
# module creation/deletion
# -----------------------------------------------

def create_source(db, modulename, versionname,
                  destdir, verbose, dry_run):
    """create directory by given source spec.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    (sourcetype, sourcedata)= db.module_source_dict(modulename, versionname)
    if sourcetype=="path":
        #cmd= "scp -r -p \"%s\" %s" % (url, destdir)
        # join(url,"") effectively adds a "/" at the end of the path. This is
        # needed in order for rsync to work as intended here.
        cmd= "rsync -a -u -L --chmod=Fu+w \"%s\" %s" % \
             (os.path.join(sourcedata,""), destdir)
        sumo.system.system(cmd, False, False, verbose, dry_run)
    elif sourcetype=="darcs":
        cmd_l= ["darcs", "get"]
        if sourcedata.has_key("tag"):
            cmd_l.extend(["-t", r"'^%s\s*$'" % sourcedata["tag"]])
        cmd_l.append(sourcedata["url"])
        cmd_l.append(destdir)
        cmd= " ".join(cmd_l)
        sumo.system.system(cmd, False, False, verbose, dry_run)
    else:
        raise AssertionError("unsupported source type %s" % sourcetype)

def delete_module(build_tag, modulename, versionname,
                  must_exist,
                  verbose, dry_run):
    """delete a single module."""
    # pylint: disable=R0913
    #                          Too many arguments
    dirname= module_dir_string(build_tag, modulename, versionname)
    if verbose:
        print "removing %s" % dirname
    if not dry_run:
        if os.path.exists(dirname):
            shutil.rmtree(dirname)
        else:
            if must_exist:
                raise IOError("error: '%s' doesn't exist" % dirname)
        # remove the parent directory if it is empty:
    rm_empty_dir(modulename, verbose, dry_run)

def create_module(db, builddb, build_tag,
                  module_set,
                  modulename, versionname,
                  extra_defs,
                  archs,
                  verbose, dry_run):
    """check out a module.

    returns the build_tag that was used. If the module was found in another
    build, return that built-tag.

    This function requires that the current working directory is the
    support directory!

    module_set:
      a set of (modulename,versionname) pairs that contains all modules of the
      build.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    if not db.check_archs(modulename, versionname, archs):
        sys.stderr.write("error: archs %s\nnot supportted by "
                         "module %s:%s\n" % \
                         (repr(archs), modulename, versionname))
    basedir= module_basedir_string(modulename)
    ensure_dir(basedir, dry_run) # creates basedir if it doesn't exist
    dirname= module_dir_string(build_tag, modulename, versionname)
    if os.path.exists(dirname):
        raise ValueError("directory %s already exists" % dirname)

    create_source(db, modulename, versionname, dirname, verbose, dry_run)
    gen_RELEASE(db, builddb, build_tag,
                module_set,
                modulename, versionname,
                extra_defs,
                verbose, dry_run)

# -----------------------------------------------
# builddb utilities
# -----------------------------------------------

def add_modules(dist_dict, db, builddb, build_tag):
    """add modules to the builddb object.

    This function looks for compatible modules in all already existing builds.
    If possible, modules of existing builds are used.

    All modules specified by dist_dict are added with tag <build_tag> to the
    builddb.
    """
    for modulename in sorted(dist_dict.keys()):
        versionname= dist_dict[modulename]

        # try to find a build that already has the module and where all it's
        # dependencies are also present with the same version as in dist_dict:
        compatible_build= builddb_match(dist_dict, db, builddb, modulename,
                                        versionname)
        if compatible_build is None:
            # no existing build of the module was found, we have to build the
            # module ourselbves:
            build_tag_used= build_tag
        else:
            # a compatible existing build of the module was found:
            build_tag_used= compatible_build

        builddb.add_module(build_tag, build_tag_used, modulename, versionname)

# -----------------------------------------------
# functions called by process()
# -----------------------------------------------

def dump_modules(modulespecs):
    """dump module specs.
    """
    for modulespec in modulespecs:
        print modulespec.to_string()

def delete_modules(builddb, build_tag, verbose, dry_run):
    """delete modules of a build.
    """
    for b in builddb.iter_builds():
        if builddb.is_linked_to(b, build_tag):
            raise ValueError("error: other builds depend on build %s" % \
                              build_tag)
    for modulename, versionname in builddb.iter_modules(build_tag):
        if builddb.module_link(build_tag, modulename):
            continue
        delete_module(build_tag, modulename, versionname, True,
                      verbose, dry_run)

    os.remove(makefilename(build_tag))

    builddb.delete(build_tag)

def cleanup_modules(build_tag, verbose, dry_run):
    """cleanup remains of a failed build.

    This can only happen if a "new" command was aborted due to an exception in
    the script.
    """
    try:
        cleanup_struc= loadcleanup(build_tag, must_exist= True)
    except IOError, e:
        sys.exit(str(e))

    module_list= cleanup_struc["modules"]
    for module_dict in module_list:
        delete_module(build_tag,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      False,
                      verbose, dry_run)
    makefile= cleanup_struc.get("makefile")
    if makefile:
        if os.path.exists(makefile):
            os.remove(makefile)
    if not dry_run:
        rmcleanup(build_tag)

def create_modules(dist_dict, db, builddb, build_tag, extra_lines,
                   archs,
                   verbose, dry_run):
    """create all modules.

    This function requires that the current working directory is the support
    directory!
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # save a list of possibly created directories in a cleanup-structure. In
    # case the script exits with an exception, the created cleanup file can be
    # used to clean up the support directory.
    # Load the cleanup file in case other parts of the script have saved
    # someting there:
    cleanup_struc= loadcleanup(build_tag)
    module_list  = cleanup_struc.setdefault("modules", [])
    module_set   = set()

    # add all modules specified by dist_dict to builddb under tag build_tag:
    add_modules(dist_dict, db, builddb, build_tag)

    if builddb.is_fully_linked(build_tag):
        # the new build would contain only links, this is probably not wanted.
        if sumo.Databases.Builddb.is_generated_buildtag(build_tag):
            # we never want an autotag build that consists only of links
            sys.exit("error, this build with an auto generated tag "
                     "would consist only of links. You can as well "
                     "use one of the existing builds. Just try "
                     "'sumo-build use'.")
        sys.stderr.write("Note: The generated build '%s' consists only of "
                         "links.\n" % build_tag)

    for modulename in sorted(dist_dict.keys()):
        versionname= builddb.module_version(build_tag, modulename)
        module_set.add((modulename, versionname))
        # do not re-create modules that are links:
        if builddb.module_link(build_tag, modulename):
            continue
        # module_list contains only the modules that are NOT links:
        module_list.append({"modulename" : modulename,
                            "versionname": versionname})

    if not dry_run:
        savecleanup(build_tag, cleanup_struc)
    for module_dict in module_list:
        create_module(db, builddb, build_tag,
                      module_set,
                      module_dict["modulename"],
                      module_dict["versionname"],
                      extra_lines,
                      archs,
                      verbose, dry_run)

def call_make(builddb_name, buildtag,
              make_options,
              verbose, dry_run):
    """call "make", then mark the build "testing"."""
    # pylint: disable=R0913
    #                          Too many arguments
    #cmd="make -f %s" % makefilename(buildtag)
    if make_options is None:
        make_options=[]
    cmd="make %s -f %s" % (" ".join(make_options),makefilename(buildtag))
    try:
        # sys.stderr.write("CALLING MAKE: %s\n" % cmd)
        sumo.system.system(cmd, False, False, verbose, dry_run)
    except IOError, e:
        sys.stderr.write("make failed, error: %s" % str(e))
        sys.exit(1)

    builddb= builddb_from_json_file(builddb_name, keep_locked= not dry_run)
    builddb.change_state(buildtag, "testing")
    builddb.json_save(builddb_name, verbose, dry_run)
    # ^^^ does also unlock the file

def fullapprelease(build_path, build_tag, builddb, db, modules,
                   aliases, extra_lines):
    """create entries for an release file.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    lines= ["# generated by sumo using build %s:\n" % build_tag,
            "SUPPORT=%s\n" % os.path.realpath(build_path)]
    if modules is None:
        modules= builddb.modules(build_tag).keys()

    basenames= {}
    mods= []
    for modulename in modules:
        tag= builddb.module_link(build_tag, modulename)
        if tag is None:
            tag= build_tag
        version= builddb.module_version(tag, modulename)
        basenames[(modulename, version)]= \
                   module_dir_string(tag, modulename, version)
        mods.append((modulename, version))

    mods= db.sortby_weight(db.sortby_dependency(sorted(mods), True))
    for (modulename, version) in mods:
        lines.append("%s=%s\n" % \
                (alias(aliases, modulename),
                 os.path.join("$(SUPPORT)", basenames[(modulename, version)])
                ))
    for l in extra_lines:
        lines.append("%s\n" % l)
    return lines

def apprelease(build_path, build_tag, modulespecs, builddb, db,
               aliases, extra_lines):
    """create entries for an release file.
    """
    # pylint: disable=R0913
    #                          Too many arguments
    # pylint: disable=R0914
    #                          Too many local variables
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        if build_tag is None:
            # unspecifed build_tag, all versions must be *exactly specified*:
            if not modulespec.is_exact_spec():
                sys.exit("modulespec '%s' is not an exactly "
                         "specified version" % modulespec.to_string())

    if build_tag is None:
        # must look for a matching build:
        new_builddb= builddb.filter_by_modulespecs(modulespecs, db)
        if new_builddb.is_empty():
            sys.exit("no build found that matches modulespecs")
        tags= [b for b in new_builddb.iter_builds()]
        build_tag= tags[0]
        sys.stderr.write("using build %s\n" % build_tag)


    build_modules= builddb.modules(build_tag)
    module_dict= {}
    for modulespec in modulespecs:
        modulename= modulespec.modulename
        v= build_modules.get(modulename)
        if v is None:
            sys.exit("error: module %s not found in build %s" % \
                     (modulename, build_tag))
        if not modulespec.test(v):
            sys.exit("error: no module matching %s "
                     "found in build %s" % \
                     (modulespec.to_string(), build_tag))
        module_dict[modulename]= v
    get_dependencies(module_dict, db, builddb, build_tag)
    return fullapprelease(build_path, build_tag, builddb, db,
                          module_dict.keys(), aliases, extra_lines)

# -----------------------------------------------
# process command line arguments and options
# -----------------------------------------------

def process(options, commands):
    """do all the work.
    """
    # pylint: disable=R0912
    #                          Too many branches
    # pylint: disable=R0911
    #                          Too many return statements
    # pylint: disable=R0915
    #                          Too many statements
    # pylint: disable=R0914
    #                          Too many local variables
    config= sumo.Config.ConfigFile.from_optionlist(
                CONFIG_NAME,
                ( "#include",
                  "arch", "alias", "builddb", "buildtag_stem", "db", "extra",
                  "makeopts", "maxstate", "module", "progress", "readonly",
                  "supportdir", "verbose",))
    if (not os.path.exists(CONFIG_NAME)) or options.no_default_config:
        config.disable_default()

    try:
        config.load(options.config)
    except ValueError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    except IOError, e:
        sys.exit("Error while loading config file,\n%s" % str(e))
    config.merge_options(options)

    if options.nolock:
        sumo.lock.use_lockfile= False
    if not commands:
        sys.exit("command missing")
    if commands[0] not in KNOWN_COMMANDS:
        sys.exit("unknown command: %s" % commands[0])

    if not options.extra:
        options.extra= []

    if commands[0]=="makeconfig":
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])
        if len(commands)<=1:
            configfile= None
        else:
            configfile= commands[1]
        config.save(configfile)
        return

    if commands[0]=="edit":
        if options.readonly:
            sys.exit("--readonly forbids editing a database file")
        if len(commands)!=2:
            sys.exit("exactly one filename must follow \"edit\"")
        sumo.lock.edit_with_lock(commands[1], options.verbose, options.dry_run)
        return

    if commands[0]=="list":
        if len(commands)>1:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        builddb= builddb_from_json_file(options.builddb)
        for buildtag in builddb.iter_builds():
            print buildtag
        return

    if commands[0]=="show":
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)

        if not options.builddb:
            sys.exit("--builddb is mandatory")
        builddb= builddb_from_json_file(options.builddb)
        if not builddb.has_build_tag(buildtag):
            sys.exit("error, buildtag \"%s\" not found" % buildtag)
        new_builddb= sumo.Databases.Builddb()
        new_builddb.add_build(builddb, buildtag)
        new_builddb.json_print()
        return

    if commands[0]=="state":
        if options.readonly:
            sys.exit("--readonly forbids changing the state of a build")

        if len(commands)>3:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (buildtag_from,buildtag)= get_buildtag(options, commands,
                                               command_index=1,
                                               optional= False,
                                               check_conflict= False)
        if buildtag_from=="option":
            state_idx= 1
        else:
            state_idx= 2

        if len(commands)<=state_idx:
            new_state= None
        else:
            new_state= commands[state_idx]

        if new_state:
            if not options.db:
                sys.exit("--db is mandatory")
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        if new_state:
            db= db_from_json_file(options.db,
                                  keep_locked= not options.dry_run)
        else:
            db= None
        builddb= builddb_from_json_file(options.builddb,
                keep_locked= not options.dry_run)
        if not builddb.has_build_tag(buildtag):
            # db and builddb __del__ method should remove lockfiles
            sys.exit("error, buildtag \"%s\" not found" % buildtag)
        if not new_state:
            print "%-20s : %s" % (buildtag, builddb.state(buildtag))
        else:
            try:
                builddb.change_state(buildtag, new_state)
            except ValueError, e:
                # db and builddb __del__ method should remove lockfiles
                sys.exit(str(e))
            builddb.json_save(options.builddb,
                              options.verbose, options.dry_run)
            # ^^^ does also unlock the file
        return

    if commands[0]=="delete":
        if options.readonly:
            sys.exit("--readonly forbids deleting a support")
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)

        if options.supportdir:
            os.chdir(options.supportdir)

        builddb= builddb_from_json_file(options.builddb)
        if not builddb.has_build_tag(buildtag):
            sys.exit("error, buildtag \"%s\" not found" % buildtag)
        try:
            delete_modules(builddb, buildtag,
                           options.verbose, options.dry_run)
        except ValueError, e:
            sys.exit(str(e))
        builddb.json_save(options.builddb,
                          options.verbose, options.dry_run)
        return

    if commands[0]=="cleanup":
        if options.readonly:
            sys.exit("--readonly forbids cleaning up")
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)
        if options.supportdir:
            os.chdir(options.supportdir)

        cleanup_modules(buildtag, options.verbose, options.dry_run)
        return

    if commands[0]=="try":
        buildtag= options.buildtag
        if not options.db:
            sys.exit("--db is mandatory")
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        if not options.maxstate:
            sys.exit("--maxstate is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        db= db_from_json_file(options.db, keep_locked= False)

        try:
            modulespecs_obj= sumo.ModuleSpec.Specs.from_strings(modulespecs,
                                                            options.builddb,
                                                            options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        try:
            dist_dict= distribution(db, modulespecs_obj, options.maxstate,
                                    options.trace, options.tracemore)
        except ValueError, e:
            # db __del__ method should remove lockfiles
            sys.exit(str(e))

        if buildtag is None:
            if not os.path.exists(options.builddb):
                builddb= sumo.Databases.Builddb()
            else:
                builddb= builddb_from_json_file(options.builddb,
                                                keep_locked= False)
            if not options.buildtag_stem:
                options.buildtag_stem= "AUTO"
            buildtag= builddb.generate_buildtag(options.buildtag_stem)
            sys.stderr.write("would create build with tag '%s'\n\n" % buildtag)

        l= []
        for (m,v) in dist_dict.items():
            l.append("%s:%s" % (m,v))
        l.sort()
        sumo.JSON.dump({"module": l})
        return

    if commands[0]=="new":
        if options.readonly:
            sys.exit("--readonly forbids creating a new build")

        buildtag= options.buildtag

        if not options.db:
            sys.exit("--db is mandatory")
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        if not options.maxstate:
            sys.exit("--maxstate is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        db= db_from_json_file(options.db, keep_locked= not options.dry_run)

        try:
            modulespecs_obj= sumo.ModuleSpec.Specs.from_strings(modulespecs,
                                                            options.builddb,
                                                            options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        try:
            dist_dict= distribution(db,
                                    modulespecs_obj,
                                    options.maxstate,
                                    options.trace,
                                    options.tracemore)
        except ValueError, e:
            # db __del__ method should remove lockfiles
            sys.exit(str(e))

        if not os.path.exists(options.builddb):
            builddb= sumo.Databases.Builddb()
        else:
            builddb= builddb_from_json_file(options.builddb,
                        keep_locked= not options.dry_run)
        if buildtag is None:
            if not options.buildtag_stem:
                options.buildtag_stem= "AUTO"
            buildtag= builddb.generate_buildtag(options.buildtag_stem)
            sys.stderr.write("creating build with tag '%s'\n" % buildtag)
        if builddb.has_build_tag(buildtag):
            # builddb __del__ method should remove lockfiles
            sys.exit("error, buildtag \"%s\" already taken" % buildtag)
        # create a new build in builddb, initial state is "unstable":
        builddb.new_build(buildtag, "unstable")
        if options.supportdir:
            os.chdir(options.supportdir)
        # modifies builddb:
        try:
            create_modules(dist_dict, db, builddb, buildtag,
                           options.extra,
                           options.arch,
                           options.verbose, options.dry_run)
            create_makefile(db, builddb, buildtag,
                            options.verbose, options.dry_run)
        except IOError, e:
            db.unlock_file()
            builddb.unlock_file()
            raise

        builddb.json_save(options.builddb, options.verbose, options.dry_run)
        # ^^^ does also unlock the file
        rmcleanup(buildtag)
        if not options.no_make:
            call_make(options.builddb, buildtag,
                      options.makeopts,
                      options.verbose, options.dry_run)
        return
    if commands[0]=="find":
        if not options.builddb:
            sys.exit("--builddb is mandatory")
        if not options.db:
            sys.exit("--db is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        db= db_from_json_file(options.db)
        builddb= builddb_from_json_file(options.builddb)
        try:
            modulespecs_obj= sumo.ModuleSpec.Specs.from_strings(modulespecs,
                                                            builddb,
                                                            options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)
        new_builddb= builddb.filter_by_modulespecs(modulespecs_obj, db)
        if not options.brief:
            new_builddb.json_print()
        else:
            if new_builddb.is_empty():
                print "no matching buildtrees found"
            else:
                print "matches:"
                d= {}
                for b in new_builddb.iter_builds():
                    d[b]= new_builddb.modules(b)
                sumo.JSON.dump(d)
        return
    if commands[0]=="useall":
        if len(commands)>2:
            sys.exit("error: extra arguments following \"%s\"" % commands[0])

        (_,buildtag)= get_buildtag(options, commands,
                                   command_index=1,
                                   optional= False,
                                   check_conflict= True)

        if not options.db:
            sys.exit("--db is mandatory")
        output= options.output
        if not output:
            _assume_dir("configure", options.dry_run)
            output= os.path.join("configure","RELEASE")

        builddb= builddb_from_json_file(options.builddb)
        db= db_from_json_file(options.db)
        lines= fullapprelease(options.supportdir \
                                 if options.supportdir else ".",
                              buildtag,
                              builddb,
                              db,
                              None,
                              scan_aliases(options.alias),
                              options.extra)
        utils.mk_text_file(output, lines, options.verbose, options.dry_run)
        return

    if commands[0]=="use":
        buildtag= options.buildtag

        if not options.db:
            sys.exit("--db is mandatory")

        modulespecs= []
        if options.module:
            modulespecs.extend(options.module)
        if len(commands)>1:
            modulespecs.extend(commands[1:])
        if not modulespecs:
            sys.exit("error: module specs missing")

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)

        if not options.db:
            sys.exit("--db is mandatory")
        output= options.output
        if not output:
            _assume_dir("configure", options.dry_run)
            output= os.path.join("configure","RELEASE")

        db= db_from_json_file(options.db)
        builddb= builddb_from_json_file(options.builddb)

        try:
            modulespecs_obj= sumo.ModuleSpec.Specs.from_strings(modulespecs,
                                                            options.builddb,
                                                            options.arch)
        except ValueError, e:
            sys.exit(str(e))

        if options.dump_modules:
            dump_modules(modulespecs_obj)
            sys.exit(0)

        lines= apprelease(options.supportdir \
                             if options.supportdir else ".",
                          buildtag,
                          modulespecs_obj,
                          builddb,
                          db,
                          scan_aliases(options.alias),
                          options.extra)
        utils.mk_text_file(output, lines, options.verbose, options.dry_run)
        return

def print_summary():
    """print a short summary of the scripts function."""
    print "%-20s: a tool for managing support EPICS trees \n" % \
          script_shortname()

def _test():
    """does a self-test of some functions defined here."""
    print "performing self test..."
    import doctest
    doctest.testmod()
    print "done!"

usage = """usage: %prog [options] command
where command is:
  makeconfig {FILE}
          Create a new configuration file from the given options. If the
          filename is '-' dump to the console, if it is omitted, rewrite the
          configuration file that was read before (see option --config).
  edit [FILE]
          Start the editor specified by the environment variable "VISUAL" or
          "EDITOR" with that file. This command first aquires a file-lock on
          the file that is only released when the editor program is terminated.
          If you want to edit a DB or BUILDDB file directly, you should always
          do this with this command. The file locking prevents other users to
          use the file at the same time you modify it.
  try [MODULES]
          This command shows the modules and versions the program would take if
          the same options would be given to command "new".
  new [MODULES]
          This command creates a new build. If the buildtag is not given as an
          option, the program generates a buildtag in the form "AUTO-nnn". Note
          that options "--db" and "--builddb" are mandatory for this command. A
          new build is created according to the modulespecs. Moduleversions may
          be unspecified or exactly specified. The algorithm tries to find
          matching moduleversions in the order they are specified for this
          command.  This command calls "make" and, after successful completion,
          sets the state of the build to "testing". If you want to skip this
          step, use option "--no-make". In order to provide arbitrary options
          to make use option "--makeopts".
  find [MODULESPECS]
          This command is used to find matching builds for a given list of
          modulespecs. It prints a list of buildtags of matching builds on the
          console.  Note that the versions in modulespecs may be *unspecified*,
          *specified exactly* or *specifed by relation*.
  useall [BUILDTAG]
          This command creates a configure/RELEASE file for an application. The
          command must be followed by buildtag. The release file created
          includes *all* modules of the build. The buildtag may be given as
          argument or option. Output to another file or the console can be
          specified with option '-o'.
  use [MODULES]
          This command creates a configure/RELEASE file for an application. The
          command must be followed by a list of modulespecs. If option
          --buildtag is given, it checks if this is compatible with the given
          modules. Otherwise it looks for all builds that have the modules in
          the required versions. If more than one matching build found it takes
          the one with the alphabetically first buildtag. Note that the
          modulespecs MUST specify versions exactly. If you have unspecified
          versions or versions specified by relation you must use command "use"
          instead. The RELEASE created includes only the modules that are
          specified. For this command the DB file must be specified with the
          "--db" option. Output to another file or the console can be specified
          with option '-o'.
  list    
          This command lists the names of all builds.
  show [BUILDTAG]
          This command shows the data of a build. The buildtag may be given as
          argument or option.
  state {BUILDTAG} {NEW STATE}
          This command is used to show or change the state of a build. The
          buildtag may be given as argument or option.If there is no new state
          given, it just shows the current state of the build. Otherwise the
          state of the build is changed to the given value. 
  delete {BUILDTAG}
          If no other build depends on the build specified by the buildtag, the
          directories of the build are removed and it's entry in the builddb is
          deleted. The buildtag may be given as argument or option.
  cleanup {BUILDTAG}
          This command removes the remains of a failed build. If the command
          "new" is interrupted or stopped by an exception in the program, the
          build may be in an incomplete state. In this case you can use the
          "cleanup" command to remove the directories of the failed build. The
          buildtag may be given as argument or option.
"""

def main():
    """The main function.

    parse the command-line options and perform the command
    """
    # command-line options and command-line help:

    parser = OptionParser(usage=usage,
                          version="%%prog %s" % my_version,
                          description="This program manages EPICS support trees"
                         )

    parser.add_option("--summary",
                      action="store_true",
                      help="Print a summary of the function of the program.",
                      )
    parser.add_option("--test",
                      action="store_true",
                      help="Perform simple self-test.",
                      )
    parser.add_option("-c", "--config",
                      action="append",
                      type="string",
                      help="Load options from the given configuration "
                           "file. You can specify more than one of these, "
                           "in this case the files are merged. If this "
                           "option is not given and --no-default-config "
                           "is not given, the program tries to load the "
                           "default configuration file %s." % CONFIG_NAME,
                      metavar="CONFIGFILE"
                      )
    parser.add_option("--no-default-config",
                      action="store_true",
                      help="If this option is given the program doesn't load "
                           "the default configuration.",
                      )
    parser.add_option("--#include",
                      action="append",
                      type="string",
                      help="Specify a an '#include' directive in the "
                           "configuration file.  This option has only a "
                           "meaning if a configuration file is created with "
                           "the 'makeconfig' command. '#include' means that "
                           "the following file(s) are included before the "
                           "rest of the configuration file. ",
                      metavar="INCLUDEFILES"
                      )
    parser.add_option("--db",
                      action="store",
                      type="string",
                      help= "Define the name of the DB file. This option "
                            "value is stored in the configuration file. ",
                      metavar="DB"
                      )
    parser.add_option("--builddb",
                      action="store",
                      type="string",
                      help= "Specify the BUILDDB file. This option value is "
                            "stored in the configuration file. ",
                      metavar="BUILDDB"
                      )
    parser.add_option("-t", "--buildtag",
                      action="store",
                      type="string",
                      help= "Specify a buildtag",
                      metavar="BUILDTAG"
                      )
    parser.add_option("--buildtag-stem",
                      action="store",
                      type="string",
                      help= "Specify the stem of a buildtag. This option "
                            "has only an effect on the commands 'new' and "
                            "'try' if a buildtag is not specified. The "
                            "program generates a new tag in the "
                            "form 'stem-nnn' where 'nnn' is the smallest "
                            "possible number that ensures that the buildtag "
                            "is unique.",
                      metavar="STEM"
                      )
    parser.add_option("--supportdir",
                      action="store",
                      type="string",
                      help= "Specify the support directory. If this option "
                            "is not given take the current working directory "
                            "as support directory.  This option value is "
                            "stored in the configuration file. ",
                      metavar="SUPPORTDIR"
                      )
    parser.add_option("-o", "--output",
                      action="store",
                      type="string",
                      help= "Define the output for commands 'useall' and "
                            "'use'. If this option is not given, 'useall' "
                            "and 'use' write to 'configure/RELEASE'. If "
                            "this option is '-', the commands write to "
                            "standard-out",
                      metavar="OUTPUTFILE",
                      )
    parser.add_option("-x", "--extra",
                      action="append",
                      type="string",
                      help= "Specify an extra line that is added to the "
                            "generated RELEASE file. This option value is "
                            "stored in the configuration file. ",
                      metavar="EXTRALINE"
                      )
    parser.add_option("-a", "--alias",
                      action="append",
                      type="string",
                      help= "Define an alias for the commands 'use' and "
                            "'useall'. An alias must have the form FROM:TO. "
                            "The path of module named 'FROM' is put in the "
                            "generated RELEASE file as a variable named "
                            "'TO'. You can specify more than one of these by "
                            "repeating this option or by joining values in a "
                            "single string separated by spaces. This option "
                            "value is stored in the configuration file. ",
                      metavar="ALIAS"
                      )
    parser.add_option("--arch",
                      action="append",
                      help="Define the name of a TARGETARCHITECTURE. You "
                           "can specify more than one target architecture."
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the "
                           "configuration file.",
                      metavar="TARGETARCHITECTURE"
                      )
    parser.add_option("-M", "--maxstate",
                      action="store",
                      type="string",
                      help= "Specify the maximum state for some commands."
                            "This option value is stored in the "
                            "configuration file. ",
                      metavar="STATE"
                      )
    parser.add_option("-m", "--module",
                      action="append",
                      help= "Define a modulespec. If you specify modules "
                            "with this option you don't have to put "
                            "modulespecs after some of the commands.  You "
                            "can specify more than one of these by repeating "
                            "this option or by joining values in a single "
                            "string separated by spaces.  This option value "
                            "is stored in the configuration file. ",
                      metavar="MODULESPEC"
                      )
    parser.add_option("-b", "--brief",
                      action="store_true",
                      help="Create a more brief output for some commands. ",
                      )
    parser.add_option("--no-make",
                      action="store_true",
                      help="With this option, \"new\" does not call "
                           "\"make\".",
                      )
    parser.add_option("--makeopts",
                      action="append",
                      type="string",
                      help="Specify extra option strings for \"make\""
                           "You can specify more than one of these by "
                           "repeating this option or by joining values in "
                           "a single string separated by spaces. "
                           "This option value is stored in the "
                           "configuration file.",
                      )
    parser.add_option("--readonly",
                      action="store_true",
                      help="Do not allow modifying the database files or "
                           "the support directory. "
                           "This option value is stored in the "
                           "configuration file.",
                      )
    parser.add_option("--nolock",
                      action="store_true",
                      help="Do not use file locking."
                      )
    parser.add_option("-p", "--progress",
                      action="store_true",
                      help= "Show progress on stderr. This option value is "
                            "stored in the configuration file. "
                      )
    parser.add_option("--trace",
                      action="store_true",
                      help="Switch on some trace messages.",
                      )
    parser.add_option("--tracemore",
                      action="store_true",
                      help="Switch on even more trace messages.",
                      )
    parser.add_option("--dump-modules",
                      action="store_true",
                      help="Dump module specs, then stop the program.",
                      )
    parser.add_option("-v", "--verbose",
                      action="store_true",
                      help="Show command calls. This option value is stored "
                           "in the configuration file.",
                      )
    parser.add_option("-n", "--dry-run",
                      action="store_true",
                      help="Just show what the program would do.",
                      )

    # x= sys.argv
    (options, args) = parser.parse_args()
    # options: the options-object
    # args: list of left-over args

    # join some of the list options:
    options.arch    = utils.opt_join(options.arch, do_sort= True)
    options.alias   = utils.opt_join(options.alias, do_sort= True)
    options.module  = utils.opt_join(options.module)
    options.makeopts= utils.opt_join(options.makeopts)

    if options.summary:
        print_summary()
        sys.exit(0)

    if options.test:
        _test()
        sys.exit(0)

    # we could pass "args" as an additional parameter to process here if it
    # would be needed to process remaining command line arguments.
    process(options, args)
    sys.exit(0)

if __name__ == "__main__":
    main()



